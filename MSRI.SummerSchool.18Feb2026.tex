\documentclass[letterpaper,11pt,oneside,reqno]{amsbook}
%\usepackage{srcltx}
\usepackage{bm}
\usepackage{mathrsfs}
%\usepackage{yfonts}
\usepackage{amsfonts,amsmath, amssymb,amsthm,amscd,stmaryrd}
\usepackage[height=9.6in,width=5.95in]{geometry}
\usepackage[mpexclude,DIV13]{typearea}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[latin1]{inputenc}
\usepackage{latexsym}
\usepackage{lscape}
\usepackage{epsfig}
%\usepackage{subfigure}
\include{bibtex}









\usepackage[color,notcite]{showkeys}
\usepackage{setspace}


\theoremstyle{remark}
\newtheorem{remark}{Remark}

\usepackage{parskip}

\newcommand{\ovbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}


\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `basename
#1.tif`.png}

\begin{document}
\bibliographystyle{alpha}
\newcommand{\cn}[1]{\overline{#1}}
\newcommand{\e}[0]{\varepsilon}
\newcommand{\phimac}{\varphi}
\newcommand{\bbf}[0]{\mathbf}

\newcommand{\Pfree}[5]{\ensuremath{\mathbb{P}^{#1,#2,#3,#4,#5}}}
\newcommand{\PfreeShort}{\ensuremath{\mathbb{P}^{BB}}}

%AAAAAAA
\newcommand{\WH}[8]{\ensuremath{\mathbb{W}^{#1,#2,#3,#4,#5,#6,#7}_{#8}}}
\newcommand{\Wfree}[5]{\ensuremath{\mathbb{W}^{#1,#2,#3,#4,#5}}}
\newcommand{\WHShort}[3]{\ensuremath{\mathbb{W}^{#1,#2}_{#3}}}
\newcommand{\WHShortCouple}[2]{\ensuremath{\mathbb{W}^{#1}_{#2}}}

\newcommand{\walk}[3]{\ensuremath{X^{#1,#2}_{#3}}}
\newcommand{\walkupdated}[3]{\ensuremath{\tilde{X}^{#1,#2}_{#3}}}
\newcommand{\walkfull}[2]{\ensuremath{X^{#1,#2}}}
\newcommand{\walkfullupdated}[2]{\ensuremath{\tilde{X}^{#1,#2}}}
%AAAAAAA

\newcommand{\PH}[8]{\ensuremath{\mathbb{Q}^{#1,#2,#3,#4,#5,#6,#7}_{#8}}}
\newcommand{\PHShort}[1]{\ensuremath{\mathbb{Q}_{#1}}}
\newcommand{\PHExp}[8]{\ensuremath{\mathbb{F}^{#1,#2,#3,#4,#5,#6,#7}_{#8}}}
%%%%

\newcommand{\D}[8]{\ensuremath{D^{#1,#2,#3,#4,#5,#6,#7}_{#8}}}
\newcommand{\DShort}[1]{\ensuremath{D_{#1}}}
\newcommand{\partfunc}[8]{\ensuremath{Z^{#1,#2,#3,#4,#5,#6,#7}_{#8}}}
\newcommand{\partfuncShort}[1]{\ensuremath{Z_{#1}}}
\newcommand{\bolt}[8]{\ensuremath{W^{#1,#2,#3,#4,#5,#6,#7}_{#8}}}
\newcommand{\boltShort}[1]{\ensuremath{W_{#1}}}
\newcommand{\boltNew}{\ensuremath{W}}
\newcommand{\QTLH}{\ensuremath{\mathfrak{H}}}
\newcommand{\QTLHgen}{\ensuremath{\mathfrak{L}}}

\newcommand{\whitenoise}{\ensuremath{\mathscr{\dot{W}}}}
\newcommand{\mf}{\mathfrak}

%\newcommand{\SHE}[2]{\ensuremath{\mathcal{Z}(#1,#2)}}
%\newcommand{\SHEShort}{\ensuremath{\mathcal{Z}}}

%\newcommand{\KPZ}[2]{\ensuremath{\mathcal{H}(#1,#2)}}
%\newcommand{\KPZShort}{\ensuremath{\mathcal{H}}}

%\newcommand{\dle}[2]{\ensuremath{\mathcal{D}^{#1}_{#2}}}
\newcommand{\EE}{\ensuremath{\mathbb{E}}}
\newcommand{\PP}{\ensuremath{\mathbb{P}}}
\newcommand{\var}{\textrm{var}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\Q}{\ensuremath{\mathbb{Q}}}
\newcommand{\T}{\ensuremath{\mathbb{T}}}
\newcommand{\E}[0]{\mathbb{E}}
\newcommand{\OO}[0]{\Omega}
\newcommand{\F}[0]{\mathfrak{F}}
\def \Ai {{\rm Ai}}
\newcommand{\G}[0]{\mathfrak{G}}
\newcommand{\ta}[0]{\theta}
\newcommand{\w}[0]{\omega}
\newcommand{\ra}[0]{\rightarrow}
\newcommand{\vectoro}{\overline}
\newcommand{\crairy}{\mathcal{CA}}
%\newcommand{\ws}{{\rm WS}}
\newcommand{\nc}{\mathsf{NoTouch}}
\newcommand{\ncf}{\mathsf{NoTouch}^f}
%\newcommand{\ncmi}{{\rm NC}^{-\infty}}
\newcommand{\wxy}{\mathcal{W}_{k;\bar{x},\bar{y}}}
%\newcommand{\wxylr}{\mathcal{W}_{k;\bar{x},\bar{y}}^{\ell,r}}
%\newcommand{\wxylrprime}{\mathcal{W}_{k;\bar{x}',\bar{y}'}^{\ell,r}}
%\newcommand{\ewxy}{\mathcal{E}_{\bar{x},\bar{y}}}
%\newcommand{\bxyf}{\mathcal{B}_{\bar{x},\bar{y},f}}
%\newcommand{\bxyflr}{\mathcal{B}_{\bar{x},\bar{y},f}^{\ell,r}}
%\newcommand{\bstar}{\mathcal{B}^{*}_{\bar{x},\bar{y},f}}
%\newcommand{\bprime}{\mathcal{B}'_{\bar{x},\bar{y},f}}
%\newcommand{\zxyf}{Z_{\bar{x},\bar{y},f}}
%\newcommand{\signci}{\sigma\big((\tilde{N}^i_1)^c\big)}
%\newcommand{\signc}{\sigma_{\tilde{N}^c}}
\newcommand{\AP}{\mathfrak{a}}
\newcommand{\cm}{\mathfrak{c}}
%\newcommand{\CMK}{\textrm{CM}^K_{\ell,r}}
%\newcommand{\XYfM}{\textrm{XY}^{f}_M}
%\newcommand{\maxone}{\mathcal{M}}
%\newcommand{\fext}{\mathcal{F}_{ext}}
%\newcommand{\aone}{{\rm A}}
%\newcommand{\setm}{{\rm M}}
\newtheorem{theorem}{Theorem}[chapter]
%\numberwithin{theorem}{subsection}
\numberwithin{figure}{chapter}
\newtheorem{partialtheorem}{Partial Theorem}[section]
\newtheorem{conj}[theorem]{Conjecture}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{experiment}[theorem]{Experimental Result}

%\numberwithin{section}{chapter}
\renewcommand{\thesection}{\thechapter.\arabic{section}}

\def\todo#1{\marginpar{\raggedright\footnotesize #1}}
\def\change#1{{\color{green}\todo{change}#1}}
\def\note#1{\textup{\textsf{\color{blue}(#1)}}}

\theoremstyle{definition}
\newtheorem{rem}[theorem]{Remark}

\theoremstyle{definition}
\newtheorem{com}[theorem]{Comment}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

\theoremstyle{definition}
\newtheorem{definitions}[theorem]{Definitions}


\theoremstyle{definition}
\newtheorem{conjecture}[theorem]{Conjecture}


\newcommand{\airysh}{\mathcal{A}}
\newcommand{\hfixed}{\mathcal{H}}
\newcommand{\afixed}{\mathcal{A}}
\newcommand{\canopynoarg}{\mathsf{C}}
\newcommand{\canopy}[3]{\ensuremath{\mathsf{C}_{#1,#2}^{#3}}}
\newcommand{\argmax}{x_{{\rm max}}}
%\newcommand{\ymax}{y_{{\rm max}}}
\newcommand{\zmax}{z_{{\rm max}}}

\newcommand{\Rkle}{\ensuremath{\mathbb{R}^k_{>}}}
\newcommand{\Ronele}{\ensuremath{\mathbb{R}^k_{>}}}
%\newcommand{\ncf}{{\rm NC}^f}
\newcommand{\ewxy}{\mathcal{E}_{k;\bar{x},\bar{y}}}

\newcommand{\bxyf}{\mathcal{B}_{\bar{x},\bar{y},f}}
\newcommand{\bxyflr}{\mathcal{B}_{\bar{x},\bar{y},f}^{\ell,r}}

\newcommand{\bxyfone}{\mathcal{B}_{x_1,y_1,f}}


\newcommand{\ptac}{p}
\newcommand{\ptact}{v}
\newcommand{\nF}{H}

\newcommand{\fext}{\mathfrak{F}_{{\rm ext}}}
\newcommand{\gext}{\mathfrak{G}_{{\rm ext}}}
\newcommand{\xext}{{\rm xExt}(\mathfrak{c}_+)}


\newcommand{\bmotion}{X}

\newcommand{\dd}{\, {\rm d}}
\newcommand{\signc}{\Sigma}
%\newcommand{\wxy}{\mathcal{W}_{k;\bar{x},\bar{y}}}
\newcommand{\wxylr}{\mathcal{W}_{k;\bar{x},\bar{y}}^{\ell,r}}
\newcommand{\wxylrprime}{\mathcal{W}_{k;\bar{x}',\bar{y}'}^{\ell,r}}
%\newcommand{\Rkle}{\ensuremath{\mathbb{R}^k_{>}}}
\newcommand{\Rklezero}{\ensuremath{\mathbb{R}^k_{>0}}}
\newcommand{\XYfM}{\textrm{XY}^{f}_M}

\newcommand{\upright}{D}
\newcommand{\energy}{E}
\newcommand{\xmax}{{\rm max}_1}
\newcommand{\ymax}{{\rm max}_2}
\newcommand{\lppls}{\mathcal{L}}
\newcommand{\lpplsre}{\mathcal{L}^{{\rm re}}}
\newcommand{\lpplsarg}[1]{\mathcal{L}_{n}^{\fa \to #1}}
\newcommand{\larg}[3]{\mathcal{L}_{n}^{#1,#2;#3}}
\newcommand{\BP}{M}
\newcommand{\weight}{\mathsf{Wgt}}
\newcommand{\pairweight}{\mathsf{PairWgt}}
\newcommand{\sumweight}{\mathsf{SumWgt}}
\newcommand{\mpgood}{\mathcal{G}}
\newcommand{\mpg}{\mathsf{Fav}}
\newcommand{\mcgone}{\mathsf{Fav}_1}
\newcommand{\radnik}[2]{\mathsf{RN}_{#1,#2}}
\newcommand{\size}[2]{\mathsf{S}_{#1,#2}}
\newcommand{\pdr}{\mathsf{PolyDevReg}}
\newcommand{\pwr}{\mathsf{PolyWgtReg}}
\newcommand{\lwr}{\mathsf{LocWgtReg}}
\newcommand{\hwp}{\mathsf{HighWgtPoly}}
\newcommand{\maxswf}{\mathsf{MaxScSumWgtFl}}
\newcommand{\emaxswf}{\e \! - \! \maxswf}
\newcommand{\minswf}{\mathsf{MinScSumWgtFl}}
\newcommand{\eminswf}{\e \! - \! \minswf}
\newcommand{\surreg}{\mathcal{R}}
\newcommand{\scf}{\mathsf{FavSurgCond}}
\newcommand{\disjtpoly}{\mathsf{DisjtPoly}}
\newcommand{\intint}[1]{\llbracket 1,#1 \rrbracket}
\newcommand{\maxsym}{*}
\newcommand{\polynum}{\#\mathsf{Poly}}
\newcommand{\dlp}{\mathsf{DisjtLinePoly}}
\newcommand{\lowb}{\underline{B}}
\newcommand{\highb}{\overline{B}}
\newcommand{\tottt}{t_{1,2}^{2/3}}
\newcommand{\tot}{t_{1,2}}

\newcommand{\mc}{\mathcal}
\newcommand{\vect}{\mathbf}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\scB}{\mathscr{B}}
\newcommand{\scBres}{\mathscr{B}^{\mathrm{re}}}
\newcommand{\rightshadow}{\mathrm{RS}Z}
\newcommand{\dbm}{L}
\newcommand{\dysonbm}{DBM}
\newcommand{\edgedbm}{\mc{L}^{\scal}}
\newcommand{\edgedysonbm}{D^{\rm edge}}
\newcommand{\gue}{\mathrm{GUE}}
\newcommand{\edgegue}{\mathrm{GUE}^{\mathrm{edge}}}
\newcommand{\eqdist}{\stackrel{(d)}{=}}
\newcommand{\geqdist}{\stackrel{(d)}{\succeq}}
\newcommand{\leqdist}{\stackrel{(d)}{\preceq}}
\newcommand{\scal}{{\rm sc}}
\newcommand{\fa}{x_0}
\newcommand{\hit}{H}
\newcommand{\scaledle}{\mathsf{Sc}\mc{L}}
\newcommand{\cenleup}{\mathscr{L}^{\uparrow}}
\newcommand{\cenledown}{\mathscr{L}^{\downarrow}}
\newcommand{\eln}{T}
%\newcommand{\xmin}{X^{{\rm min}}}
\newcommand{\xmin}{{\rm Corner}^{\mfl,\mc{F}}}
\newcommand{\ymin}{{\rm Corner}^{\mfr,\mc{F}}}
\newcommand{\gxmin}{{\rm Corner}^{\gfl,\mc{F}}}
\newcommand{\gymin}{{\rm Corner}^{\gfr,\mc{F}}}
%\newcommand{\ymin}{Y^{{\rm min}}}
%\newcommand{\barxmin}{\bar{X}^{{\rm min}}}
\newcommand{\barxmin}{{\rm \overline{C}}{\rm orner}^{\mfl,\mc{F}}}
\newcommand{\barymin}{{\rm \overline{C}}{\rm orner}^{\mfr,\mc{F}}}
\newcommand{\gbarxmin}{{\rm \overline{C}}{\rm orner}^{\gfl,\mc{F}}}
\newcommand{\gbarymin}{{\rm \overline{C}}{\rm orner}^{\gfr,\mc{F}}}
%\newcommand{\barymin}{\bar{Y}^{{\rm min}}}
\newcommand{\qmin}{{\rm Corner}^{\mfl,\mc{F}^1}}
%^{{\rm min}}}
\newcommand{\barqmin}{{\rm \overline{C}}{\rm orner}^{\mfl,\mc{F}^1}}
%^{{\rm min}}}
\newcommand{\test}{T}
\newcommand{\mfl}{\ell}
\newcommand{\mfr}{r}
\newcommand{\gfl}{\ell}
\newcommand{\gfr}{r}
\newcommand{\jre}{J}
\newcommand{\highfl}{{\rm HFL}}
\newcommand{\flyleap}{\mathsf{FlyLeap}}
\newcommand{\touch}{\mathsf{Touch}}
\newcommand{\notouch}{\mathsf{NoTouch}}
\newcommand{\close}{\mathsf{Close}}
\newcommand{\boxclose}{\mathsf{BoxClose}}
\newcommand{\abovepar}{\mathsf{High}}
\newcommand{\vecint}{\bar{\iota}}
\newcommand{\cornthree}{{\rm Corner}^\mc{G}_{k,\mfl}}
\newcommand{\cornfour}{{\rm Corner}^\mc{H}_{k,\fa}}
\newcommand{\mpgg}{\mathsf{Fav}_{\mc{G}}}
%\newcommand{\cornthree}{\llcorner^\mc{G}_{k,\mfl}}



\newcommand{\lefta}{{\rm SideLeft}}
\newcommand{\righta}{{\rm SideRight}}
\newcommand{\mida}{{\rm Middle}}
\newcommand{\xnmac}{z_n}
\newcommand{\cdor}{{\rm C}}
\newcommand{\alphapr}{\alpha'}
\newcommand{\betapr}{\beta'}
\newcommand{\barqpr}{\bar{q}'}
\newcommand{\pspr}{\pairsep_{\alphapr,\betapr,\barqpr}}

%\newcommand{\lefta}{M_{1,k+1}^{[-2\eln,\gfl]}}
%\newcommand{\mida}{M_{1,k+1}^{[\gfl,\gfr]}}
%\newcommand{\righta}{M_{1,k+1}^{[\gfr,2\eln]}}


\newcommand{\wien}{W}
\newcommand{\pole}{P}
\newcommand{\pp}{p}

\newcommand{\maxpoly}{\mathrm{MaxDisjtPoly}}



\newcommand{\low}{\mathsf{Low}}
\newcommand{\nolow}{\mathsf{NoLow}}
\newcommand{\up}{\mathsf{Up}}
\newcommand{\neargeod}{\mathsf{NearGeod}}
%dropbox test

\newcommand{\lshift}{\mc{L}^{\rm shift}}

\newcommand{\const}{D_k}
\newcommand{\numcone}{14}
\newcommand{\numctwo}{13}
\newcommand{\numcthree}{4}
\newcommand{\cone}{c_1}
\newcommand{\Cone}{C_1}
\newcommand{\rsC}{C}
\newcommand{\rsc}{c}
\newcommand{\ctemp}{d_0}
\newcommand{\smallc}{c_0}
\newcommand{\smallcprime}{c_1}
\newcommand{\smallcanother}{c_2}
\newcommand{\smallcnew}{c_3}
\newcommand{\rcon}{r_0}
\newcommand{\Cstrong}{E}
\newcommand{\formerE}{C}
\newcommand{\Chat}{\hat{C}}
\newcommand{\Cwb}{K}
\newcommand{\constnew}{\gamma_k}


\newcommand{\dist}{\vert\vert}
\newcommand{\fik}{\mc{F}_i^{[0,\ipdval]^c}}
\newcommand{\mcfa}{\mc{H}[\fa]}
\newcommand{\tent}{{\rm Tent}}
\newcommand{\goodk}{\mathsf{G}_{0,\ipdval}}
\newcommand{\pairsep}{{\rm PS}}
\newcommand{\mbf}{\mathsf{MBF}}
\newcommand{\nbd}{\mathsf{NoBigDrop}}
\newcommand{\bd}{\mathsf{BigDrop}}
\newcommand{\jleft}{j_{{\rm left}}}
\newcommand{\jright}{j_{{\rm right}}}
\newcommand{\smalljfluc}{\mathsf{SmallJFluc}}
\newcommand{\mfone}{M_{\mc{F}^1}}
\newcommand{\mfthree}{M_{\mc{G}}}
\newcommand{\fev}{\mathsf{F}}

\newcommand{\para}{Q}
\newcommand{\ipd}{1}
\newcommand{\ipdval}{1}
\newcommand{\deltamac}{\zeta}
\newcommand{\deltapi}{\theta}
\newcommand{\emac}{\eta}
\newcommand{\grabell}{\rho}

\newcommand{\staircase}{SC}
\newcommand{\coninit}{\Psi}
\newcommand{\initcond}{\mathcal{I}}
\newcommand{\maxmin}{\pwr}


%\newcommand{\xnmac}{z_{\mathcal{L}}}
\newcommand{\nmac}{n}

\newcommand{\rmreg}{{\rm Reg}}


\newcommand{\boundgood}{\mathsf{G}}


\newcommand{\intnonint}{\mathsf{NI}_n^{\rm int}}
\newcommand{\extnonint}{\mathsf{NI}_n^{\rm ext}}
\newcommand{\nonint}{\mathsf{NI}}

\makeatletter
\newsavebox\myboxA
\newsavebox\myboxB
\newlength\mylenA

\newcommand*\xoverline[2][0.75]{%
    \sbox{\myboxA}{$\m@th#2$}%
    \setbox\myboxB\null% Phantom box
    \ht\myboxB=\ht\myboxA%
    \dp\myboxB=\dp\myboxA%
    \wd\myboxB=#1\wd\myboxA% Scale phantom
    \sbox\myboxB{$\m@th\overline{\copy\myboxB}$}%  Overlined phantom
    \setlength\mylenA{\the\wd\myboxA}%   calc width diff
    \addtolength\mylenA{-\the\wd\myboxB}%
    \ifdim\wd\myboxB<\wd\myboxA%
       \rlap{\hskip 0.5\mylenA\usebox\myboxB}{\usebox\myboxA}%
    \else
        \hskip -0.5\mylenA\rlap{\usebox\myboxA}{\hskip 0.5\mylenA\usebox\myboxB}%
    \fi}
\makeatother






\title[Local random growth and Gibbs resamplings]{Minerva Lectures: Universality in models of local random growth via Gibbs resamplings}



\author[A. Hammond]{Alan Hammond}
\address{A. Hammond\\
  Departments of Mathematics and Statistics\\
 U.C. Berkeley \\
  899 Evans Hall \\
  Berkeley, CA, 94720-3840 \\
  U.S.A.}
  \email{alanmh@berkeley.edu}



\begin{abstract} 
An important technique for understanding a random system is to find a higher dimensional random system that enjoys an attractive and tractable structure and that has the system of interest as a marginal; and to analyse the new structure to make inferences about the original system. For example, the Airy$_2$ process is an important and natural random process, mapping the real line to itself, since it offers, rigorously in certain examples and putatively in very many more, a scaled description at advanced time of a random interface whose growth is stimulated by local randomness and which is subject to restoring forces such as surface tension. The Airy$_2$ process may be embedded in a canonical way as the uppermost curve in a richer random object, the Airy line ensemble - an ordered system of random continuous curves. This richer object has an attractive probabilistic property not apparent in the Airy$_2$ process itself - it is, with suitable boundary conditions, an infinite system of mutually avoiding Brownian motions; and, as such, it enjoys a natural resampling probability called the Brownian Gibbs property. The Brownian Gibbs property of the Airy line ensemble is a key probabilistic technique by which aspects of the concerned Kardar-Parisi-Zhang universality class of random growth models may be investigated. This short series of lectures will explain how, harnessed with limited but essential inputs of integrable origin, the property has been exploited in the recent work~\cite{BrownianReg} to make very strong inferences regarding the locally Brownian nature of the Airy$_2$ process; about the scaled coalescence behaviour of geodesics in last passage percolation growth models; and about the structure of the scaled interface when these models are initiated from very general initial conditions.
%\vspace{-2.5mm}
%In last passage percolation models lying in the KPZ universality class, the energy of long energy-maximizing paths may be studied as a function of the paths' pair of endpoint locations.
%Scaled coordinates may be introduced, so that these maximizing paths, or polymers, now cross unit distances with unit-order fluctuations, and have scaled energy, or weight, of unit order. In this article, we consider Brownian last passage percolation in these scaled coordinates.
%In the narrow wedge case, one endpoint of such polymers is fixed, say at $(0,0) \in \R^2$, and the other is varied horizontally, over $(z,1)$, $z \in \R$, so that the polymer weight profile is a function of $z \in \R$. This profile  is known to manifest a one-half power law, having $1/2-$-H\"older continuity. The polymer weight profile may be defined beginning from a much more general initial condition.
%In this article, we present a more general assertion of this one-half power law, as well as a bound on the poly-logarithmic correction. The polymer weight profile admits a modulus of continuity of order $x^{1/2} \big( \log x^{-1} \big)^{2/3}$, with 
%a high degree of uniformity in the scaling parameter and over a very broad class of initial data.  
\end{abstract}


\maketitle



\vspace{5mm}

\tableofcontents

\chapter{Polynuclear growth: multi-line PNG and non-intersecting random walks}


In Poissonian last passge percolation, a Poisson point process~$\mc{P}$ of unit intensity is sampled in the cone $C = \big\{ (x,t) \in \R \times [0,\infty): \vert x \vert  \leq t \big\}$.

The RSK dynamics for the polynuclear growth [PNG] model are determined by~$\mc{P}$. 
The dynamics begins at time zero in an initial confiugartion of lines $L_i = \R \times \{ i \}$ indexed by the negative integers~$-\N$ including zero. 

In the Poisson space, the horizontal line $\{ y=t \}$ rises at unit speed from its initial position along the $x$-axis. When it first encounters an element~$(x,t)$ of $\mc{P}$, a nucleation occurs on the uppermost line~$L_0$ in the line space: at time~$t$, the flat line $L_0 = \R \times \{ 0 \}$ is altered at spatial location $x$ so that it adopts the value one there. The deformation may be viewed as a $+1$ jump in the interface followed immediately by a~$-1$ jump. As time evolves from~$t$, the time-level continues to rise in the Poisson picture. In the line space, the up-jump and the down-jump in $L_0$ travel at velocities of $-1$ and $+1$, so that the interval of values at which $L_0$ equals one takes the form $\big( x- (t' - t),x+ (t' -t) \big)$ for $t' > t$.

When the second Poisson point is encountered by the rising time line, a corresponding nucleation occurs in $L_0$ in the line space, and the left and right sides of the resulting deformation proceed again at velocities of minus one and plus one. This nucleation may occur when $L_0$ has height one or zero; in either case, the nucleation is built at unit height on top of the existing interface.
Every Poisson points nucleates on the curve $L_0$ when its time comes.

At some moment, a right-advancing downstep will collide with a left-advancing upstep in $L_0$. At this instant, the two interfaces annihilate in $L_0$, so that immediately after, $L_0$ locally takes the form of the shared constant value for this line, on the left of the right-advancing downstep and the right of the left-advancing upstep at the moment of collision. However, infromation is not lost, because at this same instant, a nucleation event occurs on the line~$L_1$ at the location of the collision. The usual rules for the subsequent evolution of the nucleated deformation are at play, with the upstep and the downstep in $L_1$ spreading away at unit speed from their shared location at the collision time. 

The process continues, with each Poisson point being responsible for a nucleation in the uppermost curve~$L_0$, the collisions between upstep-downstep pairs giving rise to nucleation in the line whose index is one greater than that in which the collision occurred. Collisions and nucleations spread over a broadening range, both in the spatial and line index sense, as time advances.

Consider given time $t \geq 0$ in the Poisson picture. The time-line intersects the cone~$C$ along $[-t,t] \times \{ t \}$. Let $\bf{x}$ denote a point in the intersection, and write $\bf{0} = (0,0)$ for the origin in the plane, which is the apex of~$C$. An {\em upgoing} path from $\bf{0}$ to $\bf{x}$ is formed from a finite collection of planar line segments, each of which makes an angle with the vertical of at most one-half of a right angle.  In this way, a journey from ${\bf 0}$ to ${\bf x}$ made along an upgoing path is one in which the traveller moves in straight line segments, always adopting a compass direction that is at least as northerly as $NW$ or $NE$, with a change of direction permitted on finitely many occasions.
Note that an upgoing path from $\bf{0}$ to $(x,t)$ exists precisely when $\vert x \vert \leq t$, at points where the time-line meets the cone.

For $x \in \R$, let $h(x,t)$ denote the maximum number of elements of the Poisson cloud~$\mc{P}$ that lie on an upgoing path between $\bf{0}$ and $(x,t)$. If no upgoing path exists due to $\vert x \vert > t$, $h(x,t) = 0$ is understood.
The profile $\R \to \N: x \to h(x,t)$ is known as the PNG interface.

For $j \in \N$, we may define 
\begin{eqnarray*}
 D_j(x,t) & = & \bigg\{ (\phi_1,\cdots,\phi_j): \phi_i \, \, \, \textrm{an upgoing path from $(0,0)$ to $(x,t)$}, \, \, \, i \in \intint{j} \\ 
 & &  \qquad \qquad \textrm{with the $\phi_i$ pairwise disjoint, except at $(0,0)$ and $(x,t)$}  \bigg\} \, .
\end{eqnarray*}
Define the length $\ell(\phi)$ of $\phi \in D_1(x,t)$ to be the number of Poisson points visited by~$\phi$.
Extend the notation to $D_j(x,t)$ by setting
$$
 \ell \big( (\phi_1,\cdots,\phi_j) \big) \, = \, \sum_{i=1}^j \ell(\phi_i) \, \, \, \, \textrm{for $(\phi_1,\cdots,\phi_j) \in D_j(x,t)$} \, .
$$
Now set 
$$
 M_j(x,t) = \max \Big\{ \ell(\phi): \phi \in D_j(x,t) \Big\} \, .
$$
\begin{proposition}
For $j \in \N$ and $(x,t) \in \R \times [0,\infty)$, we have that
$$
 \sum_{i=0}^{j-1} \big(  L_{-i}(x,t) + i \big) \, = \, M_j(x,t) \, .
$$ 
\end{proposition}

\begin{definition}
Let $\lambda \in (0,\infty)$.
\begin{enumerate}
\item A continuous-time simple random walk of rate~$\lambda$ is a Markov process $X:[0,\infty) \to \Z$, $X(0) = n$,
whose jump times are a Poisson process of rate~$\lambda$, at each of which occur moves up, by~$+1$, or down, by~$-1$, according to the independent flip of a fair coin.
\item Let $x_1,x_2 \in \R$ satisfy $x_1 \leq x_2$, and let $k,\ell \in \Z$. A continuous-time simple random bridge on $[x_1,x_2]$, with starting and ending locations $k$ and $\ell$,
has the law of CTSRW $X:[x_1,x_2] \to \Z$, $X(x_1) = k$, conditioned on $X(x_2) = \ell$.
\end{enumerate}
\end{definition}
{\bf Non-intersecting walks.}
Two $\Z$-indexed walks $X_1$ and $X_2$ defined on a common real interval~$I$ are non-intersecting if $X_1(x) \not= X_2(x)$ for all $x \in I$.
Note that CTSRWs that are non-intersecting are ordered: if $X_1$ exceeds $X_2$ at one point in the common domain of definition~$I$, then this bound holds at all points in~$I$.


Let $n \in \N$ and $T > 0$. Let $\PP_{n,T}$ denote the law of $n$ independent rate-$2$ CTSRWs $X_{-i}:[-T,T] \to \Z$, $X_{-i}(-T) = -i$ indexed by $i \in \llbracket 0,n-1 \rrbracket$.
The return event $R_{n,i}$ equals $X_{-i}(T) = -i$. Set $R_n = \bigcap_{i=0}^{n-1}R_{n,i}$. Internal non-intersection is the event
$$
 \intnonint = \big\{ X_{-i}, i \in \llbracket 0,n-1 \rrbracket, \, \, \, \textrm{are mutually non-intersecting} \big\} \, .
$$
External non-intersection is 
$$
\extnonint = \big\{  X_{1-n}(x) \geq -n \, \, \textrm{for all $x \in [-T,T]$} \big\} \, .
$$
Set $\nonint = \intnonint \cap \extnonint$.


Let the deepest index $D(T)$ denote the maximum index $i \geq 0$ such that the line $L_{-i}$ has been deformed from its original constant value of $-i$ at time $T \geq 0$.
\begin{proposition}\label{p.rni}
Write $\Q$ for the Poisson randomness.
For $n \in \N$ and $T \in [0,\infty)$,
$$
\PP_{n,T}( R \cap  \nonint ) = \exp \big\{ T(T-4n) \big\} \Q\big( D(T) \leq n \big) \, .
$$
\end{proposition}
{\bf Proof.}
Consider the {\em flat} outcome $F$ under $\PP_{n,T}$, under which the line $L_{-i}$ is identically equal to~$-i$ for every $i \in \llbracket 0, n-1\rrbracket$.

Note that $\PP_{n,T}\big( \cdot \big\vert R \cap \nonint \big)$ is measure-isomorphic to the space $\Q$ given $D(T) \leq n$. The flat outcome corresponds to an absence of Poisson points in the cone $C$ up to height~$T$. Hence,
$$
 \PP_{n,T}(F) \, = \, \frac{e^{-T^2}}{\Q \big( D(T) \leq n \big)} \, .
$$
We see then that
 $$
  \frac{e^{-4nT}}{\PP_{n,T}(R \cap \nonint)}  \, = \, \frac{e^{-T^2}}{\Q \big( D(T) \leq n \big)} \, ,
 $$
 which rearranges to give the sought statement. \qed

Consider a configuration $X$ of the Poisson cloud in the cone up to height~$t$.
An element in $X$ takes the form of an unordered set
$$
 \big\{ (x_1,t_1), (x_2,t_2) \cdots, (x_m,t_m)  \big\}
$$
where $m \in \N$ and for each $i \in \intint{m}$, $t_i \in [0,T]$ with $\vert x_i \vert  \leq t_i$.

Let $Y$ denote the collection of finite sets whose elements are ordered pairs $(z,z')$ satisfying $-T \leq z < z' \leq T$.
Say that $y=\{(z_i,z_i')\}_{i=1}^m\in Y$ is \emph{nonsingular} if all of the $2m$
numbers $z_1,z_1',\dots,z_m,z_m'$ are distinct.
Write $Y^{\rm ns}\subset Y$ for the set of nonsingular configurations.

Define a map $\tau:X \to Y$ by
$$
 \big\{ (x_1,t_1), (x_2,t_2) \cdots, (x_m,t_m)  \big\} 
 \mapsto  
 \big\{ (x^-_1,x_1^+), 
 (x^-_2,x^+_2) \cdots, (x^-_m,x^+_m)  \big\}
$$
where $x_i^- = x_i - (T-t_i)$ and $x_i^+ = x_i + (T - t_i)$.



Let $\mc{P}_t$ denote the set of Poisson points of height at most $t \geq 0$.
For $x \in \mc{P}_t$, write $\mc{P}_t(x) = \mc{P}_t \setminus \{ x\}$ for this cloud with the point~$x$ removed.

For such $x$, write 
$$
 D(x^\pm) = \min \Big\{ k \geq 1: M_k^{\mc{P}_t} \big( (0,0) \to (x_\pm,t) \big) >  M_k^{\mc{P}_t(x)} \big( (0,0) \to (x_\pm,t) \big) \Big\}
$$

The RSK dynamics offers a bijection between cloud configurations in the up-to-time-$t$ cone $C_t$
and non-intersecting line configurations on $[-t,t]$. To each cloud, we run the RSK dynamics for time $t$ to construct the line configuration. For a given line configuration, we run the dynamics backwards for time~$t$, recording a point in the cloud on the descending time-line at the spatial location at which each nucleation is encountered.

Viewed in terms of suitable Poisson laws, the bijection is measure preserving. The cloud space~$C_t$ already comes accompanied with a natural Poisson measure~$\Q$, whose intensity we take equal to the constant two. It is natural to consider the line side of the story by introducing a natural Poisson measure on lines. For this purpose, we may begin with the walk measures.

Let $n \in \N \cup \{ \infty \}$.
Under the time-$T$ $n$-line walk measure $\PP^w_n(T)$, the $i$\textsuperscript{th} line $L_{1-i}:[-T,T] \to \Z$ is an independent rate-two CTSRW mapping $[-T,T] \to \Z$ with starting position $L_{1-i}(-T) = 1-i$.
When $n$ is finite, the lines $L_{1-i}$ indexed by $i \geq n+1$ are static, identically equal to $1-i$ on their domain of definition $[-T,T]$.

The measure $\PP^w_\infty(T)$ charges the full space of non-intersecting line configurations, which is in natural correspondence with the space of finite clouds in~$C_t$. However, for the purpose of analysing Poisson measures on the line space, and compare them to counterparts in the cloud space, it is useful to work with the finite-$n$ walks measures  $\PP^w_n(T)$. 

Take $n \in \N$ finite then, as well as $T > 0$. A non-intersecting $(n,T)$-line configuration is called {\em proper} if the steps in each line $L_{1-i}$, $i \in \intint{n}$, have unit magnitude and occur at distinct locations in $[-T,T]$. Let $\epsilon_0 > 0$ denote one-half of the minimum distance between consecutive entries in any of the lists $(-T,j_{i,1},\cdots,j_{i,k_i} ,T))$ indexed by $i \in \intint{n}$. Here, $\big( j_{i,k}: k \in \intint{k_i} \big)$ is an increasing list of the jumps of the line $L_{1-i}$.

Taking $\epsilon \in (0,\epsilon_0)$, consider the $\epsilon$-box $B(L,\epsilon)$ about the configuration $L$.
A line configuration~$L'$ lies in this box if its set of upsteps and downsteps is in correspondence with those of $L$ in such a way that every upstep in $L$ corresponds to an upstep in $L'$ on the same line whose location differs by at most $\epsilon$; and likewise for every downstep.

A small $\epsilon$ asymptotic for the probability of $B(L,\epsilon)$ is easily seen given the Poisson nature of the law $\PP_n^w(T)$: we have
$$
  \PP_{n,T}^w \big( B(L,\epsilon) \big) =   \exp \big\{ -4nT \big\} (2\e)^{2m} \Big( 1 + o(1) \Big)
$$
as $\epsilon \searrow 0$, where $2m$ is the number of steps in~$L$. Indeed, we may compute
 $$
 \PP_{n,T}^w \big( B(L,\epsilon) \big) =   \Big( \tfrac{1}{2} \cdot 4\epsilon \Big)^{2m} \exp \big\{ - (4nT - 2\epsilon \cdot 2m) \big\} \, ,
$$
where each factor of $4\epsilon$ corresponds to the presence of a rate-two Poisson point in each of the length-$2\epsilon$ intervals in the lines centred at steps, and each factor of one-half corresponds to the correct selection up/down for the step according to the flip of a fair coin; the exponential factor factor represents the absence of steps in the remaining part of the $n$-line space according to the Poisson rate-two measure.

The probabilities on display decay very rapidly as $n$ rises. This is largely due to the improbability that each of the $n$ walks is a bridge (whose starting and ending heights coincide)
and that the concerned walks remain non-intersecting. These attributes obtain for any configuration realizing  $B(L,\epsilon)$, and this fact permits us to translate the obtained asymptotic into one concerning the $n$-line non-interacting bridge measure, simply by division by the requiste probability  $\PP_{n,T}^w \big( R \cap \nonint \big)$. Indeed, with the notation
$\PP_{n,T}^\ell$ for the $n$-line measure given by conditioning $\PP_n^w$ on the event $R \cap \nonint$, we find that
\begin{equation}\label{e.line}
 \PP_{n,T}^\ell \big( B(L,\epsilon) \big) =   \frac{\big( 2 \epsilon \big)^{2m} \exp \big\{ - (4nT - 2\epsilon \cdot 2m) \big\}}{\PP_{n,T}^w \big( R \cap \nonint \big)} \, ,
\end{equation}




The box $B(L,\epsilon)$ corresponds to a box in cloud space. Let $\omega$ denote the cloud in $C_T$ to which the line configuration $L$ corresponds. For each point $(z_1,z_2) \in \R^2$,
write $D(z_1,z_2,\epsilon)$ for the diagonally oriented box of width~$2\epsilon$ whose centre is $(z_1,z_2)$. For $\epsilon \in (0,\epsilon_0)$ as specified above, it is straightforward to see that 
the collection of squares $D(\omega_i,\epsilon)$, $i \in \intint{m}$, is disjoint. Let $\mathsf{B}(\omega,\epsilon)$ denote the event that the Poisson cloud in $C_t$ under $\Q$
has $m$ points, with each square  $D(\omega_i,\epsilon)$ containing exactly one point.
It is straightforward that the event  $\mathsf{B}(\omega,\epsilon)$  corresponds to  $B(\omega,\epsilon)$ under the cloud-line correspondence.

We may perform a counterpart Poisson calculation for the probability of $\mathsf{B}(\omega,\epsilon)$ in cloud space, as we did for $B(\omega,\epsilon)$ in line-space:
we find that
\begin{equation}\label{e.cloud}
\Q \big( \mathsf{B}(\omega,\epsilon) \big) = \exp \big\{ - T^2 \big\} (2\epsilon)^{2m} \Big( 1 + o(1) \Big)
\end{equation}
as $\epsilon \searrow 0$. Indeed, each square lands a cloud point with asymptotic probability $(2\epsilon)^{2m}$, while the non-square part of $C_t$ is devoid of Poisson points with probability $\exp \big\{  - (T^2 - m(2\epsilon)^2 )\big\}$.

The line~(\ref{e.line}) and cloud~(\ref{e.cloud}) expressions run in close parallel, but the correspondence is imperfect.
The line side of the picture has been restricted to configurations in which only the top $n$ lines are permitted to move, in order to permit Poisson calculations, but this restriction means that the admissible configurations correspond to only part of the cloud space. Which part? 
A cloud~$\omega$ is in correspondence if and only if its depth $D(T) = D_T(\omega)$ is at most $n$. Here, the notion of depth is represented in the cloud space, even if our definition was made in line-space: the depth of a cloud configuration is the depth of the corresponding line configuration.
We find then that
$$
\PP_{n,T}^\ell \big( B(L,\epsilon) \big) =  \frac{\Q \big( \mathsf{B}(\omega,\epsilon) \big)}{\Q \big( D(\omega) \leq n \big)} \, .
$$
From~(\ref{e.line}) and~(\ref{e.cloud}), we find then that
$$
\exp \big\{ - 4nT \big\} \Q \big( D(\omega) \leq n \big) = \exp \big\{ - T^2 \big\} {\PP_{n,T}^w  \big( R \cap \nonint \big)} \, .
$$
Rearranging this identity, we obtain Proposition~\ref{p.rni}.

  \section{Chatgpt input for debatable bits in the preceding}



% --------------------------------------------------------------------
% Detachable Piece A: deterministic bijection (forward/backward PNG/RSK)
% --------------------------------------------------------------------

\medskip

\subsection*{A deterministic cloud--line correspondence}\label{s.det-bijection}

We now make precise (at the deterministic level) the correspondence between
finite point configurations in the cone $C_T$ and multi-line PNG configurations
at the fixed time~$T$.  Throughout, we work on a \emph{nonsingular} set where no
two relevant events occur at the same space--time location; this eliminates
tie-breaking issues and is the natural setting for the local ``$\e$-box''
arguments used later.

\paragraph{Proper line configurations at time $T$.}
Fix $T>0$.
A \emph{proper time-$T$ line configuration} is a sequence of functions
$\{L_{-i}(\cdot,T)\}_{i\ge 0}$ on $[-T,T]$ such that
\begin{enumerate}
\item each $L_{-i}(\cdot,T)$ is integer-valued, c\`adl\`ag, and piecewise constant
with jumps of magnitude $\pm1$ only;
\item all jump locations (across all curves) are distinct points of $(-T,T)$;
\item for all sufficiently large $i$ (depending on the configuration),
$L_{-i}(\cdot,T)\equiv -i$ (only finitely many lines are active);
\item the non-intersection constraint holds:
$$
L_{-i}(x,T) \ge L_{-(i+1)}(x,T)+1 \qquad \text{for all $x\in[-T,T]$ and $i\ge 0$}.
$$
\end{enumerate}
Write $\mc L_T^{\rm prop}$ for the set of such configurations.

\paragraph{Proper point configurations.}
Let $\Omega_T$ denote the set of finite subsets $\omega\subset C_T$.
We call $\omega$ \emph{proper} if no two points share the same $t$--coordinate
and if, under the forward PNG dynamics described below, no two annihilations
occur at the same space--time point.  (This holds $\Q$-a.s.\ for a Poisson cloud.)
Write $\Omega_T^{\rm prop}\subset \Omega_T$ for this set.

\paragraph{Forward map: cloud $\to$ lines.}
Given $\omega\in\Omega_T^{\rm prop}$ we construct a multi-line PNG evolution on
$[0,T]$ as follows.

\smallskip

\noindent
\textbf{Initialization.}  Set $L_{-i}(x,0)\equiv -i$ for all $i\ge 0$.

\smallskip

\noindent
\textbf{Deterministic evolution between events.}
Between event times, each curve $L_{-i}(\cdot,s)$ evolves by
propagating its upsteps left with velocity $-1$ and its downsteps right
with velocity $+1$.

\smallskip

\noindent
\textbf{Nucleations at Poisson points.}
When the time level reaches a point $(x_0,t_0)\in\omega$,
insert at level $0$ a unit ``spike'' at $x_0$:
equivalently, create an upstep and a downstep in $L_0(\cdot,t_0)$ at the same
spatial location $x_0$.

\smallskip

\noindent
\textbf{Annihilation and induced lower nucleation.}
Whenever (at some level $-i$) a right-moving downstep meets a left-moving upstep,
the two steps annihilate at that space--time point, and simultaneously a new
nucleation is created at level $-(i+1)$ at the same space--time location.

\smallskip

\noindent

Because $\omega$ is proper, all nucleation and annihilation events
occur at distinct space--time locations.
Between such events the dynamics is deterministic,
and at each event there is a unique local update to perform.
Consequently the forward evolution is well posed up to time $T$,
and yields a proper time-$T$ line configuration,
which we denote by $\Phi_T(\omega)$.


\paragraph{Backward map: lines $\to$ cloud.}
Conversely, given $L\in\mc L_T^{\rm prop}$ we reconstruct a point set
$\omega\subset C_T$ by running the same rules backwards in time.
Between event times, steps move with the reversed velocities
(upsteps move right, downsteps move left).
Whenever, at some level $-i$, an upstep and downstep \emph{collide} backwards in time
(i.e.\ they were created by a nucleation forwards in time), we remove this pair
from level $-i$, and simultaneously create a pair of opposite steps at level $-(i-1)$
at the same space--time location; when $i=0$ we instead \emph{record} that
space--time location as an element of the reconstructed cloud.
Properness guarantees that this reverse evolution is unambiguous and terminates
after finitely many events, yielding a finite set of recorded points in $C_T$.
We denote the reconstructed point set by $\Psi_T(L)$.

\begin{proposition}[Deterministic bijection]\label{p.det-bijection}
For each $T>0$, the maps
$$
\Phi_T:\ \Omega_T^{\rm prop}\to \mc L_T^{\rm prop},
\qquad
\Psi_T:\ \mc L_T^{\rm prop}\to \Omega_T^{\rm prop},
$$
defined above are well posed and inverse to one another.  In particular,
$\Phi_T$ is a bijection between proper point configurations in the cone up to time~$T$
and proper time-$T$ multi-line PNG configurations on $[-T,T]$.
\end{proposition}

\begin{proof}
We sketch the argument, since it is a deterministic bookkeeping statement once the
forward/backward rules are fixed.

\smallskip

\noindent
\emph{Well-posedness.}
Properness ensures that event times (nucleations and annihilations) are discrete,
that between events all step locations evolve linearly with the prescribed velocities,
and that at an event there is a unique local update to perform
(annihilate exactly one meeting pair, and create exactly one induced nucleation one level below).
Thus $\Phi_T(\omega)$ is well defined and produces a proper time-$T$ configuration.
The same reasoning applies to the reverse evolution defining $\Psi_T(L)$.

\smallskip

\noindent
\emph{Inverse property.}
Consider $\omega\in\Omega_T^{\rm prop}$ and run the forward evolution to time $T$,
obtaining $L=\Phi_T(\omega)$.  In the forward dynamics, each local event is of one of two types:
a nucleation on level $0$ (coming from a point of $\omega$) or an annihilation on level $-i$
with an induced nucleation on level $-(i+1)$.
By construction, the backward dynamics performs the exact inverse local move at the same
space--time location: it undoes each annihilation/induced-nucleation pair, and when it reaches
a level-$0$ nucleation event it records the corresponding space--time point.
Since the forward dynamics is deterministic given $\omega$, and properness prevents ambiguity,
running backwards from $L$ recovers exactly the original set of level-$0$ nucleation events,
namely the points of $\omega$.  Hence $\Psi_T(\Phi_T(\omega))=\omega$.
The same argument in reverse shows $\Phi_T(\Psi_T(L))=L$ for $L\in\mc L_T^{\rm prop}$.
\end{proof}

\begin{remark}[Relation to RSK and ``depth'']\label{r.det-bijection-rsk}
The map $\Phi_T$ is the multi-line PNG/RSK correspondence in geometric form:
the full line ensemble encodes the point configuration, while the top curve
$L_0(\cdot,T)$ encodes last-passage values.  In particular, the depth event
$\{D(T)\le n\}$ is the same as the deterministic constraint that
$L_{-(n+1)}(\cdot,T)\equiv -(n+1)$, i.e.\ that no event ever propagated below level~$-n$
up to time~$T$.
\end{remark}


% --------------------------------------------------------------------
% Detachable Piece B: Local epsilon-box correspondence
% --------------------------------------------------------------------

\medskip

\subsection*{Local $\epsilon$-box correspondence}\label{s.local-box}

We now justify rigorously the correspondence between small neighbourhoods
of a proper line configuration and small neighbourhoods of its
corresponding cloud under the deterministic bijection
$\Phi_T$ of Proposition~\ref{p.det-bijection}.

\paragraph{Proper configurations.}
Fix $T>0$.  Let $L\in\mc L_T^{\rm prop}$ be a proper time-$T$
line configuration with finitely many jumps.
Let $\omega=\Psi_T(L)$ denote the corresponding cloud in $C_T$.

Let the set of jump locations of $L$ be
\[
\{z_1^-,z_1^+,\dots,z_m^-,z_m^+\},
\]
where $z_i^-$ and $z_i^+$ denote the spatial locations of the upstep and
downstep induced by the $i$th Poisson point.

Properness implies that these $2m$ locations are all distinct.
Define
\[
\epsilon_0
=
\frac12 \min\Big(
\{ |z_a^\sigma-z_b^\tau| : (a,\sigma)\neq (b,\tau)\}
\cup
\{|z_a^\sigma\pm T|\}
\Big),
\]
so that the intervals
$[z_i^\pm-\epsilon_0,z_i^\pm+\epsilon_0]$
are disjoint and contained in $(-T,T)$.

\paragraph{Line $\epsilon$-box.}
For $\epsilon\in(0,\epsilon_0)$ define $B(L,\epsilon)$ to be the set of
proper line configurations $L'$ such that:
\begin{enumerate}
\item $L'$ has the same number of jumps on each line as $L$;
\item each upstep (respectively downstep) of $L$ corresponds to an upstep
(respectively downstep) of $L'$ on the same curve whose location differs
by at most $\epsilon$.
\end{enumerate}

\paragraph{Cloud $\epsilon$-box.}
For each point $\omega_i=(x_i,t_i)\in\omega$, define
\[
D(\omega_i,\epsilon)
=
\big\{ (x,t)\in\R^2:
|x-x_i|\le \epsilon,\ |t-t_i|\le \epsilon \big\}.
\]
For $\epsilon\in(0,\epsilon_0)$ define $\mathsf B(\omega,\epsilon)$
to be the event that:
\begin{enumerate}
\item the cloud contains exactly $m$ points in $C_T$;
\item for each $i\in\{1,\dots,m\}$,
the region $D(\omega_i,\epsilon)$ contains exactly one point;
\item no other points of the cloud lie in $C_T$.
\end{enumerate}

\begin{lemma}[Local correspondence]\label{l.local-box}
Let $L\in\mc L_T^{\rm prop}$ and $\omega=\Psi_T(L)$.
For $\epsilon\in(0,\epsilon_0)$ sufficiently small,
the deterministic bijection $\Phi_T$ restricts to a bijection
\[
\Phi_T:\ \mathsf B(\omega,\epsilon)
\longrightarrow
B(L,\epsilon).
\]
In particular, under the cloud--line correspondence,
small perturbations of point locations correspond exactly to small
perturbations of jump locations, with no change in combinatorial structure.
\end{lemma}

\begin{proof}
Because $\epsilon<\epsilon_0$, the regions
$D(\omega_i,\epsilon)$ are disjoint.
Thus every cloud configuration in $\mathsf B(\omega,\epsilon)$
consists of exactly one point in each such region,
and no other points.

Under the forward PNG dynamics, each Poisson point in
$D(\omega_i,\epsilon)$ produces exactly one nucleation event,
and the space--time location of this nucleation is perturbed by
at most $\epsilon$ from its original location.
Since all event times and annihilations are separated by at least
$2\epsilon_0>2\epsilon$, the relative ordering of all nucleations
and annihilations is unchanged.

Hence:
\begin{itemize}
\item the number of jumps on each line remains the same,
\item each jump location shifts by at most $\epsilon$,
\item no new collisions or reorderings occur.
\end{itemize}

Therefore $\Phi_T$ maps $\mathsf B(\omega,\epsilon)$
into $B(L,\epsilon)$.

Conversely, given $L'\in B(L,\epsilon)$,
running the backward dynamics produces exactly one point in each
$D(\omega_i,\epsilon)$ and no others,
since the combinatorial structure of annihilations is unchanged.
Thus $\Psi_T(L')\in\mathsf B(\omega,\epsilon)$.

The two maps are inverses on these restricted sets,
completing the proof.
\end{proof}

% --------------------------------------------------------------------
% Detachable Piece C: Poisson epsilon-box asymptotics in cloud space
% --------------------------------------------------------------------

\medskip

\subsection*{Poisson $\epsilon$-box asymptotics in the cone}\label{s.poisson-box}

We record the standard local asymptotics for Poisson point processes that
underlie the cloud-side computation in~\eqref{e.cloud}.
We state the result in the generality needed for the ``diagonal boxes''
(or any family of disjoint measurable sets of small area).

\begin{lemma}[Poisson counts in disjoint small sets]\label{l.poisson-small-sets}
Let $\mc P$ be a Poisson point process on a measurable set $S\subset\R^2$
of finite area $|S|$, with constant intensity $\lambda>0$.
Let $A_1,\dots,A_m\subset S$ be pairwise disjoint measurable sets, and
set $A_\star:=\bigcup_{i=1}^m A_i$.
Then
\begin{equation}\label{e.poisson-exact}
\Q\Big(
\#(\mc P\cap A_i)=1\ \text{for all $i\le m$},\ \ 
\#(\mc P\cap (S\setminus A_\star))=0
\Big)
=
e^{-\lambda|S|}\,
\prod_{i=1}^m \big(\lambda |A_i|\big).
\end{equation}
\end{lemma}

\begin{proof}
For disjoint sets, the Poisson counts
$\#(\mc P\cap A_1),\dots,\#(\mc P\cap A_m),\#(\mc P\cap (S\setminus A_\star))$
are independent, with respective laws
$\mathrm{Pois}(\lambda|A_i|)$ and $\mathrm{Pois}(\lambda|S\setminus A_\star|)$.
Hence the probability equals
\[
\prod_{i=1}^m \PP\big(\mathrm{Pois}(\lambda|A_i|)=1\big)\cdot
\PP\big(\mathrm{Pois}(\lambda|S\setminus A_\star|)=0\big)
=
\prod_{i=1}^m e^{-\lambda|A_i|}(\lambda|A_i|)\cdot e^{-\lambda|S\setminus A_\star|},
\]
which simplifies to~\eqref{e.poisson-exact} since
$\sum_{i=1}^m |A_i| + |S\setminus A_\star| = |S|$.
\end{proof}

\begin{corollary}[Cloud $\epsilon$-box in $C_T$]\label{c.cloud-eps}
Let $T>0$ and let $C_T=\{(x,t)\in\R\times[0,T]: |x|\le t\}$.
Then $|C_T|=T^2$.
Let $\mc P$ be a Poisson point process on $C_T$ of intensity $\lambda>0$.
Fix distinct points $\omega_1,\dots,\omega_m\in C_T$ and let
$D(\omega_i,\epsilon)\subset C_T$ be pairwise disjoint measurable sets
(depending on $\epsilon$) with areas
$|D(\omega_i,\epsilon)| = a_i(\epsilon)$.
Define the event
\[
\mathsf B(\omega,\epsilon)
:=
\Big\{
\#(\mc P\cap D(\omega_i,\epsilon))=1\ \forall i\le m,\ \ 
\#(\mc P\cap(C_T\setminus \cup_{i=1}^m D(\omega_i,\epsilon)))=0
\Big\}.
\]
Then
\begin{equation}\label{e.cloud-box-general}
\Q\big(\mathsf B(\omega,\epsilon)\big)
=
e^{-\lambda T^2}\,\prod_{i=1}^m \big(\lambda a_i(\epsilon)\big).
\end{equation}
In particular, if each $D(\omega_i,\epsilon)$ is a square of side $2\epsilon$
(or any set of area $(2\epsilon)^2$), so that $a_i(\epsilon)=(2\epsilon)^2$,
then
\begin{equation}\label{e.cloud-box-square}
\Q\big(\mathsf B(\omega,\epsilon)\big)
=
e^{-\lambda T^2}\,
\big(\lambda(2\epsilon)^2\big)^m
=
e^{-\lambda T^2}\,
(2\epsilon)^{2m}\,\lambda^m\,4^m.
\end{equation}
Under the convention $\lambda=1$, this reads
\[
\Q\big(\mathsf B(\omega,\epsilon)\big)=e^{-T^2}(2\epsilon)^{2m}(1+o(1))
\quad\text{as }\epsilon\downarrow0,
\]
up to the harmless choice of whether the box area is taken to be $(2\epsilon)^2$
or $c(2\epsilon)^2$ for some fixed $c>0$.
\end{corollary}

% --------------------------------------------------------------------
% Detachable Piece C: Poisson epsilon-box asymptotics in cloud space
% --------------------------------------------------------------------

\medskip

\subsection*{Poisson $\epsilon$-box asymptotics in the cone}\label{s.poisson-box}

We record the standard local asymptotics for Poisson point processes that
underlie the cloud-side computation in~\eqref{e.cloud}.
We state the result in the generality needed for the ``diagonal boxes''
(or any family of disjoint measurable sets of small area).

\begin{lemma}[Poisson counts in disjoint small sets]\label{l.poisson-small-sets}
Let $\mc P$ be a Poisson point process on a measurable set $S\subset\R^2$
of finite area $|S|$, with constant intensity $\lambda>0$.
Let $A_1,\dots,A_m\subset S$ be pairwise disjoint measurable sets, and
set $A_\star:=\bigcup_{i=1}^m A_i$.
Then
\begin{equation}\label{e.poisson-exact}
\Q\Big(
\#(\mc P\cap A_i)=1\ \text{for all $i\le m$},\ \ 
\#(\mc P\cap (S\setminus A_\star))=0
\Big)
=
e^{-\lambda|S|}\,
\prod_{i=1}^m \big(\lambda |A_i|\big).
\end{equation}
\end{lemma}

\begin{proof}
For disjoint sets, the Poisson counts
$\#(\mc P\cap A_1),\dots,\#(\mc P\cap A_m),\#(\mc P\cap (S\setminus A_\star))$
are independent, with respective laws
$\mathrm{Pois}(\lambda|A_i|)$ and $\mathrm{Pois}(\lambda|S\setminus A_\star|)$.
Hence the probability equals
\[
\prod_{i=1}^m \PP\big(\mathrm{Pois}(\lambda|A_i|)=1\big)\cdot
\PP\big(\mathrm{Pois}(\lambda|S\setminus A_\star|)=0\big)
=
\prod_{i=1}^m e^{-\lambda|A_i|}(\lambda|A_i|)\cdot e^{-\lambda|S\setminus A_\star|},
\]
which simplifies to~\eqref{e.poisson-exact} since
$\sum_{i=1}^m |A_i| + |S\setminus A_\star| = |S|$.
\end{proof}

\begin{corollary}[Cloud $\epsilon$-box in $C_T$]\label{c.cloud-eps}
Let $T>0$ and let $C_T=\{(x,t)\in\R\times[0,T]: |x|\le t\}$.
Then $|C_T|=T^2$.
Let $\mc P$ be a Poisson point process on $C_T$ of intensity $\lambda>0$.
Fix distinct points $\omega_1,\dots,\omega_m\in C_T$ and let
$D(\omega_i,\epsilon)\subset C_T$ be pairwise disjoint measurable sets
(depending on $\epsilon$) with areas
$|D(\omega_i,\epsilon)| = a_i(\epsilon)$.
Define the event
\[
\mathsf B(\omega,\epsilon)
:=
\Big\{
\#(\mc P\cap D(\omega_i,\epsilon))=1\ \forall i\le m,\ \ 
\#(\mc P\cap(C_T\setminus \cup_{i=1}^m D(\omega_i,\epsilon)))=0
\Big\}.
\]
Then
\begin{equation}\label{e.cloud-box-general}
\Q\big(\mathsf B(\omega,\epsilon)\big)
=
e^{-\lambda T^2}\,\prod_{i=1}^m \big(\lambda a_i(\epsilon)\big).
\end{equation}
In particular, if each $D(\omega_i,\epsilon)$ is a square of side $2\epsilon$
(or any set of area $(2\epsilon)^2$), so that $a_i(\epsilon)=(2\epsilon)^2$,
then
\begin{equation}\label{e.cloud-box-square}
\Q\big(\mathsf B(\omega,\epsilon)\big)
=
e^{-\lambda T^2}\,
\big(\lambda(2\epsilon)^2\big)^m
=
e^{-\lambda T^2}\,
(2\epsilon)^{2m}\,\lambda^m\,4^m.
\end{equation}
Under the convention $\lambda=1$, this reads
\[
\Q\big(\mathsf B(\omega,\epsilon)\big)=e^{-T^2}(2\epsilon)^{2m}(1+o(1))
\quad\text{as }\epsilon\downarrow0,
\]
up to the harmless choice of whether the box area is taken to be $(2\epsilon)^2$
or $c(2\epsilon)^2$ for some fixed $c>0$.
\end{corollary}

% --------------------------------------------------------------------
% Detachable Piece E: Normalization identity
% --------------------------------------------------------------------

\medskip

\subsection*{Normalization identity}\label{s.normalization}

We now combine the local $\epsilon$-box correspondence
(Lemma~\ref{l.local-box}) with the Poisson asymptotics
(Corollary~\ref{c.cloud-eps})
to obtain the global normalization identity.

\begin{proposition}[Normalization identity]\label{p.normalization}
Fix $n\in\mathbb N$ and $T>0$.
Then
\[
\exp\{-4nT\}\,\Q\big(D(T)\le n\big)
=
\exp\{-T^2\}\,
\PP_n^w(T)\big(R\cap\nonint\big).
\]
\end{proposition}

\begin{proof}
Let $L$ be a proper $n$-line configuration with $m$ jumps,
and let $\omega=\Psi_T(L)$ be the corresponding cloud.

By Lemma~\ref{l.local-box}, for sufficiently small $\epsilon$,
the $\epsilon$-boxes correspond:
\[
\Phi_T(\mathsf B(\omega,\epsilon))
=
B(L,\epsilon).
\]

Under $\PP_n^w(T)$,
\[
\PP_n^w(T)\big(B(L,\epsilon)\big)
=
\exp\{-4nT\}\,(2\epsilon)^{2m}(1+o(1)).
\]

Under $\Q$,
\[
\Q\big(\mathsf B(\omega,\epsilon)\big)
=
\exp\{-T^2\}\,(2\epsilon)^{2m}(1+o(1)).
\]

Restricting to the admissible subset $\{D(T)\le n\}$
and dividing by $\Q(D(T)\le n)$ yields
\[
\PP_{n,T}^\ell\big(B(L,\epsilon)\big)
=
\frac{\Q\big(\mathsf B(\omega,\epsilon)\big)}
{\Q(D(T)\le n)}.
\]

Comparing coefficients of $(2\epsilon)^{2m}$ and letting $\epsilon\downarrow0$
gives
\[
\frac{\exp\{-4nT\}}
{\PP_n^w(T)(R\cap\nonint)}
=
\frac{\exp\{-T^2\}}
{\Q(D(T)\le n)},
\]
which rearranges to the stated identity.
\end{proof}

\section{Chatgpt generated material}

\begin{proposition}[Depth equals line index]\label{p.depth-line-index}
Let $x\in\mc P_t$ and suppose that the multiline PNG construction
has been performed up to time~$t$.
Then the quantity $D(x^\pm)$ defined above is equal to the unique index
$k\ge1$ such that the nucleation caused by $x$ contributes to the curve
$L_{-(k-1)}$ at time~$t$.
Equivalently,
$D(x^\pm)=k$ precisely when
$x$ is used by an optimal $k$-tuple of disjoint upgoing paths
to $(x^\pm,t)$ but not by any optimal $(k-1)$-tuple.
\end{proposition}

\begin{proof}
By definition, $D(x^\pm)$ is the smallest $k$ for which
\[
M_k^{\mc P_t}\big(x^\pm(t),t\big)
>
M_k^{\mc P_t(x)}\big(x^\pm(t),t\big).
\]
Thus $x$ increases the optimal $k$-tuple weight but does not increase
any smaller tuple.

Now recall from Proposition~\ref{p.depth-line-index} (or the earlier
identity relating $M_j$ to the line ensemble) that
\[
M_k(x,t)
=
\sum_{i=0}^{k-1}\big(L_{-i}(x,t)+i\big).
\]
Therefore, the increment
\[
M_k^{\mc P_t}(x^\pm,t)
-
M_k^{\mc P_t(x)}(x^\pm,t)
\]
is equal to the increment in the cumulative height of the first $k$
curves at the spatial location $x^\pm(t)$ caused by the presence of $x$.

Because the multiline PNG construction propagates nucleations upward
level-by-level via annihilation events, the Poisson point $x$
produces exactly one unit increase in the curve
$L_{-(k-1)}$ at the moment its influence reaches time~$t$,
where $k$ is minimal with this property.
For smaller indices the optimal families of paths do not use $x$,
and for larger indices the influence is inherited from lower levels.

Hence the minimal $k$ for which $x$ contributes to $M_k$
is precisely the level at which the corresponding nucleation
occurs in the multiline picture.
\end{proof}

\medskip



% --------------------------------------------------------------------
% Continuation: local coordinate map to kink-data at time T; nonsingular
% configurations; and the Gibbs/bridge interpretation.
% --------------------------------------------------------------------

\medskip




\paragraph{Pushing Poisson points to time $T$ and kink data.}
In this section we view the Poisson cloud in the cone
$$
C_T=\big\{(x,t)\in \R\times[0,T]: |x|\le t\big\}
$$
as generating, at time~$T$, a finite collection of upstep--downstep pairs.
To avoid notational conflict with the time variable, we write $\omega$ for a Poisson configuration
and regard $\omega$ as a finite subset of $C_T$:
$$
\omega=\{(x_1,t_1),(x_2,t_2),\dots,(x_m,t_m)\}.
$$
Recall that $\tau$ sends each point $(x_i,t_i)$ to the ordered pair
$(x_i^-,x_i^+)$ with
$$
x_i^- = x_i-(T-t_i),\qquad x_i^+=x_i+(T-t_i).
$$
Equivalently,
$$
x_i=\frac{x_i^-+x_i^+}{2},\qquad t_i=T-\frac{x_i^+-x_i^-}{2}.
$$
Thus $\tau$ is injective on point configurations, and its range is contained in
$$
\Delta_T:=\big\{(z,z')\in[-T,T]^2: z<z'\big\}.
$$
When $\tau(\omega)=\{(x_i^-,x_i^+)\}_{i=1}^m$, we interpret $x_i^-$ and $x_i^+$
as, respectively, the spatial locations at time~$T$ of the upstep and downstep
produced by the nucleation at $(x_i,t_i)$ and transported along the
characteristics of slope $\pm1$.

\medskip

\paragraph{A nonsingular open set in kink space.}
Let $Y$ denote the collection of finite subsets of $\Delta_T$ (as above).
We say that $y=\{(z_i,z_i')\}_{i=1}^m\in Y$ is \emph{nonsingular} if all of the $2m$
numbers $z_1,z_1',\dots,z_m,z_m'$ are distinct.
Write $Y^{\rm ns}\subset Y$ for the set of nonsingular configurations.

Fix $y=\{(z_i,z_i')\}_{i=1}^m\in Y^{\rm ns}$.
For $\e>0$ sufficiently small (depending on~$y$), define the box neighbourhood
\begin{equation}\label{e.box-y}
B_\e(y)
:=
\Big\{
\{(\tilde z_i,\tilde z_i')\}_{i=1}^m \in Y^{\rm ns}:
|\tilde z_i-z_i|<\e,\ |\tilde z_i'-z_i'|<\e\ \ \forall i
\Big\}.
\end{equation}
For $\e$ small, the constraints $\tilde z_i<\tilde z_i'$ and mutual distinctness of
the $2m$ endpoints remain valid throughout $B_\e(y)$.

\medskip

\paragraph{From kink data to multi-line PNG at time $T$.}
The Prhofer--Spohn multi-line construction (equivalently, the RSK dynamics)
associates to each Poisson configuration $\omega$ a multi-line step ensemble
$\{L_{-i}(\cdot,T)\}_{i\ge0}$ at time~$T$.
On the level of time-$T$ kink data, this may be viewed as a deterministic map
\begin{equation}\label{e.PS-map}
\Phi:\ Y^{\rm ns}\ \longrightarrow\ \mc L^{\rm ns}_T,
\end{equation}
where $\mc L^{\rm ns}_T$ denotes the set of multi-line PNG time-$T$ profiles
whose kinks occur at distinct spatial locations.
Informally, $\Phi$ takes the multiset of upstep/downstep positions at time~$T$
and resolves annihilations level-by-level to produce the line ensemble at time~$T$.
(If one wishes to recover the Poisson configuration from the line ensemble,
one may augment $\mc L^{\rm ns}_T$ by standard ``recording'' data; for the present
discussion it suffices that $\Phi$ is well defined on $Y^{\rm ns}$ and locally stable.)

\begin{lemma}[Local stability away from coincidences]\label{l.local-stability}
Fix $y\in Y^{\rm ns}$.
There exists $\e_0=\e_0(y)>0$ such that for all $\e\in(0,\e_0)$:
\begin{enumerate}
\item the combinatorial resolution of annihilations used by $\Phi$ is constant on $B_\e(y)$
(i.e.\ no ``ties'' occur in determining collisions);
\item consequently, $\Phi$ restricts to a bijection from $B_\e(y)$ onto
$U_\e(\Phi(y)):=\Phi(B_\e(y))\subset \mc L_T^{\rm ns}$, and in the coordinates
given by kink locations, $\Phi$ is locally Lipschitz with locally Lipschitz inverse.
\end{enumerate}
\end{lemma}

\noindent
Lemma~\ref{l.local-stability} expresses the basic fact that, away from coincident kink
locations, small perturbations of the $x_i^\pm$ do not change the discrete pairing
structure of the step resolution, and therefore yield a smooth ``wiggle room''
in line space corresponding to the same perturbation scale in kink space.

\medskip

\paragraph{Restriction to at most $n$ active lines.}
Let $\mc L_{T,\le n}^{\rm ns}\subset \mc L_T^{\rm ns}$ denote the set of nonsingular
time-$T$ line ensembles for which no curve below index~$-(n+1)$ is active at time~$T$,
that is,
\begin{equation}\label{e.floor-event}
\mc L_{T,\le n}^{\rm ns}
:=
\Big\{\{L_{-i}(\cdot,T)\}_{i\ge0}\in \mc L_T^{\rm ns}:\ L_{-(n+1)}(\cdot,T)\equiv -(n+1)\Big\}.
\end{equation}
Equivalently, on the Poisson side this corresponds to the event $\{D(T)\le n\}$.

Define the corresponding restricted kink space by
$$
Y_{\le n}^{\rm ns}:=\Phi^{-1}\big(\mc L_{T,\le n}^{\rm ns}\big)\subset Y^{\rm ns}.
$$
For $y\in Y_{\le n}^{\rm ns}$, Lemma~\ref{l.local-stability} implies that for $\e>0$
small enough we have $B_\e(y)\subset Y_{\le n}^{\rm ns}$, hence $U_\e(\Phi(y))\subset \mc L_{T,\le n}^{\rm ns}$.
In other words, the ``hard floor'' condition at level $-(n+1)$ persists under sufficiently small
perturbations of a nonsingular configuration.

\medskip

\paragraph{Infinitesimal weights: Poisson side versus walk side.}
We record the two reference exponential factors that underlie the comparison
between the Poisson picture and the random-walk line picture.

\smallskip

\noindent
\emph{(i) Poisson cloud.}
The Poisson process in $C_T$ of unit intensity has total mass
$\mathrm{Area}(C_T)=\int_0^T 2t\,dt=T^2$.
Thus the base ``no-extra-points'' factor is $e^{-T^2}$.
Moreover, on the nonsingular set $Y^{\rm ns}$, the map
$(x,t)\mapsto (x^-,x^+)$ has constant Jacobian determinant~$2$, so
$\tau$ sends unit intensity in $(x,t)$ to intensity $\tfrac12$ in $(x^-,x^+)$.
Consequently, for fixed $y\in Y^{\rm ns}$ and $\e\downarrow0$,
\begin{equation}\label{e.poisson-box-asymp}
\Q\big(\tau(\mc P)\in B_\e(y)\big)
=
e^{-T^2}\,\Big(\tfrac12\Big)^m\,(2\e)^{2m}\,(1+o(1)),
\end{equation}
where $m$ is the number of pairs in~$y$.

If $y\in Y_{\le n}^{\rm ns}$, then $B_\e(y)\subseteq \{D(T)\le n\}$ for $\e$ small,
and therefore conditioning gives
\begin{equation}\label{e.poisson-conditioned-box}
\Q\big(\tau(\mc P)\in B_\e(y)\,\big|\,D(T)\le n\big)
=
\frac{\Q\big(\tau(\mc P)\in B_\e(y)\big)}{\Q(D(T)\le n)}.
\end{equation}

\smallskip

\noindent
\emph{(ii) Random-walk line picture.}
Under $\PP_{n,T}$, each rate-$2$ CTSRW on $[-T,T]$ has jump clock
$\mathrm{Poisson}(4T)$, so the base clock factor is $e^{-4T}$ per walk, hence
$e^{-4nT}$ for $n$ independent walks.
On the restricted state space $\mc L_{T,\le n}^{\rm ns}$, the Gibbs specification
for the line ensemble (see the next paragraph) implies that local perturbations
of kink locations carry the same Lebesgue infinitesimal $\prod_i d x_i^-\,d x_i^+$
as in~\eqref{e.poisson-box-asymp}, multiplied by the same base factor $e^{-4nT}$.
This is the sense in which the two pictures assign matching local ``volume''
to nonsingular configurations, differing only by the universal exponential
factor $e^{T^2-4nT}=e^{T(T-4n)}$ and the global normalization required by the
restriction $\{D(T)\le n\}$.

\medskip

\paragraph{Gibbs property for the truncated line ensemble.}
We now summarize the Gibbs rule that will be used repeatedly.
Consider the $n$-curve ensemble $(X_0,X_{-1},\dots,X_{1-n})$ on $[-T,T]$
under the conditional law $\PP_{n,T}(\cdot\mid R_n\cap\nonint)$.
Fix $k\in\llbracket 1,n-2\rrbracket$ and condition on the neighbouring curves
$X_{-(k-1)}$ and $X_{-(k+1)}$.
Then, conditional on these neighbours, the curve $X_{-k}$ is distributed as a
rate-$2$ CTSRW bridge between its realised endpoint values at $\pm T$,
conditioned to stay strictly between the two neighbours on the whole interval.
Likewise, the bottom curve $X_{1-n}$ is a rate-$2$ CTSRW bridge conditioned to stay
above the hard floor $-n$ (this is precisely the external non-intersection event).

{\bf Remark.}[How the Gibbs rule arises]\label{r.gibbs-origin}
One convenient route to this Gibbs property is to view
$\PP_{n,T}(\cdot\mid R_n\cap\nonint)$ as a Doob $h$-transform of $n$ independent
rate-$2$ walks killed upon collision: the conditioning on mutual non-intersection
and endpoints produces a Markov line ensemble whose single-curve conditional laws,
given neighbouring curves, are exactly constrained CTSRW bridges.
An alternative, more combinatorial route proceeds via the Karlin--McGregor/Lindstrm--Gessel--Viennot
determinantal formula for non-intersecting walk bridges, from which the same
single-curve conditional laws follow by fixing all but one path.


\medskip

\paragraph{Comment on the ``measure-isomorphism'' viewpoint.}
The maps $\tau$ and $\Phi$ provide a convenient coordinate system for comparing
the Poisson cloud picture with the random-walk line picture.
On the nonsingular sets $Y^{\rm ns}$ and $\mc L_T^{\rm ns}$, small boxes
$B_\e(y)$ correspond, via $\Phi$, to small neighbourhoods in line space
with the same $2m$ free kink coordinates.
After restricting to $Y_{\le n}^{\rm ns}$ (equivalently, $\{D(T)\le n\}$),
the induced conditional law on line ensembles has the Gibbs description above,
and local weights differ from the Poisson-side weights only by the universal
clock/area factor $e^{T^2-4nT}$ and the global normalization $\Q(D(T)\le n)$.
This is the sense in which the truncated ($\le n$) Poisson picture and the
$n$-curve non-intersecting walk ensemble may be compared ``as measures'' on a
common nonsingular coordinate space.


\medskip

\paragraph{Explicit normalization identities.}
We now record the concrete formula that is implicit in the preceding local-coordinate discussion.
Fix $n\in\N$ and $T>0$, and abbreviate the depth event by
$$
A_{n,T}:=\{D(T)\le n\}
\equiv \big\{ L_{-(n+1)}(\cdot,T)\equiv -(n+1)\ \text{on }[-T,T]\big\}.
$$
Write $\Q_{n,T}$ for the conditional Poisson law $\Q(\,\cdot\,\vert A_{n,T})$.

\smallskip

\noindent
\emph{(1) Local box probabilities and the universal exponential factor.}
Let $y=\{(z_i,z_i')\}_{i=1}^m\in Y_{\le n}^{\rm ns}$, and let $B_\e(y)$ be the kink-box
defined in~\eqref{e.box-y}.  Set $U_\e:=\Phi(B_\e(y))\subset \mc L_{T,\le n}^{\rm ns}$.
Then as $\e\downarrow0$,
\begin{equation}\label{e.local-ratio}
\frac{\Q\big(\tau(\mc P)\in B_\e(y)\big)}{\PP_{n,T}\big(U_\e\big)}
=
\exp\{T^2-4nT\}\,(1+o(1)),
\end{equation}
where the $(1+o(1))$ term depends on $y$ but not on the direction of shrinkage of the box.
Equivalently, in conditional form,
\begin{equation}\label{e.local-ratio-conditioned}
\frac{\Q_{n,T}\big(\tau(\mc P)\in B_\e(y)\big)}{\PP_{n,T}\big(U_\e\big)}
=
\frac{\exp\{T^2-4nT\}}{\Q\big(A_{n,T}\big)}\,(1+o(1)).
\end{equation}
In particular, the only global discrepancy between the two pictures in these
nonsingular kink-coordinates is the universal factor $\exp\{T^2-4nT\}=\exp\{T(T-4n)\}$
together with the conditioning normalization $\Q(A_{n,T})$.

\smallskip

\noindent
\emph{(2) A global Radon--Nikodym relation (informal but useful).}
Guided by~\eqref{e.local-ratio-conditioned}, it is natural to package the preceding as the heuristic
measure identity
\begin{equation}\label{e.RN-heuristic}
\PP_{n,T}(\,\cdot\,\vert R_n\cap\nonint)
\ \ \approx\ \ 
\Q(\,\cdot\,\vert A_{n,T})
\quad\text{with normalizing constant}\quad
\frac{\exp\{T(T-4n)\}}{\Q(A_{n,T})},
\end{equation}
where the comparison is understood on $Y_{\le n}^{\rm ns}$ (or on the corresponding line space
$\mc L_{T,\le n}^{\rm ns}$) in the sense that small kink-box probabilities match with the stated
constant factor.
In particular, if $\mc E$ is an event depending only on the top $n$ curves and supported in
$\mc L_{T,\le n}^{\rm ns}$, then one may read~\eqref{e.RN-heuristic} as suggesting
\begin{equation}\label{e.event-identity-heuristic}
\PP_{n,T}\big(\mc E\cap R_n\cap\nonint\big)
\ \ \approx\ \ 
\exp\{T(T-4n)\}\,\Q\big(\Phi^{-1}(\mc E)\cap A_{n,T}\big),
\end{equation}
with the same constant $\exp\{T(T-4n)\}$ appearing universally.

\smallskip

\noindent
\emph{(3) The proposition as a normalization statement.}
Taking $\mc E$ to be the full admissible event (i.e.\ $\mc E$ equal to the whole
$\mc L_{T,\le n}^{\rm ns}$ up to null sets), the preceding reduces precisely to the claimed
normalization relation
\begin{equation}\label{e.normalization-prop}
\PP_{n,T}\big(R_n\cap\nonint\big)
=
\exp\{T(T-4n)\}\,\Q\big(D(T)\le n\big),
\end{equation}
which is the proposition stated above.

\end{document}






\chapter{Lecture One: Exponents, curvature \\ and Gaussianity via resampling}

Important stochastic processes -- such as Brownian motion or the Airy$_2$ process --
describe the scaled, universal, behaviour of physical systems. 

Sometimes, these processes can profitably be analysed by embedding them in higher dimensional random systems in such a way that the bigger system has an attractive probabilistic property which may act as a tool, being brought to bear in the rigorous analysis of the original object of interest. This probabilistic property may be a {\em Gibbs resampling} rule -- a rule which permits a bounded part of the larger system to be resampled, given the form of the remaining part, according to an explicit conditional distribution. The latter distribution may permit analysis to be made when this given part of the larger system is resampled, with insight so gathered about the big system than being transmitted to the original process which is embedded within it.


 For example, the Airy$_2$ process $\mc{A}$
is a random continuous function $\mc{A}: \R \to \R$ which may be embeeded as the lowest indexed, and uppermost, curve $\mc{A}(1,\cdot)$ in the {\em Airy line ensemble} [AiryLE], which is a random $\N$-indexed collection $\mc{A}:\N \times \R \to \R$ of continuous curves. With suitable interpretation that copes with boundary conditions for an infinite system of curves, the AiryLE is a system of Brownian motions conditioned on mutual avoidance -- see Figure~\ref{f.airysimulation}. This has the implication that, if the top few curves are resampled on a given compact real interval, then their conditional distribution is given by a finite system of Brownian bridges, attached suitably to the endpoints generated by the curves' removal, conditioned on mutual avoidance and on avoidance of the lower boundary curve. This {\em Brownian Gibbs} property will be precisely specified later, and will form a central element in this exposition.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=12cm]{AirySimulation.pdf}
\caption{A discrete variant of the Airy line ensemble whose domain is cyclic. 
When the mesh that specifies the depicted walkers tends to zero and the Airy line ensemble is obtained, the indicated point process will converge towards the process of random statistics of the largest eigenvalues of a large matrix drawn from the Gaussian unitary ensemble. Simulation by Judit Z{\'a}dor.}
\label{f.airysimulation}
\end{center}
\end{figure}  



For now, we give two simple examples of random systems which demonstrate four characteristics of the Kardar-Parisi-Zhang [KPZ] universality class, namely:
\begin{itemize}
\item an exponent of two-thirds for the spatial scale;
\item an exponent of one-third for the scale of height;
\item and interfaces that are {\em locally Brownian} ...
\item as well as {\em globally parabolic}.
\end{itemize}

 The second of the two examples also illustrates how resampling a random system can be a useful tool for understanding it.

{\bf Example $1$: a baby version of the Airy$_2$ process.}
Let $B: \R \to \R$, $B(0) = 0$, be standard two-sided Brownian motion.
Let $t > 0$ be large. Set $X: \R \to \R$, $X(t) = B(x) - x^2/t$.

Further consider $\mc{C} = \mc{C}_X : \R \to \R$ to be the least concave majorant of $X : \R \to \R$. 


Naturally, the process $X$ is locally Brownian but globally parabolic. In fact, it also evinces the characteristic KPZ exponents of $1/3$ and $2/3$. 
We may identify these exponents by studying how closely $X$ follows the global contour offered by $\mc{C}_X$. The process $\mc{C}_X$ has a graph, a closed subset of $\R^2$, which is comprised of the union of a countable collection of closed planar line segments. The {\em facet through zero} may be defined to be the planar segment among these that passes through the vertical axis through the origin. The {\em facet length} is the random  length of the interval occupied by $x$-coordinates of points in the facet through zero. 

The facet length's scaling in $t$ as $t \nearrow \infty$
is a measure of persistence of randomness in the horizontal scale. To find a counterpart in the vertical direction, we may consider the {\em inward deviation} or {\em local roughness} of the random interface $X$ at the origin. Indeed, we may define the local roughness (at zero) to be the distance between $X(0)$ and $\mc{C}_X(0)$ -- so that local roughness measures the fluctuation of the interface away from its convex hull at a typical location. Figure~\ref{f.exampleone} illustrates this.

The claims that validate the exponent values for this model are that
$$
\textrm{in mean value:  facet length scales as $t^{2/3}$ as $t \nearrow \infty$}
$$
and
$$
 \textrm{in mean value:  local roughness scales as $t^{1/3}$ as $t \nearrow \infty$} \, .
$$

To gesture towards the proofs of these claims, the facet length $\ell$
may be identified as the horizontal scale
$$
\textrm{above which {\em parabolic curvature} is dominant}
$$
and
$$
\textrm{below which {\em Brownian fluctuation} dominates} \, .
$$
The scale of $\ell$ may be identified by equating the two effects:
$$
 \textrm{Brownian fluctuation} \approx  \textrm{parabolic curvature} \, ;
$$
or
$$
    \ell^{1/2} \approx \frac{\ell^2}{T} \, .
$$
Which leads to $\ell \approx T^{2/3}$.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{exampleone.pdf}
\caption{A toy model for the Airy$_2$ process: Brownian motion with a parabola subtracted whose  coefficient $t^{-1}$ is small and positive.}
\label{f.exampleone}
\end{center}
\end{figure}  

Regarding local roughness, the inward deviation made by $X$ as it describes the journey from one extreme point of the graph of its convex hull to the next may be expected, in view of Gaussian fluctuation, to have scale given by the square-root of the horizontal extent of that journey. Which is to say: the local roughness will behave in the form  $\big( t^{2/3} \big)^{1/2} = t^{1/3}$.


{\bf Example $2$: oriented random walk constrained by area trap.}

Consider a state space $\Lambda$
that consists of oriented (meaning downright) paths in the first quadrant of $\Z^2$
that begin on the $y$-axis and that end on the $x$-axis. 

Let $\gamma \in \Lambda$. Then the length $L(\gamma)$ of $\gamma$
is defined to be the number of steps taken by $\gamma$, which is also the sum of the vertical coordinate at which $\gamma$ begins and the horizontal coordinate at which it ends. 

The area $A(\gamma)$ is the area of the finite region enclosed by the graph of $\gamma$
and the two coordinate axes -- see Figure~\ref{f.lengthandarea}.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{lengthandarea.pdf}
\caption{An element $\gamma \in \Lambda$ with $L(\gamma) = k + \ell$ and whose area $A(\gamma)$ is the area of the hatched region.}
\label{f.lengthandarea}
\end{center}
\end{figure}   

If we set 
$$
 \Lambda_n = \big\{ \gamma \in \Lambda: L(\gamma) = n \big\} \, ,
$$
then $\big\vert \Lambda_n \big\vert = 2^n$. This is because the number of length~$n$ downright paths that begin at the origin is equal to $2^n$; and each such path may be translated directly upwards to a unique location at which it forms an element in $\Lambda_n$.


Now let $\lambda \in (0,1/2)$. We define a probabiltiy measure $\PP_\lambda$ on $\Lambda$ by insisting that
$$
 \PP_\lambda (\gamma) = Z^{-1} \lambda^{L(\gamma)} \, ,
$$
where $Z \in (0,\infty)$ is a normalization that ensures that $\PP_\lambda$ has unit mass.

Since $\lambda < 1/2$, $Z$ is finite. 

What is the distribution of length of the path obtained by sampling the law $\PP_\lambda$? It verifies 
$$
 \PP_\lambda \Big( \textrm{$\Gamma$ has length $n$} \Big) = Z^{-1} \big( 2\lambda \big)^n \, ,
$$
where we write $\Gamma$ for the sampled path.
This equality is a condition of exponential tail decay because $2 \lambda < 1$.

The law $\PP_\lambda$ may be viewed as a background or reference measure on which we now impose a constraint that involves area capture. 

To do so, let $N \in \N$. The area-constrained random model that we study in this example is
$$
 \PP_\lambda^{N^2} : = \PP_\lambda \Big( \cdot \Big\vert A(\Gamma) \geq N^2 \Big) \, .
$$
See Figure~\ref{f.typicalsample}.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{typicalsample.pdf}
\caption{A caricature of a typical sample of $\PP_\lambda^{N^2}$.}
\label{f.typicalsample}
\end{center}
\end{figure}   


Here are two natural questions, which are not quite at the heart of our brief study of this model, but rather will aid the study:
Under $\PP_\lambda^{N^2}$, what is the typical value of
\begin{itemize}
\item the length of the sampled path $\Gamma$;
\item and the excess area of $\Gamma$, namely ${\rm ExcessArea}(\Gamma) := A(\Gamma) - N^2$?
\end{itemize} 
The answers are:
\begin{itemize}
\item that $L(\Gamma)$ typically has order $N$; 
\item and that ${\rm ExcessArea}(\Gamma)$ typically also has order $N$; or more precisely, 
\begin{equation}\label{e.excessarea}
 \PP_\lambda^{N^2} \Big( {\rm ExcessArea}(\Gamma) \geq tN \Big) \leq C \exp \big\{ c t \big\} \, ,
\end{equation}
where $C$ and $c$ are two positive constants, and $t > 0$ is supposed to satisfy $t \geq C \log n$.
\end{itemize} 

Why are these the correct answers? 

Regarding the first, note that the event $A(\Gamma) \geq N^2$ on which we condition in specifying the law $\PP_\lambda^{N^2}$ is typically satisfied by randomly chosen elements in $\Gamma_n$, provided that the index $n$ is a large constant multiple of $N$. Since the random length of a sample of $\PP_\lambda$ has an exponential tail, we see that the answer to first query is in its scale the correct one. 

To see that ${\rm ExcessArea}(\Gamma) \asymp N$, note that, given a typical sample of 
 $\PP_\lambda^{N^2}$, we may perform an operation in which the sampled path $\Gamma$ is shifted one unit to the right, with a horizontal edge added to abut its starting point, in order that a new element of the state space $\Gamma$ be obtained. A gain in area of order $N$ typically results from this manoeuvre -- see Figure~\ref{f.additionandremoval}(left). But the new path and the old one have the same probability up to a constant factor to be sampled under $\PP_\lambda$, because only one edge was added in the formation of the new path. In this way, the excess area is seen to have positive probability under the conditioned law $\PP_\lambda^{N^2}$
 to be of order at most $N$. It is the opposing bound, and its more precise form displayed above, which will interest us more. But this form may be demonstrated, roughly speaking, by a reversal of the argument just given -- Figure~\ref{f.additionandremoval}(right) illustrates. If the excess of area is at least $Nt$, we may sample a path that realizes this excess, shift it to the left by an order of $t$ units, and cut off the part that was pushed into the second quadrant; and we will be left with a new path, which continues to realize the basic requirement that the captured area be at least $N^2$ -- but which does so with an order of $t$ fewer edges  than in the originally sampled path. The new path is thus preferred to the old in the underlying law $\PP_\lambda$ by a factor which grows exponentially in $t$. From this, then, we see that the part of the state space in which the excess area of the sampled path is at least $tN$ must be exponentially small in $t$ under the law $\PP_\lambda^{N^2}$ -- which is the stated estimate in the second answer.
 


\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{additionandremoval.pdf}
\caption{{\em Left:} An area gain of order $N$ is attained by a unit rightward displacement, with the outcome as likely as the input up to a unit-order factor.
{\em Right:} An area loss of order $Nt$ alongside a length saving of order $t$.}
\label{f.additionandremoval}
\end{center}
\end{figure}    
 
These answers will be valuable as we derive the next result -- which asserts that the powers of two-thirds and one-third are present in the constrained area-trap model in a manner similar to in our first example. We define $\mc{C}_\Gamma$ to be the least concave majorant of the graph of $\Gamma$. See Figure~\ref{f.facetlengthandlocalroughness} for the specifications of facet length and local roughness.



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{facetlengthandlocalroughness.pdf}
\caption{{\em Left:} The facet length (of the facet through the diagonal) of the downright path $\gamma$ is the length of the planar line segment~$\ell$. The local roughness (of the vertex in $\gamma$ lying on the diagonal) is the length of the arrow.}
\label{f.facetlengthandlocalroughness}
\end{center}
\end{figure}   

\begin{theorem}\label{t.areatrap}
Under  $\PP_\lambda^{N^2}$,
$$
 \textrm{the mean facet length scales as $N^{2/3}$}
$$
and
$$
 \textrm{the mean local roughness scales as $N^{1/3}$} \, . 
$$
\end{theorem}
We will prove this result -- or explain the substantive elements of the proof -- using a tool of {\em resampling}. We will find a random surgical procedure which takes as input a sample $\Gamma$ of  $\PP_\lambda^{N^2}$, modifies a certain part of the sampled path, and returns as output another element of the state space $\Lambda$. 
The returned element 
$\Gamma^{{\rm{re}}}$ 
(the resampled path) will verify $A\big( \Gamma^{\rm{re}} \big) \geq N^2$. Moreover, and crucially, the random surgery will be such that, if the input is chosen to have law  $\PP_\lambda^{N^2}$, then so will the output    -- so that the procedure may indeed be viewed as a resampling of this law, with the input path being distributed according to the law and the output path also doing so.

To prepare for the construction of the random surgery, we first note a basic resampling property enjoyed by the underlying path measure $\PP_\lambda$.  

Take a sample $\Gamma$ of $\PP_\lambda$. Choose two points $a$ and $b$ on $\Gamma$. 
These points are chosen to be at certain given deterministic distances along $\Gamma$ from its starting location on the $y$-axis -- but in fact they may also be chosen according to a procedure that scans for the more counterclockwise of the points in a sweep centred at the origin that proceeds clockwise from vertical; and for the other point, by such a sweep proceeding counterclockwise from horizontal. The reason for this restriction on the selection of the pair of points is that it ensures that the subpath of $\Gamma$ between them is not investigated during the selection, so that its randomness remains undisturbed.
 
The points $a$ and $b$ thus selected, the path $\Gamma$ may be viewed as a conatenation of three pieces: a first piece, abutting the $y$-axis; a second, from $a$ to $b$; and a third, leading from $b$ to the $x$-axis.

Remove $\Gamma$'s middle section, between $a$ and $b$. Then ask: 
$$
\textrm{what is the conditional distribution of the removed piece, given the form of what remains?} 
$$

The answer is simple enough: this piece-to-be-added has the distribution of a uniformly chosen downright path from $a$ to $b$.

We may pose a similar question about resampling a given section of $\Gamma$ under  
$\PP_\lambda^{N^2}$.

First, select two points $a$ and $b$ on $\Gamma$, with $b$ more clockwise than $a$ -- subject to the same constraints on the search as before. Again remove $\Gamma$ between the two selected points. And ask the question posed above.

The answer is that the piece-to-be-added has the uniform law on downright paths from $a$ to $b$, {\em subject to the condition that the resulting overall path traps an area that is at least $N^2$} -- see Figure~\ref{f.areatrapcondition}. This area constraint may be expressed in terms of the added path from $a$ to $b$ as the condition that the area trapped between the proposed path and the lower and left sides of the rectangle with northwest corner at $a$ and with southeast corner at $b$ is at least a {\em certain level} -- where this level is such that an added path that traps exactly that much area within the rectangle forms part of an overall path that traps an area of $n^2$ on its lower-side in the first quadrant. 



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{areatrapcondition.pdf}
\caption{A realization $\Gamma$ of $\PP_\lambda^{N^2}$ is resampled between its visits to vertices $a$ and $b$. The sum of the areas of the hatched regions -- the lower one indicating the resampled curve -- must be least $N^2$ in order that the random operation maintains the law $\PP_\lambda^{N^2}$.}
\label{f.areatrapcondition}
\end{center}
\end{figure}   

We now present a resampling argument to establish that mean facet length under $\PP_\lambda^{N^2}$ scales at most as $N^{2/3 + o(1)}$. We will argue that
\begin{equation}\label{e.facetlengthub}
 \PP_\lambda^{N^2} \Big( \textrm{the facet length of $\Gamma$ is at least $N^{2/3 + \e}$} \Big) \to 0
\end{equation}
as $N \to \infty$ for any given $\e > 0$. The excess area bound~(\ref{e.excessarea})
will play a central role in deriving this result.

 The symbol $\PP$ will denote the randomness of the procedure that will enable this derivation. The procedure begins simply by sampling the law $\PP_\lambda^{N^2}$. Call the sample $\Gamma^{\rm in}$. This is our {\em input} configuration; we will randomly modify it to form the output. 

Define the event 
$$
 \mathsf{BigFacet} = \Big\{ \textrm{the facet length of $\Gamma^{{\rm in}}$ is at least $N^{2/3 + \e}$}  \Big\} \, .
$$

We pick vertices $a$ and $b$ independently along $\Gamma$ uniformly among those choices in which $b$ is clockwise of $a$. 
The part of $\Gamma$ between $a$ and $b$ is removed, and replaced by a new downright path~$\Gamma_{a \to b}^{{\rm resample}}$ connecting $a$ to $b$, in such a way that the resulting overall path -- running along $\Gamma$ from the start of this path to $a$; then along $\Gamma_{a \to b}^{{\rm resample}}$; then from $b$ along $\Gamma$ to this path's end  -- which we will call $\Gamma^{{\rm out}}$, retains the law of $\PP_\lambda^{N^2}$. Recall that the rule for sampling the random downright path is the uniform choice with an input-determined area constraint discussed before this derivation began.


Recalling that the facet of a downright path is the concave boundary facet that cuts through the diagonal $y = x$, we set 
$$
 \mathsf{GoodHit} = \Big\{ \textrm{the endpoints are the facet of $\Gamma^{{\rm in}}$ are $a$ and $b$} \Big\} \, ;
$$
then $\PP \big( \mathsf{GoodHit} \big) =  O(1) N^{-2}$, since the mean of $L \big( \Gamma^{{\rm in}} \big)$ has order $N$.

Our aim is to show that, when  the input verifies $\mathsf{BigFacet}$,
then experiencing the modest good fortune of the occurrence of $\mathsf{GoodHit}$ and a little further serendipity in the action of the resampling, we obtain an output that has an excess in area that is atypical according to~(\ref{e.excessarea}) -- an atypicality which can only mean that $\mathsf{BigFacet}$ is a rare event under the input configuration law  $\PP_\lambda^{N^2}$. 

The remaining element which needs to made precise is to describe which further serendipity it is exactly on the part of the random resampling which will force this structure in the output. 
The event will be called 
$\mathsf{MoreOutThanIn}$. To specify it, note that  $\Gamma_{a \to b}^{{\rm resample}}$  partitions the rectangle ${\rm Rect}$ whose northwest corner is $a$ and whose southeast corner is $b$ into two regions, which may naturally be called the lower-left region and the upper-right region. The event 
$\mathsf{MoreOutThanIn}$ occurs when the area of the lower-left region is at least the sum of one-half the area of ${\rm Rect}$ and the quantity $\dist a - b \dist^{3/2}$.


We may find a small constant $c > 0$ such that, for all $N \in \N$, the bound $\PP \big( \mathsf{MoreOutThanIn} \big) \geq c$ holds. Indeed, we could take $c = 1/2$ were we merely to demand that the lower-left region trap one-half of ${\rm Rect}$'s area; and, since the resampling of $\Gamma$ in this rectangle experiences a Gaussian fluctuation, of order given by the square root of the distance between $a$ and $b$, we see that the further area gain of $\dist a - b \dist^{3/2}$ is achieved with constant probability.

Our central claim about the random resampling asserts that
\begin{equation}\label{e.centralclaim}
   \mathsf{BigFacet}  \cap    \mathsf{GoodHit} \, \cap \, \mathsf{MoreOutThanIn} \subseteq \Big\{ A \big( \Gamma^{{\rm out}} \big) \geq N^2 + c N^{1 + 3\e/2} \Big\}  
\end{equation}
and is illustrated by Figure~\ref{f.areagain}.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=13cm]{areagain.pdf}
\caption{
When the original downright path verifies $\mathsf{BigFacet} \cap \mathsf{GoodHit}$ (depicted at the top),
and the resampling depicted in the middle verifies $\mathsf{MoreInThanOut}$, the area gain relative to the diagonal in the depicted rectangle is secured for the resampled downright path at the bottom -- so that this path has an area excess of at least~$c N^{1 + 3\e/2}$.} 
\label{f.areagain}
\end{center}
\end{figure}   

To verify the claim, consider the path $\Gamma'$ which is formed by the replacement of the section of $\Gamma$ about $a$ and $b$ by the planar line segment that connects these two endpoints. On the event $\mathsf{GoodHit}$, we have that $A\big(\Gamma^{{\rm in}}\big) \leq A\big(\Gamma'\big)$ -- indeed, in this circumstance, $a$ and $b$
are endpoints of a facet of the input path, so the formation of $\Gamma'$ involves the substitution of the  subpath of the input path in its journey between these consecutive extreme points with the affine route directly between the endpoints of the removed journey. Furthermore, the event $  \mathsf{BigFacet}  \cap    \mathsf{GoodHit}  \cap \mathsf{MoreOutThanIn}$ entails that
     $A\big(\Gamma^{{\rm out}}\big) \geq A\big(\Gamma'\big) + c N^{1 + 3\e/2}$. 
     Indeed, $A\big(\Gamma^{{\rm out}}\big) - A\big(\Gamma'\big) \geq c \dist a - b \dist^{3/2} \geq c N^{1 + 3\e/2}$, where it is the occurrence of $ \mathsf{MoreOutThanIn}$ that ensures the first inequality and that of  $\mathsf{BigFacet}  \cap    \mathsf{GoodHit}$ which ensures the second. Thus do we obtain~(\ref{e.centralclaim}). 
     
  Since $\PP \big(  \mathsf{BigFacet}  \big)$
  is equal to    
  $$ 
  \PP_\lambda^{N^2}  \Big( \textrm{the facet length of $\Gamma$ is at least $N^{2/3 + \e}$} \Big) \, ,
  $$
  while  $\PP \big( \mathsf{GoodHit} \big\vert  \mathsf{BigFacet}  \big)  = O(1) N^{-2}$ and  
  $$
  \PP \Big( \mathsf{MoreOutThanIn} \Big\vert \mathsf{BigFacet}    \cap   \mathsf{GoodHit} \Big)  \geq c \, ,
  $$
  we see that
  \begin{eqnarray*}
   & &  \PP_\lambda^{N^2}  \Big( \textrm{the facet length of $\Gamma$ is at least $N^{2/3 + \e}$} \Big)  \times O(1) N^{-2} \times c \\
    & \leq &  
  \PP \Big(   
     \mathsf{BigFacet}  \cap    \mathsf{GoodHit} \cap  \mathsf{MoreOutThanIn} \Big) \\
  & \leq &     \PP \Big( A \big( \Gamma^{{\rm out}} \big) \geq N^2 + c N^{1 + 3\e/2} \Big)
    \end{eqnarray*} 
      where the second inequality makes use of the claim~(\ref{e.centralclaim}).
      Since $\Gamma^{{\rm out}}$ under $\PP$ is  $\PP_\lambda^{N^2}$-distributed, we see that the term in the last displayed line equals 
$$
 \PP_\lambda^{N^2} \Big( {\rm ExcessArea}(\Gamma) \geq N \cdot cN^{3\e/2} \Big)
$$
which by~(\ref{e.excessarea}) is at most $C \exp \big\{ - c^2 N^{3\e/2} \big\}$. Thus, we learn that 
$$
  \PP_\lambda^{N^2}  \Big( \textrm{the facet length of $\Gamma$ is at least $N^{2/3 + \e}$} \Big) \leq O(1) N^2 c^{-1} C \exp \big\{ - c^2 N^{3\e/2} \big\} ,
$$
so that~(\ref{e.facetlengthub}) is indeed obtained. 

Our principal result about the area-trap path model, Theorem~\ref{t.areatrap},  makes two assertions. First, mean facet length is said to have a typical order of $N^{2/3}$; and second, mean local roughness is said to have order $N^{1/3}$. We have explained the reason for the upper bound on mean facet length. We will not discuss much the accompanying lower bound, nor the bounds needed on local roughness -- beyond saying that all these bounds arise in essence from the Gaussian fluctuation that is inherent in the area-constrained path, a path which is largely free from cares dictated by area on spatial scales below $N^{2/3}$.

We have seen how resampling the area trap path model has betrayed its characteristic KPZ features -- the two exponents; its global curvature; and its local Gaussianity. The model has thus largely served the purpose of exposition that we have intended for it. It is perhaps worth mentioning, however, that the basic resampling technique of proof leads to stronger conclusions. We may define ${\rm MFL}(\Gamma)$ to be the {\em maximum facet length} of a downright path $\Gamma \in \Lambda$ -- the maximum length of any of the planar line segments that comprise the graph of  the concave majorant $\mc{C}_\Gamma$. Further we may denote by ${\rm MLR}$ the {\em maximum local roughness} of $\Gamma$ -- this being the maximum over vertices in $\Gamma$ of the distance from the vertex to the graph of $\mc{C}_\Gamma$. 

The resampling technique may be pursued to obtain the next result, in which the poly-logarithmic corrections to the one-third and two-third powers are exhibited for these maximum statistics.
\begin{theorem}\label{t.max}
There exist positive constants $C$ and $c$ such that
$$
 \PP_\lambda^{N^2}  \bigg(  c \leq \frac{{\rm MLR}(\Gamma)}{n^{1/3} (\log n)^{2/3}} \leq C \bigg) \to 1
 $$
and
$$
 \PP_\lambda^{N^2}  \bigg(  c \leq \frac{{\rm MFL}(\Gamma)}{n^{2/3} (\log n)^{1/3}} \leq C \bigg) \to 1
 $$ 
as $N \to \infty$. 
\end{theorem}
 
The area trap path model is in a `baby' KPZ universality class -- it evinces exponents and qualitative features of the richer universality, but presumably without its rich distributional scaled structure including the GUE Tracy-Widom distribution. The model is a useful testing ground for some aspects of KPZ universality -- the polylogarithmic corrections in Theorem~\ref{t.max} are also found in KPZ, in problems concerning the maximal scaled energy, and the maximum fluctuation, of short geodesics. 
 


\chapter{Lecture Two: the Gibbs property of Brownian LPP, \\ and the main theorems}

Enough of baby KPZ -- we begin the lecture by formulating the model in the KPZ universality class which will become our object of study.



\section{Brownian last passage percolation [LPP]}





\subsection{The model's definition.}
This model was introduced by~\cite{GlynnWhitt} and further studied in~\cite{O'ConnellYor};
we will call it Brownian LPP.
On a probability space carrying a law labelled~$\PP$, we let $B:\Z \times \R \to \R$ denote an ensemble of independent  two-sided standard Brownian motions $B(k,\cdot):\R\to \R$, $k \in \Z$.

Let $i,j \in \Z$ with $i \leq j$. 
We denote the integer interval $\{ i,\cdots  , j \}$ by $\llbracket i,j \rrbracket$.
Further let $x,y \in \R$ with $x \leq y$.
With these parameters given, we consider the collection of  non-decreasing lists 
 $\big\{ z_k: k \in \llbracket i+1,j \rrbracket \big\}$ of values $z_k \in [x,y]$. 
With the convention that $z_i = x$ and $z_{j+1} = y$,
we associate an energy to any such list, namely   $\sum_{k=i}^j \big( B ( k,z_{k+1} ) - B( k,z_k ) \big)$.
We may then define  the maximum energy, 
$M^1_{(x,i) \to (y,j)}$,  to be the supremum of the energies of all such lists. 

We use a simpler notation in a special case -- that of narrow wedge initial data.
For $x > 0$, we set $M_n^1(x) = M^1_{(0,1) \to (x,n)}$, so that $M_n^1:[0,\infty) \to \R$ is a random energy profile of geodesics emanating from the origin to a variable location. (In fact, these geodesics begin at $(0,1)$ rather than at $(0,0)$ -- a minor discrepancy that ensures that $n$ horizontal coordinates are traversed by such paths.)

\subsection{A geometric view: staircases.}\label{s.staircases}
In order to make a study of those lists that attain the maximum energy, 
we begin by noting that the lists are in bijection with certain subsets of $[x,y] \times [i,j] \subset \R^2$ that we call {\em staircases}.
Staircases offer a geometric perspective on Brownian LPP and perhaps help in visualizing the problems in question.


%To introduce them ,we first mention  some basic notation: for  $i,j \in \Z$ with $i \leq j$,
%we denote the interval interval $\{ i,\cdots  , j \}$ by $\llbracket i,j \rrbracket$.
 

 The staircase associated to the non-decreasing list $\big\{ z_k: k \in \llbracket i+1,j \rrbracket \big\}$ is specified as the union of certain horizontal planar line segments, and certain vertical ones.
The horizontal segments take the form $[ z_k,z_{k+1} ] \times \{ k \}$ for $k \in \llbracket i , j \rrbracket$.
Here, the convention that $z_i = x$ and  $z_{j+1} = y$ is again adopted. 
The right and left endpoints of each consecutive pair of horizontal segments are interpolated by a vertical planar line segment of unit length. It is this collection of vertical line segments that form
the vertical segments of the staircase.

The resulting staircase may be depicted as the range of an alternately rightward and upward moving path from starting point $(x,i)$ to ending point $(y,j)$. 
The set of staircases with these starting and ending points will be denoted by $\staircase_{(x,i) \to (y,j)}$.
Such staircases are in bijection with the collection of non-decreasing lists considered above. Thus, any staircase $\phi \in \staircase_{(x,i) \to (y,j)}$
is assigned an energy $E(\phi) = \sum_{k=i}^j \big( B ( k,z_{k+1} ) - B( k,z_k ) \big)$ via the associated $z$-list. 



%Let $B:\Z \times \R \to \R$ be a collection of independent standard two-sided Brownian motions.


%Let $i,j \in \Z$ with $i \leq j$.
%We denote the integer interval $\{i,\cdots,j\}$ by $\llbracket i,j \rrbracket$.
%Further let $x,y \in \R$ with $x \leq y$.
%Consider the collection of  non-decreasing lists 
% $\big\{ z_k: k \in \llbracket i+1,j \rrbracket \big\}$ of values $z_k \in [x,y]$. 
%With the convention that $z_i = x$ and $z_{j+1} = y$,
%we associate an energy $\sum_{k=i}^j \big( B ( k,z_{k+1} ) - B( k,z_k ) \big)$ to any %such list.
%We then define  the maximum energy
%$$
%M^1_{(x,i) \to (y,j)} \, = \, \sup \, \bigg\{ \, \sum_{k=i}^j \Big( B ( k,z_{k+1} ) - B( k,z_k ) \Big) \, \bigg\} \, , 
%$$
%where the supremum is taken over all such lists. The random process $M^1_{(0,1) \to (\cdot,n)}: [0,\infty) \to \R$ was introduced by~\cite{GlynnWhitt} and further studied in~\cite{O'ConnellYor}.


\section{Mutually avoiding staircase collections -- and ensembles of energy profiles}

Let $n \in \N$ and $\ell \in \intint{n}$.

For $x > 0$, let $\staircase^\ell_{(0,1) \to (x,n)}$ denote the collection of $\ell$-tuples $\bar\phi = \big( \phi_1,\cdots,\phi_\ell \big)$, where
\begin{itemize}
\item $\phi_j \in \staircase_{(0,j) \to (x,n - \ell + j)}$ for $j \in \intint{\ell}$;
\item and the union of the horizontal planar segments of the $\phi_j$ are pairwise disjoint.
\end{itemize}

We define the energy $E (\bar\phi)$ of such a collection $\bar\phi$ by setting
$$
  E \big( \bar\phi \big) = \sum_{j=1}^\ell E(\phi_j) \, ,
$$
where note that the summand has already been defined. 

We now define the maximum $\ell$-tuple energy
$$
 M_n^\ell(x) = \sup \Big\{ E(\bar\phi): \bar\phi \in \staircase^\ell_{(0,1)\to(x,n)} \Big\} \, .
$$


\begin{definition}
The $n$-indexed Brownian LPP line ensemble $L_n: \intint{n} \times [0,\infty) \to \R$
is defined by insisting that, for $\ell \in \intint{n}$, 
$$
 M_n^\ell(x) = \sum_{i=1}^\ell L_n(i,x) \, .
$$
\end{definition}
In this way, $L_n(i,x)$ is the energy gain that arises when the number of disjoint staircases from $(0,1)$ to $(x,n)$ is increased from $i-1$ to $i$. It is thus not hard to see that $L_n(i,x) < L_n(i-1,x)$ whenever $i \geq 2$ and $x > 0$.

\begin{definition}
Let $n \in \N$. The Dyson Brownian motion line ensemble ${\rm DysonBM}_n: \intint{n} \times [0,\infty) \to \R$ is, formally, a system of $n$ standard Brownian motions on $[0,\infty)$ conditioned never to intersect (and recorded in decreasing order).
\end{definition}
The conditioning in this definition is singular and something needs to be done to make sense of it. The theory of the Doob-$h$ transform could be invoked. Or we could take the weak limit as $\e \searrow 0$ and $K \nearrow \infty$ of a system of Brownian motions each begun at distinct locations of absolute value at least $\e$ and conditioned on absence of intersection during $[0,K]$.

The fundamental relationship between Brownian LPP and mutually avoiding Brownian motions is next.

\begin{theorem}[O'Connell-Yor 2002]
Let $n \in \N$. The Brownian LPP and Dyson Brownian motion line ensembles, $L_n$ and ${\rm DysonBM}$, both map $\intint{n} \times [0,\infty)$ to $\R$. They are equaol in law.
\end{theorem}

Note that $L_n(1,n)$ is the geodesic energy for the journey $(0,1) \to (x,n)$. How does this random variable behave for high $n$? Since $L_n(1,n)$ is equal in law to ${\rm DysonBM}_n(1,n)$, a connection of Dyson Brownian motion to random matrix theory offers a means of furnishing an answer.

\begin{theorem}
Let $t > 0$. The point process indicated in the Figure~\ref{f.dysonbm}, namely $\big\{ {\rm DysonBM}_n(i,t): i \in \intint{n} \big\}$, is equal in law to the set of eigenvalues $\big\{ \lambda_n(i,t): i \in \intint{n}  \big\}$ of a matrix sampled from the Gaussian unitary ensemble with entry variance $t$.
\end{theorem}


\begin{figure}[ht]
\begin{center}
\includegraphics[height=8cm]{dysonbm.pdf}
\caption{The dots indicate the point process of values of Dyson Brownian motion at time $t$.}
\label{f.dysonbm}
\end{center}
\end{figure}   


Using this connection, and tail bounds on the top GUE eigenvalue due to Aubrun and Ledoux, it is understood that ${\rm DysonBM}_n(1,n)$ behaves to first order as $2n$; has standard deviation $n^{1/3}$; and upper bounds on the scaled tail of the form $C \exp \big\{ - c t^{3/2} \big\}$.

That is, setting
$$
 \mc{L}^{\rm sc}_{n} \big( 1,0 \big)
  = 2^{-1/2} n^{-1/3} \Big( L_n \big( 1, n  \big) - 2 n  \Big) \, ,
$$
we have:
\begin{proposition}\label{p.scaledonepoint}
There exist constants $C,c>0$ such that for every $n \in \N$ it is the case that
\begin{enumerate}
\item
for $s \in [0,2^{1/2}n^{1/3}]$,
$$
\PP \big( \mc{L}_n^\scal (1,0) \leq - s \big) \leq C \exp \big\{ - c s^{3/2} \big\} \, ,
$$
\item and, for $s \geq 0$,
$$
\PP \big( \mc{L}_n^\scal (1,0) \geq  s \big) \leq C \exp \big\{ - c s^{3/2} \big\} \, .
$$
\end{enumerate}
\end{proposition}
{\bf Proof.} The first statement 
is due to Ledoux and the second to Aubrun in view of the connections between GUE and the Dyson Brownian motion marginal, and between Dyson Brownian motion and Brownian LPP. \qed

As the notation $\mc{L}^{\rm sc}_{n} \big( 1,\cdot \big)$ suggests, we want to specify a stochastic process $\mc{L}^{\rm sc}_{n} \big( 1,\cdot \big)$ that describes the scaled energy of a geodesic from the origin to a further endpoint that is in a variable location. 



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{lnscaledunscaled.pdf}
\caption{The parallelogram on the left is mapped to the square on the right by an affine change of coordinates. The size of the parallelogram -- its height of order $n^{1/3}$ and its width of order $n^{2/3}$ -- are, in view of Proposition~\ref{p.scaledonepoint} and Brownian scaling, suitable for the specification of the scaled ensemble as the image curve collection on the right.}
\label{f.lnscaledunscaled}
\end{center}
\end{figure}   


In view of the consideration described in Figure~\ref{f.lnscaledunscaled}, we define the {\em scaled} Brownian last passage percolation line ensemble
$$
 \mc{L}^{\rm sc}_{n}: \intint{n} \times \big[- \tfrac{1}{2} n^{1/3} , \infty \big) \to \R 
$$
by setting, 
for $(i,x) \in \intint{n} \times \big[- \tfrac{1}{2} n^{1/3} , \infty \big)$,
\begin{equation}\label{e.scl}
 \mc{L}^{\rm sc}_{n} \big( i,x \big)
  = 2^{-1/2} n^{-1/3} \Big( L_n \big( i, n + 2n^{2/3} x \big) - 2 n - 2 n^{2/3}x \Big) \, .
\end{equation}

What does the scaled ensemble describe? 
A geodesic that runs from $(0,1)$ to $(n,n)$ has energy of the form $2n + \Theta(1) n^{1/3}$, where the random quantity $\Theta(1)$ is this geodesic's {\em scaled energy} or {\em weight}.
This weight is $\mc{L}^{\rm sc}_{n} (1,0)$. If instead  the geodesic runs from $(0,1)$ to $(n + 2n^{2/3},n)$, then the associated weight is $\mc{L}^{\rm sc}_{n}(1,1)$. In the case of a triple of disjoint staircases, the weight is $\sum_{i=1}^3 \mc{L}^{\rm sc}_{n} (i,0)$.



\begin{figure}[ht]
\begin{center}
\includegraphics[height=7cm]{NonIntPolyScaling.pdf}
\caption{Let $n \in \N$,  $t_1 <t_2$ be reals and also let $x, y \in \R$. The endpoints of the geodesic in the left sketch are such that, when the scaling map~$R_n$ is applied to produce the right sketch,  the result is an $n$-polymer from $(x,t_1)$ to $(y,t_2)$. We work with the special case $t_1= 0$ and $t_2=1$ -- but scaling considerations dictate the behaviour of the general case from the special one.
%$\rho_{n;(x,t_1)}^{(y,t_2)}$ results.
  }
\label{f.scaling}
\end{center}
\end{figure}  


Indeed, the affine scaling map $R_n: \R^2 \to \R^2$ given by 
$$
 R_n \big(v_1,v_2 \big) = \Big( 2^{-1} n^{-2/3}( v_1 - v_2) \, , \,   v_2/n \Big) \, .
$$ 
(and depicted in Figure~\ref{f.scaling})
sends staircases to $n$-{\em zigzags} and geodesics to {\em polymers} in such a way that 
$$
  \rho_{n;(0,0)}^{(x,1)} : = \textrm{the image under $R_n$ of the geodesic from $(0,1)$ to $R_n^{-1}(x,1)$} \, ,
$$
which is the polymer whose journey is between the scaled coordinate locations $(0,0)$ and $(x,1)$, may be viewed as having weight  $\mc{L}^{\rm sc}_{n}(1,x)$; while the multi-polymer  seen in the middle sketch of the upcoming Figure~\ref{f.threesketches} -- the scaled counterpart to the disjoint staircase triple mentioned a moment ago -- has weight  $\sum_{i=1}^3 \mc{L}^{\rm sc}_{n} (i,0)$.

\section{The Brownian Gibbs property}

This property is a crucial probabilistic tool for analysing mutually avoiding systems of Brownian motions, such as $L_n: \intint{n} \times [0,\infty) \to \R$ or indeed  $\mc{L}^{\rm sc}_{n} (: \intint{n} \times [0,\infty) \to \R$.

First a little notation. Let $k \in \N$. Write $\bar{x}$ for a vector in $\R^k$. Such a vector $\bar{x} = (x_1,x_2,\cdots,x_k)$ is a $k$-decreasing list if $x_i > x_{i+1}$ for $1 \leq i \leq k-1$.  Write $\Rkle \subseteq \R^k$ for the set of $k$-decreasing lists.

Recall Brownian bridge $B:[a,b] \to R$, $B(a) = x \in \R$, $B(b) = y \in \R$ -- this is Brownian motion $W:[a,b] \to \R$, $W(a)=x$, conditioned on $W(b) = y$.

\begin{definition}
Let $k\in \N$, $a,b \in \R$ with $a < b$, and $\bar{x},\bar{y}\in \Rkle$. Write $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}$ for the law of the
ensemble $B:\intint{k} \times [a,b] \to \R$ whose constituent curves $B(i,\cdot):[a,b] \to \R$, $i \in \intint{k}$, are 
independent Brownian bridges that satisfy $B(i,a) = x_i$ and $B(i,b) = y_i$. 


Let  $f:[a,b] \to \R \cup \{-\infty\}$ be a measurable function such that $x_k>f(a)$ and $y_k>f(b)$.
Define the non-touching event on an interval $A\subset [a,b]$ with lower boundary data $f$ by
\begin{equation*}
\notouch_f^A  =  \Big\{ \, \textrm{for all } x \in A \, ,  \,  B(i,x) > B(j,x) \textrm{ whenever } 1\leq i<j\leq k \, \, , \, \, \textrm{ and  $B(k,x) > f(x)$} \Big\} \, . 
\end{equation*}
We omit the subscript $f$ in the case that it equals $-\infty$ throughout $[a,b]$ (and thus plays no role). We omit the superscript $A$ in the case that $A = [a,b]$. With this convention, the event $\notouch$ always imposes {\em internal} curve avoidance, but only imposes {\em external} avoidance of the lower boundary condition when this is indicated in the subscript.

The conditional measure $\mc{B}^{[a,b]}_{k;\bar{x},\bar{y}} \big( \cdot \big\vert \notouch_f \big)$  is the  {\it mutually avoiding Brownian bridge ensemble on the interval $[a,b]$ with entrance data  $\vectoro{x}$, exit data $\vectoro{y}$ and lower boundary condition $f$}. 

We will sometimes refer to the {\em acceptance probability}, which is defined to be  $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}\big(\notouch_f  \big)$.
\end{definition}


The law $\mc{B}^{[a,b]}_{k;\bar{x},\bar{y}} \big( \cdot \big\vert \notouch \big)$ is a prototypical example of a line ensemble that enjoys the Brownian Gibbs property.

\begin{definition}
Let $\mc{L}: \intint{n} \times [a,b] \to \R$ be an ensemble. It satisfies the Brownian Gibbs property if, whenever $k \in \intint{n}$ and $[u,v] \subseteq [a,b]$, the conditional distribution of $\mc{L}$ restricted to $\intint{k} \times [u,v]$ given the data $\mc{L}$ on the remainder --  on $\intint{k} \times \big( [a,b] \setminus [u,v] \big) \, \cup \,  \llbracket \ell +1,n \rrbracket \times [a,b]$ -- equals $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}\big(\cdot \big\vert \notouch_f  \big)$, where $\bar{x} = \big( \mc{L}(1,u), \cdots, \mc{L}(k,u) \big)$, $\bar{y} = \big( \mc{L}(1,v), \cdots, \mc{L}(k,v) \big)$  and $f = \mc{L}(k+1,\cdot) \big\vert_{\cdot \in [u,v]}$. Here, we take $f =-\infty$ if $k = n$.
\end{definition}
See Figure~\ref{f.basicbg}.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=7cm]{basicbg.pdf}
\caption{In a rejection sampling view of the Brownian Gibbs resampling of the top three curves of an ensemble on the interval $[u,v]$, independent Brownian bridges on this interval with the respective bead endpoints are consecutively sampled until the outcome verifies the concerned avoidance constraints. The three bold dotted curves in the depicted attempt fail due to both internal and external violations of avoidance.}
\label{f.basicbg}
\end{center}
\end{figure}  


Back to the {\em scaled} Brownian last passage percolation line ensemble
$\mc{L}^{\rm sc}_{n}: \intint{n} \times \big[- \tfrac{1}{2} n^{1/3} , \infty \big) \to \R$.
Recall Figure~\ref{f.lnscaledunscaled}, which offered a schematic depiction of the highest two curves in the unscaled and scaled ensembles for a high value of~$n \in \N$. The dashed parallelogram on the left transforms into the dashed square on the right under the affine change of coordinates in~(\ref{e.scl}) by which $\mc{L}_n^{\scal}$ is formed from $L_n$.  The right sketch depicts when $n$ is large the highest curves in $\mc{L}^\scal_n$. These surge upwards until, far to the left of the origin, -- at scale $-n^{-1/9}$ -- they join a bounded channel about the parabola $- 2^{-1/2} x^2$, which they then typically inhabit until far beyond the origin on the right, -- at scale~$n^{1/9}$ -- when the parabola drops away beneath them. We may expect then that the scaled ensemble  $\mc{L}^{\rm sc}_{n}$:
\begin{itemize}
\item satisfies the Brownian Gibbs property;
\item satisfies one-point tails on the top curve inherited from Aubrun and Ledoux;
\item and in the large is parabolic.
\end{itemize}
The next definition captures all this.

By a {\em Brownian Gibbs ensemble}, we mean a line ensemble that satisfies the Brownian Gibbs property. 


\begin{definition}\label{d.regularsequence} 
%Let $n \in \N$ and $\xnmac \in [0,\infty)$. 
%
Consider a Brownian Gibbs ensemble that has the form
$$
\mc{L}: \intint{n} \times \big[ - z_n , \infty \big) \to \R   \, ,
$$
and which is defined on a probability space under the law~$\PP$.
The number $n$ of ensemble curves and the absolute value $z_n$ of the finite endpoint may take any values in $\N$ and $[0,\infty)$.
(In fact, we may also take $z_n = \infty$, except that we would then take the domain of definition of $\mc{L}_n$ to be $\intint{n} \times \R$.)

For two constants $C \geq c > 0$, the ensemble $\mc{L}$ is called  $(\rsc,\rsC)$-regular -- or, in practice, simply regular  --  if:
\begin{enumerate}
\item {\bf Endpoint escape.} $z_n \geq  \rsc n^{1/3}$.
\item {\bf One-point lower tail.} If $z \geq - z_n$ satisfies $\vert z \vert \leq \rsc n^{1/9}$, then
$$
\PP \Big( \mc{L} \big( 1,z\big) + 2^{-1/2}  z^2 \leq - s \Big) \leq \rsC \exp \big\{ - \rsc s^{3/2} \big\}
$$
for all $s \in \big[1, \nmac^{1/3} \big]$.
\item {\bf One-point upper tail.}  If $z \geq - z_n$ satisfies $\vert z \vert \leq \rsc  n^{1/9}$, then
$$
\PP \Big( \mc{L} \big( 1,z\big) +  2^{-1/2} z^2 \geq  s \Big) \leq \rsC \exp \big\{ - \rsc s^{3/2} \big\}
$$
for all $s \in [1, \infty)$.
\end{enumerate}
\end{definition}

\begin{proposition}\label{p.lereg}
There exist choices of the positive constants $\rsc$ and $\rsC$ such that each of the scaled Brownian LPP line ensembles
$\mc{L}_n^{\scal}: \intint{n} \times \big[- \tfrac{1}{2} n^{1/3}  , \infty \big) \to \R$, $n \in \N$,  
is $(\rsc,\rsC)$-regular.
 \end{proposition}
 {\bf Proof.} Details are omitted, but in essence this is the Brownian Gibbs property, which is inherited from ${\rm DysonBM}_n$ via O'Connell-Yor, along with Aubrun's and Ledoux's tail bounds on the top eigenvalue in ${\rm GUE}_n$. \qed
 
 Now 
$\mc{L}_n^{\scal}$ 
 enjoys integrable features -- for example, there are determinantal expressions for probabiliities such as that of the event depicted in Figure~\ref{f.determinantaltouch}, in which each of the very short vertical intervals is visited by one of the curves in the ensemble. Pr{\"a}hofer and Spohn~\cite{PrahoferSpohn} introduced in 2002 what they called the multi-line Airy process -- in essence, the high-$n$ limit of the ensemble $\mc{L}_n^{\scal}$ when the limit is taken in the sense of finite dimensional distributions. 
 

\begin{figure}[ht]
\begin{center}
\includegraphics[height=7cm]{determinantaltouch.pdf}
\caption{Imagine that each of the depicted vertically aligned intervals has an infinitesimal length ${\rm d}x$. The depicted curves of $\mc{L}_n^{\scal}$ collectively visit all these intervals. The probability of this happening has the form $h \big( {\rm d} x \big)^K$, where $K$ denotes the number of the intervals. The factor $h$ depends on the intervals' locations and has a determinantal expression.}
\label{f.determinantaltouch}
\end{center}
\end{figure}   
 
 The first application of the Brownian Gibbs property was in joint work with Ivan Corwin:
 \begin{theorem}[\cite{AiryLE}]
 We may couple the ensembles 
$\mc{L}_n^{\scal}$, $n \in \N$, on a single probability space so that the restrictions 
$\mc{L}_n^{\scal}: \intint{k} \times I \to \R$ (where here $k \in \N$ is any positive integer, and $I \subset \R$ any compact interval)
converge uniformly to the restriction to this domain of a non-intersecting ensemble
$\mc{L}: \N \times \R \to \R$ (with $\N = \{1,2\cdots \}$) that satisfies the Brownian Gibbs property.

Indeed, setting $\mc{A}(i,x) = 2^{1/2} \mc{L}(i,x) + x^2$, $\mc{A}: \N \times \R \to \R$ is an ensemble that is stationary in $x$ -- this is the Airy line ensemble. 
 \end{theorem} 
 We will not explain the proof, but the basic idea is to use finite dimensional convergence, with the Brownian Gibbs property furnishing the necessary regularity. We will explain now at least a little of the technical aspect of this convergence. Consider a Brownian Gibbs resampling of 
$\mc{L}_n^{\scal}$, i.e., a random map sending the law 
$\mc{L}_n^{\scal}$ 
 to itself in which say the top two curves of this ensemble are resampled on the interval $[-1,1]$. 
 The conditional distribution in the update step is $\mc{B} \big( \cdot \big\vert \notouch_f \big)$, where $\mc{B} = \mc{B}_{2;x_1,x_2,y_1,y_2}$ and $f = 
\mc{L}_n^{\scal}(3,\cdot)$, $x_1 = 
\mc{L}_n^{\scal}(1,-1)$,   $x_2 = 
\mc{L}_n^{\scal}(2,-1)$,   $y_1 = 
\mc{L}_n^{\scal}(1,1)$ and   $y_2 = 
\mc{L}_n^{\scal}(2,1)$. 

Recall the acceptance probability $\mathscr{A}_n = \mc{B} \big( \notouch_f \big)$. The law $\mc{B}$ is unadulterated Brownian randomness -- with square-root regularity for curve fluctuation, enough for tightness given finite dimensional distributional control. In the resample that maps $\mc{L}_n^{\scal}$ to itself, it is the possible rarity of $\notouch_f$ -- the possibly low value of the acceptance probability -- which may disrupt the presence of this unadulterated Brownian randomness in the image copy of $\mc{L}_n^{\scal}$. So the key technical proposition in~\cite{AiryLE} states:
\begin{proposition}\label{p.accprob}
For all $\e > 0$, there exists $\delta > 0$ such that, for $n \in \N$, 
$$
 \PP \big( \mathscr{A}_n \geq \delta \big) \geq 1 - \e \, .
$$
\end{proposition}
We will not return to establish this, but we will extensively discuss ideas that can rather quickly give a proof of this proposition.

A principal consequence of this main theorem of~\cite{AiryLE} is:
\begin{theorem}\label{t.mainconseq}
Let $\mc{L}: \N \times \R \to \R$ denote the weak limit of $\mc{L}_n^{\scal}$ as $n \to \infty$. Let  $k \in \N$ and let $I = [x,y] \subset \R$ be a compact interval. Then the random function $I \to \R: z \to \mc{L}(k,z) - \mc{L}(k,x)$ is absolutely continuous with respect to Brownian motion.  
\end{theorem}
       We will consistently reserve the symbol $\mc{L}$ to denote this ensemble 
$\mc{L}: \N \times \R \to \R$.

{\bf Proof of Theorem~\ref{t.mainconseq}.} This is in essence a consequence of $\mc{L}$  being a Brownian Gibbs ensemble that is ordered, since this forces the acceptance probability on $\intint{k} \times I$ to be almost surely positive. \qed 

The conclusion offered by Theorem~\ref{t.mainconseq} was recently strengthened and quantified by an extensive analysis using the Brownian Gibbs property.

A little further notation is needed to describe these more recent results.

Let $f:[a,b] \to \R$ be a continuous function. Such a function will be called a {\em standard bridge} if $f(a) = f(b) = 0$. 

For a general continuous function $f:[a,b] \to \R$, we define $f^{{a,b}}: [a,b] \to \R$ to be the unique standard bridge obtained by affine translation of $f$. That is,
$$
 f^{[a,b]} (x) = f(x)  - \tfrac{b-x}{b-a} f(a)  - \tfrac{x-a}{b-a} f(b)  \, \, \, \textrm{for $x \in [a,b]$} \, .
$$ 
The notation extends to line ensembles:
let $n \in \N$ and  $a,b \in \R$ satisfy $-z_n \leq a \leq b$. Consistently with the bridge notation, we specify the standard bridge ensemble
$\mc{L}_{n}^{[a,b]} : \intint{n} \times [a,b] \to \R$ induced on~$[a,b]$ by $\mc{L}_n$ to be  
$$
\mc{L}_{n}^{[a,b]}\big( i, x \big) = 
\mc{L}_{n}\big( i, x \big) \, - \,
\ell_{n}^{[a,b]}\big( i, x \big) \, \, \, \textrm{for $(i,x) \in \intint{n} \times [a,b]$} \, , 
$$
where 
$\ell_{n}^{[a,b]}\big( i, \cdot \big)$ denotes the affine function whose values at $a$ and $b$ are $\mc{L}_n\big(i,a\big)$ and $\mc{L}_n\big(i,b\big)$. 

Write $\mc{C}_{0,0} \big( [a,b], \R \big) = \big\{ f:[a,b] \to \R: \textrm{$f$ is a standard bridge} \big\}$. If $B:[a,b] \to \R$ is Brownian motion, then $B^{[a,b]}$ is $\mc{B}_{1;0,0}^{[a,b]}$-distributed. This law is called {\em standard Brownian bridge}. 

To say that $\mc{L}_n^{\scal}(1,\cdot): [-1,1] \to \R$
is {\em uniformly absolutely continuous}
with respect to Brownian motion on $[-1,1]$
is to assert that for all $\e > 0$, there exists $\delta > 0$ such that, for all $n \in \N$, the condition that 
$$ 
\mc{B}_{1;0,0}^{[a,b]} \big( B \in A \big) < \delta
$$ 
for any given measurable subset $A \subseteq \mc{C}_{0,0} \big( [a,b], \R \big)$ (and where $B = B(1,\cdot)$) implies that
$$
 \PP \big( \mc{L}_n^{\scal}(1,\cdot) \in A  \big) < \e \, .
$$ 
This is in essence the state of affairs achieved by~\cite{AiryLE} -- uniformity of comparison between ensemble curves and Brownian motion is achieved in the curve index $n$, but without any quantitative relation being demonstrated between the parameters $\e$ and $\delta$.

When quantitative relation is known between these parameters that takes a power law form, a moment bound results on the Radon-Nikodym derivative of the two concerned measures on continuous curves. 

Indeed, suppose that $\mu$ and $\nu$ are two probability measures on a common measurable space $(\Omega,\mc{F})$. To make the assertion concerning a {\em Radon-Nikodym moment bound} that
$$
\tfrac{{\rm d}\nu}{{\rm d}\mu} \in L^{\beta-}({\rm d}\mu) \, \, \, \textrm{for a given $\beta \in [1,\infty)$}
$$
is the same as claiming about the {\em deformation in probability of rare events} that
$$
 \forall \eta \in (0 , 1 - \beta^{-1}), \exists C = C_\eta \, \, \textrm{such that $\forall A \in \mc{F}$,} \, \, \, \nu(A) \leq C \mu(A)^\eta \, .
$$

We quantify the comparison of the curves in $\mc{L}_n^{\scal}$ or in its high~$n$ limit $\mc{L}$ with Brownian bridge by using the latter language, of deformation in probability of rare events. 

Recall that each $\mc{L}_n^{\scal}$ is a $(c,C)$-regular ensemble -- and so is $\mc{L}$, with a tiny abuse of notation.

Here is the quantified comparison -- one of the main theorems of [H17a].

\begin{theorem}[Brownian bridge regularity]\label{t.bbr}
Let $n \in \N$. Suppose that $\mc{L}_n$ is an $n$-curve regular ensemble. Let $K \in \R$ satisfy $[K,K+1] \subset c/2 \cdot [-n^{1/9},n^{1/9}]$. Let $k \in \N$ denote a curve index. Let  $A \subseteq \mc{C}_{0,0} \big( [K,K+1], \R \big)$ be measurable, and set $a = \mc{B}_{1;0,0}^{[K,K+1]}(A)$. 

If $n \geq n_0 (k)$, $a \leq a_0(k)$ and 
\begin{equation}\label{e.alb}
a \geq \exp \big\{ - c_1(k) n^{1/12} \big\} \, ,
\end{equation}
then 
$$
 \PP \Big( \mc{L}_n^{[K,K+1]} (k,\cdot) \in A \Big) \leq a \cdot \exp \Big\{ \big( \log a^{-1} \big)^{5/6} O_k(1) \Big\} \, ,
$$
where $O_k(1)$ is a $k$-dependent term which has no dependence on $a$ or $n$.
\end{theorem}
That is, deformation of rare events is controlled strongly, with for example an event whose Brownian bridge probability is $a$ having ensemble probability at most $a^{1 - o(1)}$ where the term $a^{-o(1)}$ is controlled uniformly in high ensemble curve number $n$.

There are two caveats about the theorem: 

{\em 1.} Comparison is made of the standard bridge-valued $\mc{L}_n^{[K,K+1]}$ to Brownian bridge. The theorem does not attempt comparsion of $\mc{L}_n(1,\cdot) - \mc{L}_n(1,K): [K,K+1] \to \R$ to standard Brownian motion on $[K,K+1]$.

{\em 2.} Imposing condition~(\ref{e.alb}) entails that extremely small probability events are not considered -- in a strongly  $n$-dependent sense of `small'. Note however that when $\mc{L}$ is considered, so that $n =  \infty$, this condition is vacuously satisfied. In the $n = \infty$ case, then, the theorem implies that 
$\tfrac{{\rm d}\nu}{{\rm d}\mu} \in L^{\infty-}({\rm d}\mu)$ where $\mu = \mc{B}_{1;0,0}^{[-1,1]}$ and $\nu$ is the law of $\mc{L}^{[-1,1]}(1,\cdot) - \mc{L}^{[-1,1]}(1,-1): [-1,1] \to \R$.

To give a practical sense of the strength of the comparison, we provide a corollary. Recall first that 
$$
\mc{B}_{1;0,0}^{[0,1]} \Big( \sup_{x \in [0,1]}  \big\vert B(1,x) \big\vert > s \Big)  \in [1,2] \cdot e^{-2s^2} \, .
$$
\begin{corollary}
$$
 \PP \Big(  \sup_{x \in [0,1]}  \big\vert \mc{L}^{[0,1]}(1,x) \big\vert \geq  s  \Big) \leq C_1 \exp \big\{ -2 s^2 (1 - c_1 s^{-1/3}) \big\} \, .
$$
\end{corollary}

Now the second main theorem.
\begin{theorem}[$k$-curve closeness at one point]\label{t.kneartouch}
Let $\mc{L}_n$ be a regular ensemble. Then the probability that $\mc{L}_n(k,0) \geq \mc{L}_n(k,1) - \eta$ behaves as $\eta^{k^2 - 1 + o(1)}$ for small $\eta > 0$.
\end{theorem}
The event that the top $k$ curves in a regular ensemble come within $\eta$ of each other has particular significance when that ensemble is $\mc{L}^\scal_n$ . As Figure~\ref{f.threesketches} illustrates, this circumstance occurs when there exists a collection of mutually disjoint staircases with shared endpoints each of whose members comes close to attaining the maximum energy among staircases with these endpoints -- where by `clse' is meant within order $\eta$ if the measurement is undertaken in scaled units. This phenomenon is closely related to the mutual coexistence of geodesics with endpoints that are at a small positive distance when this distance is also measured in scaled units -- so that Theorem~\ref{t.kneartouch}, in asserting the rarity of near touch among the top several curves in regular ensembles, also has much to say in an effort to prove that such mutual coexistence of geodesics is unlikely in Brownian LPP. 
\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{threesketches.eps}
\caption{{\em Left:} In the formation of the Brownian last passage percolation line ensemble, the maximum triple energy  $M^3_n(t) =\sum_{i=1}^3 L_n(i,t)$, for $t > 0$ given, is formed by considering the sum of the increments on the intervals indicated by horizontal solid black lines of the depicted independent Brownian motions and finding the maximum possible such value. {\em Middle:} Taking $n$ large and setting $t = n + 2n^{2/3}x$ for a given $x \in \R$, we may consider the maximizing triple and depict it after the change of coordinates $(x_1,x_2) \to \big( \tfrac{1}{2} n^{-2/3}(x_1-x_2), x_2 n^{-1} \big)$. If $n$ is high enough, the semi-discrete structure will be indiscernible in the new sketch, and the triple of paths --  a multi-polymer watermelon -- will appear to share the endpoints $(0,0)$ and $(1,x)$. 
{\em Right:} Suppose that, in the middle sketch, %the event $\neargeod_{n,3}\big( x,r \big)$ occurs for a given small $r > 0$, 
the elements in the path triple have very similar energies, with a collective deficit of $r n^{1/3}$ over the total available in principle, where $r > 0$ is a given small value. Measuring the deficit in units of $2^{1/2} n^{1/3}$,  a $2^{-1/2}r$-near touch will arise between the top three curves in the scaled ensemble $\mc{L}^\scal_n$ over location~$x$.}
\label{f.threesketches}
\end{center}
\end{figure}    
The last two theorems are the principal conclusions of the Brownian Gibbs analysis in [Ham17a]. Along the way to their derivation, a result depending on some of the apparatus needed to derive them concerns local fluctuation of the curves in regular ensembles. For convenience, we state this result merely for the $n=\infty$ case.
\begin{theorem}[Local Fluctuation]\label{t.locfluc}
Let $\mc{A}:\R \to \R$ denote the {\rm Airy}$_2$ process. There exist $M,m > 0$ such that, for all $x \in \R$, $\e \in (0,1]$ and $K > 0$,
$$
 \PP \Big( \sup_{h \in (0,\e)} \big\vert \mc{A}(x+h) - \mc{A}(x) \big\vert \geq K \e^{1/2} \Big) \leq M e^{- m K^{3/2}} \, ;
$$
here $\mc{A}$ could equally be replaced by $\mc{L}$.
\end{theorem}
The route to our two main theorems can be presented as a journey of three stages, labelled `basic', `intermediate' and `advanced'. Figure~\ref{f.methods} summarises this.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=7cm]{methods.eps}
\caption{The three-stage journey to our two main theorems.}
\label{f.methods}
\end{center}
\end{figure} 

As we turn to attempting to explain the proof of the principal result Theorem~\ref{t.bbr} on Brownian bridge regularity, we will follow this three-stage journey. This second lecture ends by discussing the first step -- the basic elements of the Brownian Gibbs approach.

\section{Stage One: Brownian Gibbs basics}

Five basic general properties of Brownian Gibbs ensembles are needed.
\begin{itemize}
\item A: Monotonicity lemmas
\item  B: Stopping domain Brownian Gibbs resampling
\item C: No Big Max
\item D: Near parabolic invariance of regular ensembles
\item E: Control on lower curves
\end{itemize}

We discuss these briefly in turn. 

{\em A: Monotonicity lemmas.}  Consider the basic law $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}$ which appears in the BG resampling associated to $\intint{k} \times [a,b]$.
We want to record two forms of stochastic monotonicity regarding this law. The first concerns the replacement of the left or right boundary vectors $\bar{x}$ or $\bar{y}$ by a new vector whose components are all at least as high as their counterparts in the replaced vector. The effect is to send the law upwards, in the sense that the original law and the new one may be coupled together so that the curves in the new law are always at least as high as their counterparts in the original.

In its second form, the monotonicity result asserts that the same response occurs when we instead replace the lower boundary condition by a function which is pointwise at least as large. 

These results were proved in~\cite{AiryLE} by a technique which is a simple illustration of the principle that, in order to understand a given random system, it is sometimes useful to embed that system in a higher dimensional  random object, and analyse the latter instead. In the present case, we first move to a discrete system, with fine mesh mutually avoiding random walks approximating the curves in the law  $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}$ . Then we introduce a Markov dynamic that at a given step attempts a local change in the form of one of these walks. We design the dynamic so that it converges in the limit of many updates to the mutually avoiding system of walks that interests us -- our approximation of   $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}$. Then we run the dynamic simultaneously on two configurations, one with boundary data approximating   $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}$ and one with data approximately the modified form of this law in which either the boundary vectors or the lower boundary condition have been increased. We find an explicit initial condition for the two sets of walkers that respect the sought monotonicity -- with the curves in the altered system being at least as high as in the original one. Then we check that any given update for the dynamic -- an update which is shared in the two systems -- never creates a violation of monotonicity. Since the two systems converge in the limit of many updates to the approximations of the law   $\mc{B}_{k;\bar{x},\bar{y}}^{[a,b]}$ and its upward perturbed counterpart, this monotonicity transmits as desired to this law and its perturbation.


{\em B: Stopping domain Brownian Gibbs resampling.}

The basic BG resample indexed by $\intint{k} \times I$ involves a deterministic number of curves $k$ and a deterministic interval $I$. We strengthen this, keeping $k$ fixed, but permitting $I$ to be random. The random interval~$I$ cannot have an arbitrary form of randomness if the BG rule governing the resampling is to remain valid -- one must not peek inside the curve data in $\intint{k} \times I$ if the validity of the rule is to remain valid. The random interval $I$ is permitted to be a {\em stopping domain} -- in essence, we may examine the top $k$ curves is a rightward sweep, stopping whenever we please as the new data comes in, and declare our location of stopping to be the left endpoint of $I$. And similarly, we may sweep to the left to find the right endpoint. This done so that $I$ is non-empty, naturally. Such a stopping domain has been found without the observer ever peeking into $\intint{k} \times I$ -- so that the original BG resample rule works in this setting. 

{\em C: No Big Max}

The axioms of a regular ensemble ensure that the upper tail of the top curve above one point -- a random variable such as $\mc{L}_n^{\scal}(1,0)$ -- has a rapidly decaying tail. But what of the maximum value attained by the ensemble's top curve on a compact interval -- a quantity such as  $\sup \big\{ \mc{L}_n^{\scal}(1,x) : x \in [-1,1] \big\}$? In principle, this could be much higher, even if the finite dimensional distributions of the ensemble are controlled. But the Brownian Gibbs property keeps the maximum on the same scale as the one-point statistic.

\begin{proposition}[No Big Max]\label{p.nobigmax} 
Let $\mc{L}_n$ be an $n$-curve regular ensemble.  For $r \in \big[0,\rsc/2 \cdot n^{1/9}\big]$, $t \in \big[ 2^{7/2} , 2 n^{1/3} \big]$ and $n \geq (2c)^{-18}$,
$$
\PP \Big( \sup_{x \in [-r,r]} \big( \mc{L}_n ( 1,x ) + 2^{-1/2}x^2 \big) \geq t \Big) \leq  (r + 1) \cdot  6  \rsC \exp \big\{ - 2^{-9/2} \rsc  t^{3/2} \big\} \, . 
$$
\end{proposition}
{\bf Proof.} This amounts to showing that
\begin{equation}\label{e.high}
 \PP \big( \mathsf{High}(t) \big) \leq C e^{-c t^{3/2}} \, ,
\end{equation}
where 
$$
\mathsf{High}(t) = \Big\{   \sup_{x \in [-1,1]} \mc{L}_n(1,x) \geq t  \Big\} \, .
$$
We prove this by using a stopping domain BG resampling. We search in $[-1,1]$ from the left until we encounter a random $X$ in this interval for which $\mc{L}_n(1,X) \geq t$. 
Then we consider the random interval $[X,2]$ -- it may be the interval $[1,2]$ if such $X$ is never encountered; but no matter. A little control is needed at a point, chosen to be~$2$, beyond the right-hand endpoint of the interval~$[-1,1]$ -- we know that $\mc{L}_n(1,2)$ is at least $-t/3$ except on an event of probability $C e^{-ct^{3/2}}$, because this one-point lower tail bound is addressed in the definition of a regular ensemble. 

Consider what happens when the BG resampling associated to $\{ 1 \} \times [X,1]$ occurs in the presence of the event $\mathsf{High}(t) \cap \big\{ \mc{L}_n(1,2) \geq - t/3  \big\}$. In this case, $X < 1$. Consider the value of the resampled curve at the point $1$. The resample has the law of Brownian bridge on $[X,1]$ with left endpoint at least $t$; with right endpoint at least $-t/3$; and with lower boundary condition provided by the second ensemble curve on $[X,2]$. If we remove this second curve, and replace the left endpoint by the value $t$, and the right endpoint by the value $-t/3$, we only decrease the probability that the resampled curve at $1$ exceeds any given level -- this is the content of the two monotonicity results treated in 
{\em Basics A}. But the law resulting from these alterations could not be simpler -- it is Brownian bridge on the interval $[X,1]$ with left value $t$ and right value $-t/3$. This process has probability at least one-half to assume a value greater than the affine interpolation of those end values; and, since $X \geq -1$, the latter value is at least $t/9$.

In summary, the resampled process' value at $1$ exceeds $t/9$ with probability at least 
$$
 \tfrac{1}{2} \cdot \PP \Big( \mathsf{High}(t) \cap \big\{ \mc{L}_n(1,2) \geq - t/3  \big\}\Big) \, .
$$
But the random resampling maintains the law of the ensemble -- and since the ensemble is regular, we have a bound on how rare this outcome is:
$$
  \PP \Big(  \mc{L}_n(1,1) \geq t/9 \Big) \leq C \exp \big\{ - c (t/9)^{3/2} \big\} \, .
$$
Thus we find that 
$$
 \PP \Big( \mathsf{High}(t \Big) \leq   \PP \big(\mc{L}_n(1,2) <  - t/3 \big) + 2C \exp \big\{ - c (t/9)^{3/2} \big\} \leq \Theta(1) \exp \big\{ - \Theta(1) (t/9)^{3/2} \big\} \, .
$$
This is a consequence of the sought form~(\ref{e.high}). \qed

The last proof is a simple demonstration of BG resampling -- it shows how exceptional behaviour, such as a very high value for the top curve in a BG ensemble, can become typical, with in this case the high value spreading under resampling to occur on a unit-order interval.

{\em D: Near parabolic invariance of regular ensembles}

This is a simple property about which we comment only briefly. A regular ensemble's top curves on a compact interval about the origin are locally Brownian, and, on a slightly larger scale, they are globally parabolic -- they hew to the parabola $-Q$, where $Q(x) = 2^{-1/2}x^2$. Suppose instead that we view the top curves on a compact interval centred instead at a point $x$ which satisfies $\vert x \vert \leq c/2 \cdot n^{1/9}$. The top curves are rapidly ascending if $x$ is negative (and large, subject to its constraint); or rapidly descending if $x$ is positive and large. Change coordinates by adding a suitable linear function to flatten the curves in this neighbourhood -- and then shift the picture so that the top curves in this neighbouthood are now above the origin at roughly unit height. It is a basic consequence of the definition of a regular ensemble that the resulting ensemble remains regular -- with a small adjustment, in the values of the parameters $c$ and $C$. That is, the top curves are locally Brownian, and hew again to the parabola $-Q(x)$ on large scales, up to horizontal scale $n^{1/9}$. 

The role of this near parabolic invariance is to permit us to take a result proved near the origin, such as the No Big Max Proposition~\ref{p.nobigmax} -- and to extend its domain of validity to a much wider region of $x$-coordinates -- to these $x$ at or below scale $n^{1/9}$.


{\em E: Control on lower curves}

This is our final basic BG input.
The definition of regular ensemble insists on the BG property and one-point control on the top curve -- nothing else. Using the BG property, we work to propagate understanding of one-point behaviour to lower curves in the ensemble. By induction, for increasing $k \in \N$, we may thus prove:
$$
 \PP \Big( \mc{L}_n(k,0) \leq -s \Big) \leq C_k e^{- c_k s^{3/2}} \, .
$$ 
We will not explain how this induction works -- but it is a BG resample argument. We will need this lower curve control in the intermediate and advanced steps, as we progress towards the proof of the Brownian bridge regularity  Theorem~\ref{t.bbr}. The recorded bound could well be also available from determinantal or other integrable techniques but we have not found it in the literature. 


\chapter{Lecture Three: Local fluctuation results via the Wiener candidate}

This lecture is devoted to proving the Local Fluctuation Theorem~\ref{t.locfluc}. This is the second, {\em intermediate}, stage in the three-stage journey to the principal Brownian bridge regularity Theorem~\ref{t.bbr}.
The intermediate step involves introducing a new resampling of an ensemble, one that is a little more subtle than the basic BG resampling -- the objects we introduce, which will be used again in the final lecture, are {\em missing closed middle reconstruction} and the associated {\em Wiener candidate}.

First a note about the construction of the Brownian bridge law $\mc{B}_{1;x,y}^{[a,b]}$, whose sample $B:[a,b] \to \R$, $B(a) = x$, $B(b) = y$, we here call simply $B$, rather than $B(1,\cdot)$.

Let $[u,v] \subseteq [a,b]$. The process $B$ may be constructed by
\begin{enumerate}
\item sampling its pair value $(B(u),B(v))$ according to the density on $\R^2$ whose value at $(z_1,z_2)$ is, up to a factor of normalization, equal to
$$
 \exp \Big\{ - \tfrac{(x-z_1)^2}{2(u-a)} - \tfrac{(z_2-z_1)^2}{2(v-u)} - \tfrac{(z_2-y)^2}{2(b-v)} \Big\} \, ;
$$
\item constructing three independent standard Brownian bridges on the intervals $[a,u]$, $[u,v]$ and $[v,b]$;
\item and then forming $B:[a,b] \to \R$ by adding the function that interpolates the values of $B$ on the four-point set $\{ a,u,v,b \}$ on which it is already constructed and the sum of the three sampled standard bridges.
\end{enumerate}
Very similarly, we may represent the process $B$ by a list of data
\begin{itemize}
\item its values $(B(u),B(v))$;
\item and the three standard bridges $B^{[a,u]}$,  $B^{[u,v]}$ and  $B^{[v,b]}$. 
\end{itemize}
We now split this data in different way, into two pieces of data, which -- for reasons to be explained momentarily -- we call the {\em retained} and the {\em lost} data.
The retained data is
\begin{itemize}
\item the bridges  $B^{[a,u]}$ and  $B^{[v,b]}$.
\end{itemize}
The lost data is then presented in a {\em two-piece list} in the form:
\begin{itemize}
\item the values $(B(u),B(v))$;
\item and the bridge  $B^{[u,v]}$.
\end{itemize}
We may equally present the lost data in a {\em one-piece list}:
\begin{itemize}
\item the marginal  $B: [u,v] \to \R$.
\end{itemize}
Why these names? Suppose that an experimenter realizes the process $B$ according to the law $\mc{B}_{1;x,y}^{[a,b]}$, and records the outcome in the form of retained and lost data. Suppose then that the experimenter discards the lost data, and hands only the retained data to an observer, who is aware that $B$ has been sampled according to $\mc{B}_{1;x,y}^{[a,b]}$. The observer has all information except the lost data.

Let $\mc{F}$ denote the $\sigma$-algebra of information to which the observer is privy -- the $\sigma$-algebra
 generated by the retained data. Let $\PP_{\mc{F}}$ denote conditional probability given $\mc{F}$.
 That is, $\PP_{\mc{F}}(A) = \E \big[ {\bf 1}_A \big\vert \mc{F} \big]$.  
 
 We will view the observer's perspective in view of an attempt that the observer may make to reconstruct the process $B$ given the available, retained, data.
 The law $\mc{F}$ represents this perspective. The observer may choose to describe the conditional distribution of what is unknown by recording a random process of lost data in either one-piece of two-piece list form. 

If two-piece list form is adopted, then the unknown data has the form of a point-pair value at $u$ and $v$; and a standard bridge on $[u,v]$. The sampling of these data may be viewed by placing a pair of beads on vertical rods at $x$-coordinates $u$ and $v$ at heights respectively dictated by the sampled point-pair value; adding the standard bridge on $[u,v]$
to the affine interpolation on $[u,v]$ of the bead locations; and affinely translating the two side bridges to meet their fixed endpoints at $a$ and at $b$ and the bead locations. 

In the one-piece list perspective, the observer reconstructs the lost data -- the marginal process $B:[u,v] \to \R$ -- by sampling $W:[u,v] \to \R$
as the marginal on $[u,v]$ of a realization
 %$W:[a,b] \to \R$ 
of the bridge law $\mc{B}_{1;x,y}^{[a,b]}$ that is sampled independently of the retained data; then the observer sets $B$ on the side intervals $[a,u]$
and $[v,b]$ by affinely translating the retained side bridges in accordance with their fixed endpoints and the variable ones specified by the already determined values $B(u)$
and $B(v)$.

\section{Reprising this for real -- with a regular ensemble}

We will work with the ensemble $\mc{L}: \N \times R \to \R$ for simplicity. Missing closed middle reconstruction is the reconstruction of $\mc{L}$ which is counterpart to the Brownian bridge case just discussed. 

The reconstruction has three parameters $T > 0$, $\ell \in [-T,0]$ and $r \in [0.,T]$.
The interval $[-2T,2T]$ is partitioned 
$$
  \big[-2T,2T\big]  =  \big[ - 2T,\ell\big] \cup  \big[\ell,r\big]  \cup \big[r,2T\big] 
$$
The left interval, counterpart to $[a,b]$ is partitioned into a {\em middle} interval $[\ell,r]$, counterpart to $[u,v]$, and two {\em side} intervals: $[-2T,\ell]$ on the left and $[r,2T]$ on the right.

We now record a presentation of the ensemble  $\mc{L}: \N \times R \to \R$ into retained and lost data, in which the lost data is recorded in either one-piece or two-piece list form.

The retained data is:
\begin{itemize}
\item the top curve $\mc{L}(1,\cdot)$ on $\R \setminus [-2T,2T]$;
\item all lower curve data $\mc{L}(k,x)$ for $k \geq 2$ and $x \in \R$; 
\item and the side bridges $\mc{L}^{[-2T,\ell]}(1,\cdot)$
and   $\mc{L}^{[r,2T]}(1,\cdot)$.
\end{itemize}
In its two-piece list form, the lost data is 
\begin{itemize}
\item the middle bridge $\mc{L}^{[\ell,r]}(1,\cdot)$;
\item and the pair values $\big( \mc{L}(1,\ell), \mc{L}(1,r) \big)$.  
\end{itemize}
In its one-piece list form, the same data is
\begin{itemize}
\item the process $\mc{L}(1,\cdot): [\ell,r] \to \R$.
\end{itemize}
Consider then the perspective of the observer who is presented merely with the retained data. We again write $\mc{F}$ for the $\sigma$-algebra of the retained data to which the observer is has access; and write $\PP_{\mc{F}}$ for conditional probability given $\mc{F}$.

{\em Viewing $\mc{L}$ from the observer's perspective.}
The observer's point of view is depicted in Figure~\ref{f.wienercandidate}. Here, the observer realizes the law $\mc{B}_{1;u,v}^{[-2T,2T]}$
with $u = \mc{L}(1,-2T)$ and $v = \mc{L}(1,2T)$, where note that these $(u,v)$ values are indeed known to the observer.
The Wiener candidate $W$ is defined to be the marginal on $[\ell,r]$ of the realized process. Using the bead locations thus dictated, the two side interval process values 
$$
\mc{L}(1,\cdot): [-2T,\ell] \cup [r,2T] \to \R
$$
are obtained by affine translation as discussed before.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=9cm]{wienercandidate.eps}
\caption{The perspective of the observer of $\mathcal{F}$ and the construction of the Wiener candidate are depicted for the case of two curves -- recall however that we merely consider the top curve in these lectures for reasons of convenience. The two curves on $[-2\eln,2\eln]$ that are dotted, dashed and then dotted again are samples of the law $\mc{B}_{2;\bar{u},\bar{v}}^{[-2\eln,2\eln]}$, with $(u_1,u_2) = \big( \mc{L}_n(1,-2\eln),  \mc{L}_n(2,-2\eln) \big)$ and $(v_1,v_2) = \big( \mc{L}_n(1,2\eln) ,  \mc{L}_n(2,2\eln) \big)$. The marginal of these curves on $[\ell,r]$, i.e., their dashed sections, forms the Wiener candidate $W$. 
The thicker solid black curve on $[-2\eln,\ell]$ is the affine translation of $\mc{L}_n^{[-2\eln,\ell]}$ with left endpoint $\mc{L}_n(1,-2\eln)$ and right endpoint $W(1,\ell)$. Similarly on the right, and for the thinner solid black second curve.
The black beads on the vertical line with $x$-coordinate $\ell$, located at heights $\big( W(1,\ell),W(2,\ell) \big)$, thus dictate the form of the
black curves to the left via affine translation subject to the fixed left endpoints; and similarly of course on the right.
The left side and middle interval tests are passed but the right side test is failed by the Wiener candidate, so that the candidate is unsuccessful in this instance.}
\label{f.wienercandidate}
\end{center}
\end{figure}



{\em However}, the proposed outcome must be checked for avoidance constraints between the top and the second curve on the side intervals and on the middle interval. In this way, there are {\em three tests} that must be passed: these are associated to, and named after, the {\em left side}~$[-2T,\ell]$, the {\em middle interval}~$[\ell,r]$, and the {\em right side}~$[r,T]$. 
%reviewagain See Figure. See Figure. See Figure.

This then is {\em missing closed middle reconstruction}, so named because the observer lacks knowledge of $\mc{L}(1,\cdot): [\ell,r] \to \R$ throughout the middle interval $[\ell,r]$;
so that the bead locations $\mc{L}(1,\ell)$ and $\mc{L}(1,r)$ are {\em random} for the observer.

We now use this technique to prove the Local Fluctuation Theorem~\ref{t.locfluc}: namely, 
$$
 \PP \Big( \sup_{x \in (0,\e)} \big\vert \mc{L}(1,x+h) - \mc{L}(1,x) \big\vert \geq K \e^{1/2} \Big) \leq C e^{- c K^{3/2}} \, .
$$
First consult Figure~\ref{f.leftcorner} for an explanation of the form of the left and right side tests, including the role of two $\mc{F}$-measurable real random variables $\mathsf{LeftCorner}$
and $\mathsf{RightCorner}$.



\begin{figure}[ht]
\begin{center}
\includegraphics[height=6cm]{leftcorner.pdf}
\caption{In the left sketch, the observer has brought the upper bead over $\ell$ down as far as possible compatibly with passing the left side test.  The curve which ends at this bead  touches the second curve on $[-2T,\ell]$. This curve is being affinely translated in accordance with the bead location and with the curve's fixed left endpoint -- see the right sketch for a depiction of the outcome when the bead is raised by distance $a > 0$. The minimum location for the bead -- the level of the horizontal dotted line -- is defined to be $\mathsf{LeftCorner}$. Admissible locations for the Wiener candidate $W$ at $\ell$ are those at or above  $\mathsf{LeftCorner}$, and the conditional distribution $W(\ell)$ given that $W$ passes the left-side test is given by the Gaussian law of $W(\ell)$, conditioned on $W(\ell) \geq \mathsf{LeftCorner}$. There is a similar story for the right-side test -- and a counterpart minimum level $\mathsf{RightCorner}$ for $W(r)$ so that the Wiener candidate does not violate the right-side test.} 
\label{f.leftcorner}
\end{center}
\end{figure}




We make use a {\em favourable} event $F$. This is an $\mc{F}$-measurable event -- whose occurrence or otherwise is known to the observer   -- on which the observer's perspective is sufficiently pleasant to admit analysis of the application in question -- Theorem~\ref{t.locfluc} at present.

For this application of missing closed middle reconstruction, we make the parameter settings $T = 1$, $\ell = -1$ and $r=1$.
For now, our specification of the event $F = F_t$ will depend on a parameter $t > 0$ -- to be specified shortly. Indeed, for $t > 0$, we specify $F = F_t$
to be the event that
\begin{enumerate}
\item $\mc{L}(1,-2)$ and $\mc{L}(1,2)$ belong to $[-t,t]$;
\item $\mathsf{LeftCorner}$ and $\mathsf{RightCorner}$ belong to $[-t,t]$;
\item and $\mc{L}(2,x) \leq t$ for all $x \in [-1,1]$.
\end{enumerate} 
\begin{lemma}[The favourable event is typical]\label{l.fav}
$$
 \PP \big( F_t^c \big) \leq C_1 e^{c_1 t^{3/2}} \, .
$$
\end{lemma}
{\bf Proof.} Property $(1)$ is one-point upper and lower tail bounds.
Regarding property~$(2)$, note that
$$
 \mc{L}(2,-1) \leq \mathsf{LeftCorner} \leq \mc{L}(1,-1)
$$
and
$$
 \mc{L}(2,1) \leq \mathsf{RightCorner} \leq \mc{L}(1,1)
$$ 
The right-hand terms here are not~$\mc{F}$-measurable -- but that doesn't matter. We see from the displays that $(2)$ reduces to one-point upper and lower tail bounds.

Property~$(3)$ is handled via ensemble ordering and No Big Max. \qed

Now for the proof of Theorem~\ref{t.locfluc} -- using the favourable event $F_t$, and setting $t$ in terms of $K$.

Recall that, under $\PP_\mc{F}$, the Wiener candidate $W:[-1,2] = [\ell,r] \to \R$ has the marginal law on $[-1,1]$ of $\mc{B}_{1;u,v}^{[-2,2]}$
wth $u = \mc{L}(1,-2)$ and $v = \mc{L}(1,2)$.

What are the prospects for success of the Wiener candidate?

\begin{lemma}[Wiener candidate success lower bound]\label{l.wcsuccess}
$$
 \PP_{\mc{F}} \Big( \textrm{the Wiener candidate succeeds}  \Big) \geq \exp \big\{ - O(1) t^2 \big\} \cdot {\bf 1}_{F_t} \, .
 $$
\end{lemma}
{\bf Proof.} Consider the event that, under $\PP_\mc{F}$, 
\begin{equation}\label{e.wevent}
 t \leq W(x) \leq 2t \, \, \, \, \forall x \in [-1,1] \, .
\end{equation}
Any such $W$ is successful (provided that $F_t$ occurs) because 
$$
 W(x) \geq t > \mc{L}(2,x) \, \, \, \, \forall x \in [-1,1] 
$$
-- so the middle interval test is passed;
$$
 W(-1) \geq t \geq \mathsf{LeftCorner} 
$$
-- so the left side test is passed; and 
$$
 W(1) \geq t \geq \mathsf{RightCorner} 
$$
-- so the right side test is passed.

{\bf Q1:} What is the $\PP_\mc{F}$-probability of the event in~(\ref{e.wevent}), given any $\mc{F}$-data that verifies $F_t$?

{\bf A1:} At least $e^{-C_1 t^2}$ with $C_1 \approx 20$.

Why this answer? See Figure~\ref{f.wienerleap} and its caption.




\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{wienerleap.eps}
\caption{The red Wiener candidate realizes $W(x) \in [t,2t]$ throughout $x \in [-1,1]$ in the depiction. The Gaussian probability of its endpoint values $W(-1)$ and $W(1)$ lying in the middle-third of $[t,2t]$
are at least of the form $e^{-(3t)^2}$ due to the lower bounds on $\mc{L}(1,-2)$ and $\mc{L}(1,2)$. The need for these endpoints to exceed $\mathsf{LeftCorner}$ and $\mathsf{RightCorner}$ only helps in achieving this outcome for $W(-1)$ and $W(1)$. If it is achieved, then with positive conditional probability the red Wiener candidate stays in the channel $[t,2t]$ during $x \in [-1,1]$. Thus the candidate realizes $W(x) \in [t,2t]$  for $x \in [-1,1]$ with probability at least $e^{-O(1)T^2}$ whenever $F_t$ occurs.} 
\label{f.wienerleap}
\end{center}
\end{figure}



{\bf Q2:}  What is the Wiener candidate's chance of making a big fluctuation on $[0,\e]$?


{\bf A2:} The answer is the next bound:
$$
 \PP_\mc{F} \Big( \sup_{x \in (0,\e)} \big\vert W(x+\e) - W(x) \big\vert \geq K \e^{1/2} \Big) \cdot {\bf 1}_{F_t} \leq C_2 e^{-c_1 K^2}
$$
when $t \leq O(k)$.

Why does the bound hold? 



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{wienerbigfluc.eps}
\caption{The Wiener candidiate is in essence Brownian motion of drift of order at most~$t$ -- and this permits us to bound above the probability of that it experiences a big fluctuation on the interval~$[0,\e]$.} 
\label{f.wienerbigfluc}
\end{center}
\end{figure}


See Figure~\ref{f.wienerbigfluc}. The movement of $W$ on $[0,\e]$ takes the form 
$$
  O(t) \e + \e^{1/2} G \, ,
$$
where $G$ is a standard Gaussian random variable. With $t \leq K$ and $K \e \leq \e^{1/2}$ (which is equivalent to the harmlessly supposed upper bound on $\e$, $\e \leq K^{-2}$), the movement in question is at most $2 \e^{1/2} G$. Thus we confirm the given answer.

We are ready to put these elements together.

We choose $t = O(1)K$. For a random process $X$ defined on an interval that includes $[0,\e]$, we write 
$$
\mathsf{BigFluc}(X) = \Big\{ \sup_{x \in (0,\e)} \big\vert W(x+\e) - W(x) \big\vert \geq K \e^{1/2} \Big\} \, .
$$
Note then that
$$
 \PP \Big( \mathsf{BigFluc}\big(\mc{L}\big) \Big) \leq  
 \PP \Big( \mathsf{BigFluc}\big(\mc{L}\big)  \cap F_t \Big) + 
 \PP \big( F_t^c \big) \, .  
$$
Now,
$$
 \PP \Big( \mathsf{BigFluc}\big(\mc{L}\big) \cap F_t \Big) 
$$
is equal to
$$
 \E \bigg[ \PP_{\mc{F}} \Big(  \mathsf{BigFluc}\big(\mc{L}\big) \Big) \cdot {\bf 1}_{F_t}  \bigg] \, .
$$
Since 
$$
 \PP_{\mc{F}} \Big(  \mathsf{BigFluc}\big(\mc{L}\big) \Big) =  \PP_{\mc{F}} \Big(  \mathsf{BigFluc} (W) \Big\vert W \, \, \textrm{succeeds} \Big) \, ,
$$
the last expression is at most
$$
 \E \Bigg[ 
 \frac{\PP_{\mc{F}} \Big(  \mathsf{BigFluc} (W) \Big)}{\PP_{\mc{F}} \Big( W \, \, \textrm{succeeds} \Big)}  \cdot {\bf 1}_{F_t}  \Bigg] \, .
$$
and thus also at most
$$
 \E \Bigg[ 
 \frac{C_2 e^{-c_1K^2}}{e^{- C_1 O(K^2)}}   \cdot {\bf 1}_{F_t}  \Bigg] \, .
$$
in view of Answers A1 and A2 as well as the choice $t = O(K)$. Indeed, selecting $t = O(1)K$ with the $O(1)$ term of unit order but small enough, we find that
$$
 \PP \Big( \mathsf{BigFluc}\big(\mc{L}\big) \cap F_t \Big) 
\leq e^{-c_3 K^2}
$$
with $c_3 > 0$. We insist that $t \geq c K$ because we further use Lemma~\ref{l.fav}:
$$
 \PP \big( F_t^c \big) \leq C_1 e^{-c_1 t^{3/2}} \, .
$$
Thus, 
$$
\PP \Big( \mathsf{BigFluc}\big(\mc{L}\big)  \Big) \leq O(1) e^{-O(1) t^2} + O(1) e^{-O(1) t^{3/2}} \, ;  
$$
and Theorem~\ref{t.locfluc}, i.e.,
$$
 \PP \Big( \sup_{x \in (0,\e)} \big\vert \mc{L}(1,x+\e) - \mc{L}(1,x) \big\vert \geq K \e^{1/2} \Big) \leq C e^{-c K^{3/2}}
 $$
is proved. \qed 

These intermediate tools  -- missing closed middle reconstruction and the Wiener candidate -- may also be used to give a fairly direct proof of the key step in the construction of the Airy line ensemble -- Proposition~\ref{p.accprob}, the uniform lower bound on the acceptance probability; this is forthcoming work with Jacob Calvert and Milind Hegde.

\chapter{Lecture Four: proving Brownian bridge regularity \\ via the jump ensemble}

Here we prove Theorem~\ref{t.bbr} in the special case of the ensemble $\mc{L}: \N \times \R \to \R$. For the purpose of recall, and because the assertion slightly simplifies in this special case, we state the relevant result.

\begin{theorem}[Brownian bridge regularity]\label{t.bbr.special}
Let  $a \in (0,1)$ denote  $\mc{B}_{1;0,0}^{[0.1]}(A)$ where $A \subseteq \mc{C}_{0,0} \big( [0,1], \R \big)$ is measurable. Then
$$
 \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) \leq a \cdot \exp \Big\{ \big( \log a^{-1} \big)^{5/6} O(1) \Big\} \, .
$$
\end{theorem}
Note that we are attempting a proof of this result only for curve index $k=1$ -- working in this case is not much more than a notational convenience. We work merely with the spatial interval $[0,1]$
because the stationarity of the Airy line ensemble permits this reduction -- in the general case of a regular ensemble, it is near parabolic invariance (Basics $D$) which performs the corresponding role.

In crude summary of this statement, then, we are aiming to show a result of the form: 
\begin{eqnarray}
& & \textrm{an event whose Brownian bridge probability is $\e$} \label{e.implic} \\
 & &  \textrm{has probability for the top curve in $\mc{L}$ which is at most $\e^{1 - o(1)}$} \, . \nonumber
\end{eqnarray}
 
 We now reserve the symbol $\e > 0$ to denote the small probability of a Brownian bridge $\mc{B}_{1;0,0}^{[0,1]}$ event~$A$.
 
 First, we review our prospects of proving an implication of the form~(\ref{e.implic}) using our present, intermediate, apparatus: MCM reconstruction and the Wiener candidate.
 
 We have specified a favourable event $F_t$, depending on a parameter $t > 0$. We will choose $t$ in terms of $\e > 0$.
 
 The basic inequality of the intermediate method asserts that, for an event $A$ with $\mc{B}_{1;0,0}^{[0,1]}(A) = \e$,
 $$
  \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) \, \leq \, \E \bigg[  \PP_{\mc{F}} \Big( W^{[0,1]}(\cdot) \in A \, \Big\vert \, W \, \, \textrm{succeeds} \Big) \cdot {\bf 1}_{F_t} \bigg] \, + \, \PP \big( F_t^c \big) \, ;
 $$
 or 
 $$
  \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) \, \leq \, \E \Bigg[  \frac{\PP_{\mc{F}} \Big( W^{[0,1]}(\cdot) \in A}{\PP_{\mc{F}} \Big( W \, \, \textrm{succeeds} \Big)} \cdot {\bf 1}_{F_t} \Bigg] \, + \, \PP \big( F_t^c \big) \, .
 $$
 The right-hand numerator $\PP_{\mc{F}}\big( W^{[0,1]}(\cdot) \in A \big)$ equals $\mc{B}_{1;0,0}^{[0,1]}(A) = \e$. In order to achieve
 $$
  \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) \leq \e^{1 - o(1)} \, ,
 $$
 we thus need two things:
 \begin{enumerate}
 \item {\em plausible success of the Wiener candidate}, i.e., on $F_t$ that
 $$
 \PP_{\mc{F}} \Big( W \, \, \textrm{succeeds} \Big) \geq \e^{o(1)} \, ;
 $$
 \item and {\em rarity of failure of the favourable event}, i.e., 
 $$
  \PP \big( F_t^c \big) \leq \e^{1 - o(1)} \, .
 $$
 \end{enumerate}
 
Note then that $(1)$ is an upper bound on $t$, since $\PP_{\mc{F}} \big( W \, \, \textrm{succeeds} \big) \geq e^{-O(1)t^2}$ on $F_t$; and $(2)$ is a lower bound on $t$, because $\PP \big( F_t^c \big) \leq e^{-O(1) t^{3/2}}$.

Indeed, for these reasons, $(1)$ forces $t \leq o(1) \big( \log \e^{-1} \big)^{1/2}$, while $(2)$ forces $t \geq \Theta(1)  \big( \log \e^{-1} \big)^{3/2}$.

These incompatible choices show that the present method cannot work -- at least not with its present parameter choices $T=1$, $\ell = -1$ and $r=1$.

Our first recourse to remedy this trouble is to vary the parameter settings. Suppose that we try 
$$
 T = \big( \log \e^{-1} \big)^\alpha > 0
$$
with $\ell$ and $-r$ equal to, or in any case of the order of, $T$. Here, $\alpha > 0$ is a parameter which we are at liberty to vary in seeking a better outcome for the method.

The new advantage is that the Wiener candidate, who needs to jump over a hill of height $O \big( (\log \e^{-1})^{2/3} \big)$, -- a height whose order is dictated by the consideration~$(2)$ above, where the favourable event $F_t$ is specified by a natural variation now that the parameter choices $(T,\ell,r)$ may no longer equal $(1,-1,1)$ --
now has a duration $(\log \e^{-1})^\alpha$ in which to make the jump, rather than merely unit-order time. However, the height of the hill has increased, because the attempted high jump begins at lower locations than before, in view of parabolic curvature. See Figure~\ref{f.recourse}.
Indeed, $\mc{L}(1,\pm 2T) \asymp - \big(\log \e^{-1} \big)^{2\alpha}$.



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{recourse.eps}
\caption{With $T = - \big( \log \e^{-1} \big)^\alpha$, the Wiener candidate has duration of order  $\big( \log \e^{-1} \big)^\alpha$ to jump over a hill of height  $\big( \log \e^{-1} \big)^{2/3}$, but must begin and end its journey in a valley below the base of the hill by order  $\big( \log \e^{-1} \big)^{2\alpha}$.} 
\label{f.recourse}
\end{center}
\end{figure}


Consideration~$(2)$ continues to dictate a choice of $t$ that satisfies
$$
 t \geq \Theta(1)  \big(\log \e^{-1} \big)^{2/3} \, ;
$$
and, in fact, we may choose equality here.

Regarding $(1)$, the Wiener success probability on $F_t$ has the form
$$
 \exp \bigg\{ - \tfrac{1}{\big( \log \e^{-1} \big)^\alpha} \Big( \big( \log \e^{-1} \big)^{2/3} + \big(\log \e^{-1}\big)^{2\alpha} \Big)^2 O(1) \bigg\} \, = \, 
 \exp \Big\{ - \big( \log \e^{-1} \big)^{(4/3 - \alpha) \vee 3\alpha} O(1) \Big\}   \, ,
$$
where inside the first exponential, the term in parentheses in the numerator is the hill height and the denominator is the duration in which the jump may be completed. 
This expression is maximized when $4/3 - \alpha = 3\alpha$, in which case, it takes the form
$$
\exp \big\{ - O(1) ( \log \e^{-1}) \big\} = \e^{O(1)} \, .
$$

We have come close to, {\em but cannot achieve}, the desired form $\e^{o(1)}$. What we instead want -- what would clearly suffice -- is an expression of the form$\exp \big\{ ( \log \e^{-1})^{1-\zeta} \big\}$ for some $\zeta > 0$. We refer to our failure to obtain it -- we merely obtained $\zeta = 0$ -- as the {\em high jump} difficulty.


Set back by this difficulty we may seem to be, we have nonetheless learnt a sensible way MCM parameter $T > 0$: henceforth, we set
$$
 T = D \big( \log \e^{-1} \big)^{1/3} \, ,
$$
where $D > 0$ is a constant to be chosen suitably in applications. 



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{secondfavour.eps}
\caption{Depicted is an example of a realization of the new favourable event $\mathsf{Fav}$. The conditions that collectively specify this event are that $\mathsf{LeftCorner}$ and $\mathsf{RightCorner}$ belong to $[-T,T]$; that $\mc{L}(2,x) \leq T$ for all $x [\ell,r]$; and that $\mc{L}(1,-2T)$ and $\mc{L}(1,2T)$ differ from the parabolically determined level $- 2^{3/2}T^2$ by at most $T^2$.} 
\label{f.secondfavour}
\end{center}
\end{figure}

 We continue to work with a favourable event $\mathsf{Fav} = F_t$, with $t = \Theta(1) \big( \log \e^{-1} \big)^{2/3}$, with $F_t$ now specified analogously to before for the new choice of $T$. See Figure~\ref{f.secondfavour}. The upper bound on the probability of failure of the favourable event now takes the form:
 \begin{lemma}\label{l.favour}
 $$
  \PP \big(  \mathsf{Fav}^c \big) \leq \e^{O(1) D^3} \, .
  $$
 \end{lemma}
Next, we set the parameters $\ell$ and $r$. The obvious respective choices are $-T$ and $T$, but we will make a choice $\ell \in [-T,0]$ and $r \in [0,T]$ that renders the lower boundary condition $\mc{L}(2,\cdot)$ slightly more regular on $[\ell,r]$. 

To specify our choice of $(\ell,r)$, we introduce the {\em least concave majorant} $\cm_+:[-\eln,\eln] \to \R$ of the curve $\mc{L}_n(2,\cdot):[-\eln,\eln] \to \R$.



Define a random variable pair $(\ell,r)$ according to
\begin{eqnarray*}
  \ell  & = & \inf \big\{ x \in [-\eln,\eln]: \cm_+'(x) \leq    4 \eln \big\} \\
\textrm{and}  \, \, \,   r  & = & \sup \big\{ x \in [-\eln,\eln]: \cm_+'(x) \geq -  4 \eln \big\} \, ,  
\end{eqnarray*}
where the convention that $\inf \emptyset = \eln$ and 
$\sup \emptyset = - \eln$ is adopted.
That is, $\ell \in [-T,T]$ is the leftmost location at which $\cm_+$ has slope at most $4T$, and $r$ is the rightmost at which this slope is at least~$-4T$.

It is easily seen that the occurrence of $\mathsf{Fav}$ forces $\ell \in [-T,-T/2]$ and $r \in [T/2,T]$.

\section{More promising than the Wiener candidate -- the jump ensemble}

Consider the law $\PP_\mc{F}$ for $\mc{F}$-data that realizes  $\mathsf{Fav}$. We have seen that Wiener candidate success occurs with probability $\e^{O(1)}$ -- but we need $\e^{o(1)}$. That is, we need to solve the high jump difficulty.

We will vary the Wiener candidate $W:[\ell,r] \to \R$ to obtain the jump curve $J:[\ell,r] \to \R$. The success probability of $J$ will be at least $\e^{o(1)}$ for $\mc{F}$-data verifying $\mathsf{Fav}$ as desired. 
%reviewagain See Figure.

The Wiener candidate finds it difficult to pass the middle interval test -- that it exceeds $\mc{L}(2,\cdot)$ on $[\ell,r]$. 

{\em Idea:} make this easier by first conditioning the Wiener candidate on exceeding a coarse-grained caricature of $\mc{L}(2,\cdot)$ on $[\ell,r]$.


Recall that $\cm_+:[-\eln,\eln] \to \R$ is  the least concave majorant of the curve $\mc{L}_n(k+1,\cdot):[-\eln,\eln] \to \R$. 
Let $\xext \subset [\mfl,\mfr]$ denote the set of $x$-coordinates of extreme points of the closed set $\big\{ (x,y) : \mfl \leq x \leq \mfr \, , \, y \leq \cm^+(x) \big\}$.
 Note that $\xext$ consists  of the intersection with $[\mfl,\mfr]$ of the set of points of local non-constancy of $\cm_+'$; necessarily, $\{ \mfl,\mfr \} \in \xext$.  Let $\pole$ denote a subset of $\xext$  with the properties that 
\begin{itemize}
\item $\{ \mfl,\mfr \} \in \pole$;
\item any distinct elements $\pp_1,\pp_2 \in \pole$ satisfy $\vert \pp_1 - \pp_2 \vert > \ipd$;  
\item and, if $x \in \xext  \setminus \pole$, then some element $\pp \in \pole$ satisfies $\vert \pp - x \vert \leq \ipd$. 
\end{itemize}
We have $\vert P \vert \leq 2T$ since $[\ell,r] \subseteq [-T,T]$.

Why the `pole' set? The upcoming Figure~\ref{f.jumpensemble} explains.

Recall that, under $\PP_\mc{F}$, the Wiener candidate $W:[\ell,r] \to \R$ is the marginal on $[\ell,r]$ of $\mc{B}_{k;u,v}^{[-2T,2T]}$, where $u = \mc{L}(1,-2T)$
and $v = \mc{L}(1,2T)$.
We say that the Wiener candidate passes the {\em jump} test if it clears all the pole tops, namely if 
$$
\wien(x) > \mc{L}_n\big(2,x \big) \ \, \, \textrm{for all $x \in \pole$} \, .
$$
This test is weaker than the middle interval test which entails the above bound for all $x \in [\ell,r]$ (and we have $P \subseteq [\ell,r]$).

Indeed, the examination of the Wiener candidate may represented in three steps:
\begin{itemize}
\item Test $1$ is the side intervals test;
\item Test $2$ is the jump test;
\item and Test $3$ is the middle interval test.
\end{itemize}
See Figure~\ref{f.passandfail}.
\begin{figure}[ht]
\begin{center}
\includegraphics[height=11cm]{passandfail.pdf}
\caption{Here, the pole set $P$ has four elements, with $P = \big\{ \ell,p_1,p_2,r \big\}$. The dotted map {\rm Tent} straddles the four bold poles indexed by $P$. The red Wiener candidate $W:[\ell,r] \to \R$ has transcript: test~$1$ is failed, with the left side test passed and the right side test failed; test~$2$ is passed, because $W$ jumps over the four poles; test~$3$, the middle interval test, is failed, because $W$ touches $\mc{L}(2,\cdot)$ on $[\ell,p_1]$.} 
\label{f.passandfail}
\end{center}
\end{figure}



\begin{figure}[ht]
\begin{center}
\includegraphics[height=11cm]{jumpensemble.pdf}
\caption{The jump ensemble depicted with $k=2$ curves -- we work with $k=1$, so that we may call this object simply the jump curve.
The depiction is not to scale: the intervals $[-2\eln,-\eln]$ and  $[\eln,2\eln]$ are too short. 
% The side intervals have been shortened for this depiction: recall that  $[\mfl,\mfr] \subseteq [-\eln,\eln]$. 
%In the figure, we write ${\rm l}$ for $\mfl$ and ${\rm r}$ for $\mfr$. 
The pole set~$P$  in this example equals $\{ \mfl, p_1 , p_2, \mfr \}$. The vertical poles are depicted in thick solid lines. 
The function ${\rm Tent}:[\ell,r] \to \R$
is defined to be the affine function that interpolates the values $\mc{L}(k+1,p)$ for $p \in P$.
We picture vertical poles rising above the locations $p \in P$, with the tent map stretched over their tops.
In the figure, the point $x$ is an element of $\xext$ but not of $P$, because $\vert x - p_1 \vert < 1$. (In fact, there are almost surely infinitely many elements of $\xext \setminus P$.) The piecewise affine dashed curve defined on $[\mfl,\mfr]$ is $\tent$. The rougher dashed curves are the jump ensemble $J:[1,2] \times [\mfl,\mfr] \to \R$. The jump ensemble fails the criterion of passing Test~$3$ due to the meeting of the two $J$-curves and contact between $J(1,\cdot)$ and $\mc{L}_n(3,\cdot)$.} 
\label{f.jumpensemble}
\end{center}
\end{figure}


Under $\PP_\mc{F}$, the jump curve $J:[\ell,r] \to \R$ is constructed so that it has the conditional distribution of $W:[\ell,r] \to \R$ given that $W$ passes Test~$1$ and~$2$ -- see Figure~\ref{f.jumpensemble}.
We may picture the jump curve as being a halfway house between the unadulterated Brownian randomness of the Wiener candidate $W$
and the object of interest $\mc{L}(1,\cdot)$ whose Brownianity is to be established.

{\em Next:} the jump curve is a serious candidate to pass the third and final test; in a sense, it solves the high jump difficulty, with $\zeta = 1/3$.
\begin{proposition}[Realized promise of the jump curve]\label{p.jpromiserealized}
We have that
$$
 \PP_{\mc{F}} \Big(  J \, \, \textrm{passes Test $3$} \Big)  \, \geq \, 
 \exp \Big\{ -  O(1) \big( \log \e^{-1} \big)^{2/3} \Big\}  \cdot  {{\bf 1}}_{\mathsf{Fav}} \, .
$$
\end{proposition} 
This is the key proposition in the general apparatus of the jump ensemble method. We will see to what we have reduced the Brownian bridge regularity Theorem~\ref{t.bbr} by assuming the proposition -- then we will indicate something of its proof.

\section{Proving Theorem~\ref{t.bbr} via Proposition~\ref{p.jpromiserealized}}
Recall that we want to show that for $A \subseteq \mc{C}_{0,0} \big( [0,1], \R \big)$ with $\mc{B}_{1;0,0}^{[0,1]}(A) = \e$, we have that
$$
 \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) \leq \e \cdot  C \exp \Big\{ C \big( \log \e^{-1} \big)^{5/6}  \Big\} \, ,
$$
{\bf Proof.} The basic inequality of the jump method is
\begin{eqnarray*}
 & &  \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) \\ 
 & \leq &  \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \, , \, \mathsf{Fav} \Big) + \PP \big( \mathsf{Fav}^c \big) \\
 & = &  \E \bigg[ \PP_\mc{F} \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) {\bf 1}_{\mathsf{Fav}}  \bigg] + \PP \big( \mathsf{Fav}^c \big) \\
 & = &  \E \bigg[ \PP_\mc{F} \Big( J^{[0,1]} (\cdot) \in A \Big\vert J \, \, \textrm{passes Test $3$} \Big) {\bf 1}_{\mathsf{Fav}}  \bigg] + \PP \big( \mathsf{Fav}^c \big) \\  
 & \leq &  \E \Bigg[ \frac{\PP_\mc{F} \Big( J^{[0,1]} (\cdot) \in A \Big)}{\PP_\mc{F} \Big( J \, \, \textrm{passes Test $3$} \Big)} {\bf 1}_{\mathsf{Fav}}  \Bigg] + \PP \big( \mathsf{Fav}^c \big) \, .
\end{eqnarray*}
By the Realized Promise Proposition~\ref{p.jpromiserealized} and the Favourable Event Probabiltiy Lemma~\ref{l.favour}, we find that
$$
 \PP \Big( \mc{L}^{[0,1]} (1,\cdot) \in A \Big) \leq \exp \Big\{  O(1) \big( \log \e^{-1} \big)^{2/3} \Big\}  \PP_\mc{F}  \Big( J^{[0,1]} (\cdot) \in A \Big) {\bf 1}_{\mathsf{Fav}}  
 \, + \, \e^{O(1) D^3} \, . 
$$
Since we may choose the jump method paramter $D > 0$ high enough that $O(1) D^3 \geq 1$, we see that the input needed to complete the proof of Theorem~\ref{t.bbr} -- given the jump ensemble method, including Proposition~\ref{p.jpromiserealized} -- is
$$
 \PP_\mc{F}  \Big( J^{[0,1]} (\cdot) \in A \Big) {\bf 1}_{\mathsf{Fav}}  
\leq  \e \cdot \exp \Big\{ C \big( \log \e^{-1} \big)^{5/6} \Big\}  \, ,
$$
where $\mc{B}_{1;0,0}^{[0,1]}(A) = \e$. The next proposition furnishes this input.
\begin{proposition}[Brownian regularity for $J$]\label{p.bbrj}
 Let $A \subseteq \mc{C}_{0,0} \big( [0,1], \R \big)$ satisfy 
 \begin{equation}\label{e.aprob}
  \mc{B}_{1;0,0}^{[0,1]}(A) \geq \e^{D^2/2} \, .
 \end{equation}
 Then  
$$
 \PP_\mc{F}  \Big( J^{[0,1]} (\cdot) \in A \Big) {\bf 1}_{\mathsf{Fav}}  
\leq  \mc{B}_{1;0,0}^{[0,1]}(A)  \cdot O(1) \exp \Big\{ O(1) \big( \log \e^{-1} \big)^{5/6} \Big\}  \, .
$$
\end{proposition}
Note that, in the application, $\mc{B}_{1;0,0}^{[0,1]}(A) = \e$, so that condition~(\ref{e.aprob}) is satisfied provided that we choose, as we may, $D^2 \geq 2$.

Two steps remain then to complete the proof of Theorem~\ref{t.bbr}:
\begin{enumerate}
\item verifying the general jump method component Proposition~\ref{p.jpromiserealized}; 
\item and verifying the problem-determined Proposition~\ref{p.bbrj}.
\end{enumerate}
We now sketch arguments for these two results in turn.

{\bf Sketch of proof of Proposition~\ref{p.jpromiserealized}.}
Suppose for simplicity that $\ell = -T$, $r = T$, and that the pole set has three elements in the form $P = \big\{ -T,0,T \big\}$; and that
$$
 \mc{L}(2,0) = T^2 \, , \, \mc{L}(2,-T) = \mc{L}(2,T) = - T^2 \, , \, \mc{L}(1,-2T) = \mc{L}(1,2T) = -2T^2  \, .
$$
This is in essence an extreme case. 

What hope is there for the curve $J$ to succeed, i.e., to pass the middle interval test: $J(x) \geq \mc{L}(2,x)$ for all $x \in [-T,T]$? See Figure~\ref{f.twojumpcurves}.




\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{twojumpcurves.eps}
\caption{Two jump curves -- the unbroken curve passes the middle interval test, and the dashed curve fails it. The random variable $J(-T)$ may be caricatured as a normal random variable -- whose mean $-2T^2$
and whose variance has order $T$ -- conditioned to exceed the pole top at $-T$.} 
\label{f.twojumpcurves}
\end{center}
\end{figure}



Crudely, $J(-T)$ is a normally distributed random variable of mean 
$-2T^2$ and variance of order $T$ {\em conditioned} to be above $\mc{L}(2,-T) = -T^2$. 
By how much does $J(-T)$ typically exceed this minimum level?
The density at $x$ for this random excess equals 
%reviewagain (and see the left sketch!)
$$
  \frac{\exp \Big\{ - \tfrac{(T^2 + x)^2}{T} \Big\}}{\exp \Big\{ - \tfrac{(T^2)^2}{T} \Big\}}
$$
which when $x = o(T^2)$ is approximately $\exp \big\{ - \tfrac{T^2 x}{T} \big\} = \exp \big\{ - Tx \big\}$. 

This is an example of {\em cancellation of first-order kinetic costs}: the first-order term in the numerator and the denominator are both 
$$
 \exp \big\{ - T^3 O(1) \big\} = \e^{O(1) D^3} \, ,
$$
where recall that $T = D \big( \log \e^{-1} \big)^{1/3}$. This cost is the unacceptably high term that we saw in the high jump difficulty -- in the explanation of why the intermediate, Wiener candidate, approach was inadequate. 
Here, however, these high terms cancel, reflecting the conditioning to which the jump curve $J$ is subject by its definition. 

In the application, we choose $x$ to be of order $\big( \log \e^{-1} \big)^{1/3}$. We find that
the probability under $\PP_\mc{F}$ that $J(-T)$ (which is $J(\ell)$ in our present simplification)
exceeds its minimum possible value by an order of  $\big( \log \e^{-1} \big)^{1/2}$ behaves as  $\exp \big\{ - \Theta(1) \big( \log \e^{-1} \big)^{2/3} \big\}$ -- this is because the argument of the exponential $-Tx$ has this form in view of  $T = D \big( \log \e^{-1} \big)^{1/3}$  and  $x =\big( \log \e^{-1} \big)^{1/3}$.



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{threeexcessjumps.eps}
\caption{The jump curve on $[\ell,r] = [-T,T]$ is depicted as
exceeding each of the three poles by at least $\big( \log \e^{-1} \big)^{1/2}$; it thus typically exceeds the dotted map ${\rm Tent}$ by the same order throughout $[-T,T]$.} 
\label{f.threeexcessjumps}
\end{center}
\end{figure}



What happens in the circumstance that this excess indeed has this order? See Figure~\ref{f.threeexcessjumps}. Note that $J$ is above ${\rm Tent}$ at $-T$, $0$ and $T$ by order 
$\big( \log \e^{-1} \big)^{1/3}$. It deviates from affine interpolation of these endpoints by order $T^{1/2} = \big( \log \e^{-1} \big)^{1/6}$ -- that is, typically, $J$ exceeds ${\rm Tent}$ on $[-T,T]$ by order $\big( \log \e^{-1} \big)^{1/3}$ consistently. 

Now $\mc{L}(2,\cdot)$ on $[-T,T]$ may rise above ${\rm Tent}$ sometimes -- because not every extreme point of $\big\{ (x,y): - T \leq x \leq T , y \leq \cm_+(x) \big\}$ is in the pole set $P$. But by how much may it rise above  ${\rm Tent}$?
\begin{lemma}\label{l.xnearpole}
For $x \in [-T,T] = [\ell,r]$,
  $$
   \mc{L}(2,x) - {\rm Tent}(x) \leq 8T \, .
  $$
\end{lemma}
See Figure~\ref{f.xnearpole} for a proof sketch.



\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{xnearpole.eps}
\caption{This sketch illustrates a proof of Lemma~\ref{l.xnearpole}. An extreme point of the graphs of the concave majorant $\cm_+$ has horizontal coordinate $x$ lying between consecutive pole set elements $p_1$ and $p_2$. Thus $x$ lies within unit distance of either $p_1$ or $p_2$ -- here, we suppose the latter. In the sketch, the tent map, of slope at most $4T$, and a downward sloping dotted line, of slope $-4T$, touch the top of the pole at $p_2$. The planar point $\big( x, \mc{L}(2,x) \big)$ is bounded below by ${\rm Tent}$ and above by the downward sloping line. The indicated arrow distance, which is an upper bound on how much $\mc{L}(2,\cdot)$ may exceed ${\rm Tent}$, is thus at most $8T$.} 
\label{f.xnearpole}
\end{center}
\end{figure}


Since $T \asymp  \big( \log \e^{-1} \big)^{1/3}$, we see that, with suitable selection of constant factors, $J$ has in the circumstance -- depicted in Figure~\ref{f.threeexcessjumps} -- of exceeding the pole tops by the indicated margin  positive conditional probability to exceed $\mc{L}(2,\cdot)$ on $[-T,T]$ -- and thus to pass Test~$3$, the middle interval test, and be successful. 
That is,
$$
 \PP_\mc{F}  \Big( J \, \, \textrm{succeeds}\Big)  
\geq  \exp \Big\{  - O(1) \big( \log \e^{-1} \big)^{2/3} \Big\} {\bf 1}_{\mathsf{Fav}}  
  \, ,
$$
as we sought to show in deriving Proposition~\ref{p.jpromiserealized}. \qed

\section{Sketch of proof of Proposition~\ref{p.bbrj}}

Recall that, in essence, we seek to show that if $\e =   \mc{B}_{1;0,0}^{[-1,1]}(A)$, then 
$$
 \PP_\mc{F}  \Big( J^{[-1,1]} (\cdot) \in A \Big) {\bf 1}_{\mathsf{Fav}}  
\leq  \e  \cdot O(1) \exp \Big\{ O(1) \big( \log \e^{-1} \big)^{5/6} \Big\}  \, .
$$
Here, we arbitrarily but harmlessly switched the interval of attention from $[0,1]$ to $[-1,1]$.

Again, we work with a special case to focus our attention: $P = \big\{ - T , 0 , T \big\}$, $\mc{L}(2,-T) = \mc{L}(2,T) = - T^2$ and $\mc{L}(2,0) = T^2$. 

\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{redjump.eps}
\caption{The jump curve illustrated in the special case under review and with boundary conditions making its effective drift before and after zero as pronounced as possible.} 
\label{f.redjump}
\end{center}
\end{figure}

How does does $J$ on $[-1,1]$ differ from ordinary Brownian motion on this interval? More to the point: how does $J^{[-1,1]}$ differ from standard Brownian bridge?

Let's make this comparison after fixing $J(-T)$ and $J(T)$ at the lowest possible locations that these values may adopt: $J(-T) = J(T) = -T^2$. This in essence gives a worst case scenario, in which the jump that $J$ faces is as high as it ever may be -- see  Figure~\ref{f.redjump}. 

Now, $J^{[-1,1]}$ can be caricatured as $B(x) + {\rm SimpleTent}(x)$, where ${\rm SimpleTent}:[-1,1] \to \R$ is the affine function that interpolates the values zero at $-1$; $T$ at zero; and zero at $T$. Similarly, $J^{[-1,1]}$ is roughly a Brownian bridge that experiences drift $T$ during $[-1,0]$ and drift $-T$ during $[0,1]$ -- the reason for the rough validity of these models being that the stated drifts are dictated by the need to make a movement of order $T^2$ in a duration~$T$.

We are trying to show that an $\e$-probability event for standard Brownian bridge has probability at most $\e  \cdot O(1) \exp \Big\{ O(1) \big( \log \e^{-1} \big)^{5/6} \Big\} $ for $J^{[-1,1]}$. 
Given our caricature of $J^{[-1,1]}$, which event is liable to maximize the $J^{[-1,1]}$-probability among those events whose probability under $\mc{B}_{1;0,0}^{[-1,1]}$ equals~$\e$?
The event is clear enough: it is
$$
 \big\{ J^{[-1,1]}(0) \geq R \big\} \, ,
$$
where $R$ satisfies 
$$
\mc{B}_{1;0,0}^{[-1,1]} \big( B(0) \geq R \big) = \e \, ,
$$
and thus also satisfies $\exp \big\{ - R^2 O(1) \big\} = \e$ or equivalently $R = O(1) \big( \log \e^{-1}  \big)^{1/2}$.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=10cm]{simplecomparison.eps}
\caption{The dotted affine curve is ${\rm SimpleTent}$. The red curve, our caricature of $J^{[-1,1]}$, is a sample of standard Brownian bridge on $[-1,1]$ to which ${\rm SimpleTent}$ has been added. The red curve is to be compared in law to the black curve, which is standard Brownian bridge on the same interval. The event which is liable to expose the contrast between the curves most vividly is that either exceeds a given high level at zero.} 
\label{f.simplecomparison}
\end{center}
\end{figure}

What then is $\PP \big( J^{[-1,1]}(0) \geq R \big)$ when $R$ is so chosen? It is (and see Figure~\ref{f.simplecomparison}!)
$$
 \exp \big\{ - (R - T)^2 \big\} \, = \,  
\mc{B}_{1;0,0}^{[-1,1]} \big( B(0) \geq R \big)  \times  \exp \big\{ R O(T) \big\} \, .
$$
Here, the term $T$ appearing in the left-hand expression is the roughly the mean of $J^{[-1,1]}(0)$. The term  
$\mc{B}_{1;0,0}^{[-1,1]} \big( B(0) \geq R \big)$ is a first-order term -- of type ``$e^{-R^2}$'' -- which in effect equals the dominant term when the bracket inside the exponential on the left-hand side is expanded. What we have seeing in the displayed equation is in effect a cancellation of first-order kinetic costs. That the remaining product on the right-hand side indeed has the form $\exp \big\{ R  O(T) \big\}$ depends on $T = o(R)$ -- a valid bound given our choices.

Thus,
$$
 \PP \big( J^{[-1,1]}(0) \geq R \big) = 
\mc{B}_{1;0,0}^{[-1,1]} \big( B(0) \geq R \big) \exp \big\{ O(1) \big( \log \e^{-1} \big)^{5/6} \big\} \, ;
$$
the first term on the right-hand side equals $\e$, and the second has its form because it equals  $\exp \big\{ R O(T) \big\}$ 
where  $T = \big( \log \e^{-1} \big)^{1/3}$ and  $R = O(1) \big( \log \e^{-1} \big)^{1/2}$.

This case is supposed to be the worst -- this is merely a sketch of a proof! -- and assuming that it is, our conclusion is
$$
 \PP \big( J^{[-1,1]}  \in A \big) \leq  
  \e \cdot \exp \big\{ O(1) \big( \log \e^{-1} \big)^{5/6} \big\} 
$$
whenever 
$\mc{B}_{1;0,0}^{[-1,1]}(B \in A) = \e$. This completes the proof sketch of Proposition~\ref{p.bbrj}. \qed



\bibliographystyle{plain}

\bibliography{airy}


\end{document}

 
\section{Introduction}

The $1 + 1$ dimensional Kardar-Parisi-Zhang (KPZ) universality class includes a wide range of interface models suspended over a one-dimensional domain, in which growth in a direction normal to the surface competes with a smoothening surface tension in the presence of a local randomizing force that roughens the surface.
Such surfaces typically grow linearly, with fluctuations after that linear growth is subtracted being described by scaling exponents:
if linear growth has order $n$, then interface height above a given point has typical deviation from the mean of order $n^{1/3}$, while non-trivial correlations in this height as the spatial coordinate is varied are encountered on scale~$n^{2/3}$. Moreover, an exponent of one-half dictates the interface's regularity, with the interface height being expected to vary between a pair of locations at distance of order at most $n^{2/3}$
on the order of the square root of the distance between these locations.

Such growth models may be initiated at time zero with a given interface profile. In the narrow wedge case, when growth is initiated from a unique point, 
a limiting description of the late time interface, suitably scaled in light of the one-third and two-thirds powers and up to the subtraction of a parabola, is offered by the {\rm Airy}$_2$ process,
 which is a random  function $\mc{A}: \R \to \R$, whose finite dimensional distributions are specified by Fredholm determinants, that was introduced by~\cite{PrahoferSpohn}. 
 Another well-known initial condition is the flat case, when growth begins from a zero initial condition. Here, the ${\rm Airy}_1$ process describes the interface at late time. 
  The one-half power law for interface regularity is expressed by the H{\"o}lder-$1/2-$-continuity of the processes~${\rm Airy}_1$ and~${\rm Airy}_2$, which was proved in~\cite{QR13}. 


Growth may be initiated from a much more general initial condition than in these narrow wedge or flat cases.
For initial conditions that grow at most linearly, it has been anticipated that a limiting description of the suitably scaled late-time interface should exist in these cases also. Indeed, in a recent preprint~\cite{MQR17}, Matetski, Quastel and Remenik
have utilized a biorthogonal ensemble representation found by~\cite{Sas05,BFPS07} associated to the totally asymmetric exclusion process in order to  find Fredholm determinant formulas for the multi-point distribution of the height function of this growth process begun from an arbitrary initial condition. Using these formulas to take the KPZ scaling limit, the authors construct a scale invariant Markov process that lies at the heart of the KPZ universality class. The time-one evolution of this Markov process may be applied to very general initial data, and the result is the scaled profile begun from such data, which generalizes the ${\rm Airy}_1$ and~${\rm Airy}_2$ processes seen in the flat and narrow wedge cases. 
These more general limiting processes also enjoy  H{\"o}lder-$1/2-$-continuity:  see~\cite[Theorem 4.4]{MQR17}.


The broad range of interface models that are rigorously known or expected to lie in the KPZ universality class includes many last passage percolation models.
Such an LPP model comes equipped with a planar random environment, which is independent in disjoint regions. 
Directed paths, that are permitted say to move only in a direction in the first quadrant, are then assigned energy via this randomness, by say integrating the environment's value along the path.
For a given pair of planar points, the path attaining the maximum energy over directed paths with such endpoints is called a geodesic. 
The random interface model that we alluded to at the outset is then specified as the maximum geodesic energy when one geodesic endpoint is varied and the other held fixed, in the narrow wedge case, or when the other is free to vary and is rewarded according to the initial condition, in the more general case.   
The one-third and two-thirds power laws for typical deviation of maximum energy and for lateral correlation have been rigorously demonstrated for only a few LPP models, each of which enjoys an integrable structure: the seminal work of Baik, Deift and Johansson~\cite{BDJ1999} 
 rigorously established the one-third exponent, and moreover obtained the GUE Tracy-Widom distributional limit, for the case of Poissonian last passage percolation, while the two-thirds power law for transversal fluctuation was derived for this model by Johansson~\cite{Johansson2000}. 
For models in which these two exponents have been rigorously identified,
the exponent pair dictates a system of scaled coordinates in which the concerned maximizing paths and their weights are unit-order, random, quantities: the scaled geodesics may be called polymers, and their scaled energies, weights.



 


 Brownian last passage percolation  is an LPP model with attractive integrable and probabilistic features. 
In this article, we study the scaled interface profile (that is, the polymer weight profile) in Brownian LPP begun from a very general initial condition. We present results proving a more precise version of the one-half power law for interface regularity than has been established hitherto. Here are two of the  main conclusions:
\begin{itemize}
\item In Theorem~\ref{t.differenceweight}, we prove that the maximum difference in the weight of two point-to-point polymers whose endpoints differ by at most a small scaled quantity~$\e$ exceeds $\e^{1/2}R$
with probability at most $\exp \big\{  - O(1) R^{3/2}  \big\}$ for a very broad range of values of $R$, uniformly in the scaling parameter for Brownian LPP.
\item In Theorem~\ref{t.wlp.one}, we prove that any weak limit point of the scaled interface profiles, as the scaling parameter tends to infinity, has sample paths that admit a modulus of continuity of the order of $x^{1/2} \big( \log x^{-1} \big)^{2/3}$. This assertion, alongside a finite-$n$ counterpart, Theorem~\ref{t.nmodcon}, is proved uniformly over a large class of the data that initiates the random growth. 
\end{itemize}

For a given choice of initial condition, the weak limit point in Theorem~\ref{t.wlp.one} may be expected to be unique and to coincide with the interface profile obtained from this initial data by evolving for a given duration the Markov operator constructed in~\cite{MQR17}. However, this Markov operator has been constructed as a limit of totally asymmetric exclusion, so at present this assertion is not proved.
Were the techniques of~\cite{MQR17} to be adapted to hold for Brownian last passage percolation, it would then presumably be possible to assert the upper bound of order $x^{1/2} \big( \log x^{-1} \big)^{2/3}$ on  modulus of continuity for general initial condition interface profiles under the KPZ fixed point.

The strongly on-scale assertion of the one-half power law for profile regularity in Theorem~\ref{t.differenceweight} plays a significant role in two companion papers. In~\cite{NonIntPoly}, it is harnessed to prove that, in Brownian last passage percolation, it is a superpolynomial rarity that a large number of disjoint polymers coexist in a unit-order scaled region. In~\cite{Patch}, this assertion is exploited
to make a strong unit-order Brownian comparison for polymer weight profiles (about which more momentarily).
%: in this work, the general initial condition polymer weight profiles that are the subject of the present study are shown to bear a strong comparison with Brownian motion on unit-order scales.

Beyond the conclusions just discussed, the present article also presents a useful tool, Proposition~\ref{p.maxminweight}. Although the weight of a polymer is random, this weight is dictated in the large by parabolic curvature, with the randomness playing a unit-order role once this curvature is accounted for. The proposition shows that the discrepancy between polymer weight and parabola is controlled uniformly 
as the polymer's endpoints are varied over compact intervals lying in a very broad region. This tool is needed in the present article and in~\cite{NonIntPoly}. For exponential or Poissonian last passage percolation, a similar tool has been developed, in~\cite[Propositions~$10.1$ and~$10.5$]{SlowBondSol}.



We also mention that an alternative expression of the one-half power law for interface regularity is the assertion that Airy processes such as   {\rm Airy}$_1$ and {\rm Airy}$_2$, or scaled interface models in the last passage percolation setting, locally resemble Brownian motion.
Such statements may be understood in a local limit, when Gaussianity of a process $\mc{A}$ is proved for the low~$\e$ limit for the random variable $\e^{-1/2} \big( \mc{A}(x+\e) - \mc{A}(x) \big)$
associated to any given $x \in \R$. 
Finite dimensional distributional convergence to Brownian motion (of diffusion rate two) in this limit  has been proved for the Airy$_2$ process in~\cite{Hagg}, for the Airy$_1$ process in~\cite{QR13},
and for the more general versions of these Airy processes constructed in \cite{MQR17} in Theorem~$4.4$ of that paper; in~\cite{Pimentel17}, similar 
 local limit results for general initial condition profiles have been obtained for geometric last passage percolation models. 
Comparison to Brownian motion may also be made without taking such a local limit. In~\cite{AiryLE}, 
the ${\rm Airy}_2$ process was understood to be absolutely continuous with respect to Brownian motion on a unit-order interval, by a technique in which this process is embedded as the uppermost curve in a random ensemble of, in effect, mutually avoiding Brownian motions. (This {\em Brownian Gibbs} technique will play a fundamental role in the present article, and we will return to it.) This inference was improved in~\cite{BrownianReg}, where the implied Radon-Nikodym derivative is shown to lie in all $L^p$-spaces for $p \in (1,\infty)$, albeit after an affine shift is applied to the ${\rm Airy}_2$ process, so that comparison is made not to Brownian motion but to Brownian bridge. In a companion paper to the present article~\cite{Patch}, 
the problem of unit-order scale Brownian comparison is made for the class of Brownian LPP polymer weight profiles, begun from general initial data,  that are the subject of the present article.
It is in essence shown there that a given unit-order interval may be split into a random but controlled number of intervals in such a way that the profile when restricted to the smaller intervals has, after affine adjustment, a Radon-Nikodym derivative with respect to Brownian bridge that lies in $L^p$ for $p \in (1,3)$. 

 

\subsection{Brownian last passage percolation [LPP]}\label{s.brlpp}
%This model was introduced in~\cite{O'ConnellYor};
%we call it Brownian LPP.
We now define this model.
On a probability space carrying a law labelled~$\PP$,
let $B:\Z \times \R \to \R$ denote an ensemble of independent  two-sided standard Brownian motions $B(k,\cdot):\R\to \R$, $k \in \Z$.

Let $i,j \in \Z$ with $i \leq j$.
We denote the integer interval $\{i,\cdots,j\}$ by $\llbracket i,j \rrbracket$.
Further let $x,y \in \R$ with $x \leq y$.
Consider the collection of  non-decreasing lists 
 $\big\{ z_k: k \in \llbracket i+1,j \rrbracket \big\}$ of values $z_k \in [x,y]$. 
With the convention that $z_i = x$ and $z_{j+1} = y$,
we associate an energy $\sum_{k=i}^j \big( B ( k,z_{k+1} ) - B( k,z_k ) \big)$ to any such list.
We then define  the maximum energy
$$
M^1_{(x,i) \to (y,j)} \, = \, \sup \, \bigg\{ \, \sum_{k=i}^j \Big( B ( k,z_{k+1} ) - B( k,z_k ) \Big) \, \bigg\} \, , 
$$
where the supremum is taken over all such lists. The random process $M^1_{(0,1) \to (\cdot,n)}: [0,\infty) \to \R$ was introduced by~\cite{GlynnWhitt} and further studied in~\cite{O'ConnellYor}.

% \sup \Big\{ E(\phi): \phi \in  \upright_{(x,i) \to (y,j)} \Big\} \, .





The one-third and two-thirds KPZ scaling considerations that we outlined earlier in the introduction are manifest in Brownian LPP. When the ending height $j$ exceeds the starting height $i$ by a large quantity $n \in \N$, and the location $y$ exceeds $x$ also by $n$, then the maximum energy grows linearly, at rate $2n$,
and has a fluctuation about this mean of order $n^{1/3}$. Moreover, if $y$ is permitted to vary from this location, then it is changes of $n^{2/3}$ in its value that result in a non-trivial correlation of the maximum energy with its original value.

These facts prompt us to introduce scaled coordinates to describe the two endpoint locations, and a notion of scaled maximum energy, which we will refer to as weight. 
Let  $n \in \N$, and 
suppose that $x,y \in \R$ satisfy 
 $y \geq x - 2^{-1} n^{1/3}$.
Define 
\begin{equation}\label{e.weightmzeroone} 
  \weight_{n;(x,0)}^{(y,1)} \,     =  \,   2^{-1/2} n^{-1/3} \Big(  M^1_{(2n^{2/3}x,0) \to (n  + 2n^{2/3}y,n)} - 2n  -  2n^{2/3}(y-x) \Big) \, .
\end{equation}
(Clearly, $n$ must be positive. In fact, $\N$ will denote $\{1,2,\cdots \}$ throughout.)


Consistently with the facts just mentioned, the quantity  $\weight_{n;(x,0)}^{(y,1)}$ may be expected to be, for given real choices of $x$ and $y$, a unit-order random quantity, whose law is tight in the scaling parameter $n \in \N$. The quantity describes, in units chosen to achieve this tightness, the maximum possible energy associated to journeys which in the original coordinates occur between  $(2n^{2/3}x,0)$ and $(n  + 2n^{2/3}y,n)$.
In scaled coordinates, this is a journey between $(x,0)$ and $(y,1)$.
We view the first coordinate as space and the second as time, so this journey is between $x$ and $y$ over the unit time interval $[0,1]$.


 Underlying this definition is a geometric picture of scaled maximizing paths, or polymers, that achieve these weight values. We will defer explicitly defining these polymers, but it is useful to bear in mind that 
  $\weight_{n;(x,0)}^{(y,1)}$ equals the weight of a polymer that travels between locations that in scaled coordinates equal $(x,0)$ and $(y,1)$.

\subsection{Main results}

In four subsections, we present the principal conclusions: on  polymer weight difference under horizontal perturbation of endpoints; our finite-$n$ 
assertion concerning the modulus of continuity of polymer weight profiles from general initial condition; the inference made about weak limit points of such profiles in the high~$n$ limit; 
and a general tool, on the rarity of deviation from parabolic curvature by polymer weights.

%First, we introduce a formulation of a polymer weight profile initiated by a very general initial condition, and state an assertion, Theorem~\ref{t.wlp.one}, to the effect that, in a certain uniform sense, any such profile has modulus of continuity at most $x^{1/2} \big( \log x^{-1} \big)^{2/3}$.
%This result articulates a one-half power law for such profiles, establishing that variation of one endpoint of a polymer results in a Holder continuity of $1/2-$ for the resulting weight; the result is refined by a poly-logarithmic correction.

%Our second main result, Theorem~\ref{t.differenceweight}, is a different articulation of this one-half power principle: when we consider a unit-time polymer whose endpoints are perturbed by a given small quantity $\e$, the change in polymer weight exceeds $\e^{1/2} R$ with probability $\exp \big\{ - O(1) R^{3/2} \big\}$ for given large $R$, uniformly in high choices of the scaling parameter $n \in \N$.
  
%  Our third result, Proposition~\ref{p.maxminweight}, shows that the weight profile $\weight_{n;(x,0)}^{(y,1)}$
 % hews to the parabolic shape $-2^{1/2}(y-x)^2$, with a maximum discrepancy from this shape as $(x,y)$ varies over any compact region whose tail has a super-exponential decay.

\subsubsection{Polymer weight change under horizontal perturbation of endpoints}\label{s.pwc}
Set $Q:\R \to \R$, $Q(z) = 2^{-1/2} z^2$.
The polymer weight   $\weight_{n;(x,0)}^{(y,1)}$  has a globally parabolic profile, hewing to the shape $-Q(y-x)$. When this parabolic term is added to the polymer weight, the result is a random process in $(x,y)$
which typically suffers changes of order $\e^{1/2}$
when $x$ or $y$ are varied on a small scale $\e > 0$.
Our first main result gives rigorous expression to this statement, uniformly in $(n,x,y) \in \N \times \R \times \R$ for which the difference $\vert y - x \vert$ is permitted to inhabit an expanding region about the origin, of scale~$n^{1/18}$.

\begin{theorem}\label{t.differenceweight}
Let $\e \in (0,2^{-4}]$. 
Let $n \in 2\N$ be an {\em even} integer that satisfies
$n \geq 10^{29} c^{-18}$ and let $x,y \in \R$ satisfy  $\big\vert x - y  \big\vert \leq 2^{-5/3} 3^{-1} \rsc  n^{1/18}$.
Let 
 $R \in \big[10^4 \, , \,   10^3 n^{1/18} \big]$.
Then
\begin{equation}\label{e.differenceweight}
\PP \left( \sup_{\begin{subarray}{c} u_1,u_2 \in [x,x+\e] \\
    v_1,v_2 \in [y,y+\e]  \end{subarray}} \Big\vert \weight_{n;(u_2,0)}^{(v_2,1)} + Q(v_2 - u_2) - \weight_{n;(u_1,0)}^{(v_1,1)} - Q(v_1 - u_1) \Big\vert  \, \geq \, \e^{1/2}
  R  \right)
\end{equation}
  is at most  $10032 \, C  \exp \big\{ - c_1 2^{-20}   R^{3/2}   \big\}$.
\end{theorem}
Here, we set $c_1 = 2^{-5/2} c \wedge 1/8$, where $\wedge$ denotes minimum. Bounds in Theorem~\ref{t.differenceweight}, and many later results, have been expressed explicitly up to two positive constants $c$ and $C$. See Subsection~\ref{s.regular} for a discussion of the role of this pair of constants.  




%In this result, an upper bound is being found on the probability that the maximum weight difference witnessed by variation of the starting or ending polymer endpoint on given intervals of length~$\e$ exceeds $\e^{1/2}R$. We may take $x$ and $y$ to be fixed locations, in a bounded interval, so that the hypothesis $n \geq \Theta(1) \vert x - y \vert^{18}$
%is rather mild, given that our aim is to understand these systems uniformly in high choices of $n$. 
The imposition in Theorem~\ref{t.differenceweight} that 
 $R \in \big[10^4 \, , \,   10^3 n^{1/18} \big]$ is rather weak, with the case where $R$ is fixed being of interest; and indeed, the decay rate asserted by the theorem 
 is already very fast when 
$R$ is of order $n^{1/18}$.
The condition that $n \in 2\N$ is even is a microscopic detail which transmits to certain later results.


\subsubsection{Maximum local variation of polymer weight profiles from general initial data}

What do we mean by such polymer weight profiles?  The random function $y \to   \weight_{n;(0,0)}^{(y,1)}$
may be viewed as the weight profile obtained by scaled maximizing paths that travel from the origin at time zero to the variable location $y$ at time one. This insistence that the paths must begin at the origin, called the narrow wedge by physicists, is of course rather special. 
We now make a more general definition, of the  $f$-rewarded line-to-point polymer weight  $\weight_{n;(*:f,0)}^{(y,1)}$. Here, $f$ is an initial condition, defined on the real line. 
Paths may begin anywhere on the real line at time zero; they travel to $y \in \R$ at time one. (Because they are free at the beginning and fixed at the end, we refer to these paths as `line-to-point'.) They begin with a reward given by evaluating $f$ at the starting location, and then gain the weight associated to the journey they make.  The value $\weight_{n;(*:f,0)}^{(y,1)}$, which we will define momentarily, denotes the maximum $f$-rewarded weight of all such paths.   In the notation $\weight_{n;(*:f,0)}^{(y,1)}$, we again use subscript and superscript expressions to refer to space-time pairs of starting and ending locations. The starting spatial location is being denoted $*:f$. The star is intended to refer to the free time-zero endpoint, which may be varied, and the $:f$ to the reward offered according to where this endpoint is placed.

The next definition specifies essentially the broadest class of $f$ suitable for a study of the weight profiles $y \to \weight_{n;(*:f,0)}^{(y,1)}$ for all sufficiently high $n \in \N$.



\begin{definition}\label{d.if}
Writing  $\ovbar\coninit = \big( \coninit_1,\coninit_2,\coninit_3 \big) \in (0,\infty)^3$ for a triple of positive reals, we let $\initcond_{\ovbar\coninit}$
denote the set of measurable functions $f:\R \to \R \cup \{ - \infty \}$ such that
$f(x) \leq \coninit_1 \big( 1 + \vert x \vert \big)$
and $\sup_{x \in [-\coninit_2,\coninit_2]} f(x) > - \coninit_3$.
\end{definition}



For $f$ lying in one of the function spaces 
$\initcond_{\ovbar\coninit}$, we now formally define the $f$-rewarded line-to-point polymer weight  $\weight_{n;(*:f,0)}^{(y,1)}$ to be 
$$
    \sup_{x \in (-\infty,2^{-1}n^{1/3} + y]} \big(  \weight_{n;(x,0)}^{(y,1)}    + f(x) \big)  \, .
$$



Our second main result asserts that the maximal variation in $f$-rewarded $n$-polymer weight over length~$\e > 0$ intervals in $[-1,1]$ is a controlled random multiple of $\e^{1/2} \big( \log \e^{-1}\big)^{2/3}$. 
The bound on probability, above scale 
$e^{-O(1)n^{1/12}}$, is asserted uniformly in initial 
data, and in $(n,\e)$, except for very small $\e \leq e^{-O(1)n^{1/12}}$. 
\begin{theorem}\label{t.nmodcon}
For $\ovbar\coninit \in (0,\infty)^3$, some  $c',r_0 = c'(\ovbar\coninit),r_0(\ovbar\coninit) > 0$ and all 
$f \in \initcond_{\ovbar\coninit}$,~$n~\in~2\N$~and~$r~\geq~r_0$,
\begin{equation}\label{e.nmodcon}
\PP \left( \sup_{\begin{subarray}{c} y,z \in [-1,1], \\
    2\exp \{-c' n^{1/12} \} < z - y < e^{-1}  \end{subarray}} \frac{\Big\vert \, \weight_{n;(*:f,0)}^{(z,1)} - \weight_{n;(*:f,0)}^{(y,1)} \, \Big\vert}{(z-y)^{1/2} \big( \log (z-y)^{-1} \big)^{2/3}} \, \geq \, r  \right) \leq  2^{45} c^{-4/3} r^{-2} \big( \log r \big)^{4/3} \vee 4e^{-c' n^{1/12}} \, .
\end{equation}
\end{theorem}


\subsubsection{Modulus of continuity of weak limits of weight profiles from general initial data}

Let $n \in \N$,  $\ovbar\coninit \in (0,\infty)^3$ and  $f \in \initcond_{\ovbar\coninit}$.
Let $\nu_{n;(*:f,0)}^{([-1,1],1)}$ denote the law of the random function
$$
[-1,1] \to \R : y \to \weight_{n;(*:f,0)}^{(y,1)} \, . 
$$

The control offered by Theorem~\ref{t.nmodcon} is certainly sufficient to show that the curves of any weak limit point of $\nu_{n;(*:f,0)}^{([-1,1],1)}$ as $n \to \infty$ (through even values) admit modulus of continuity $z^{1/2} \big( \log z^{-1} \big)^{2/3}$, up to a random factor that is controlled uniformly in the choice of limit point.

To formulate a theorem in this regard,
let $\mathcal{A}$ be an arbitrary index set, and let  $\big\{ \nu_{n,\alpha}: n \in \N \big\}$, $\alpha \in \mathcal{A}$, be an $\mathcal{A}$-indexed collection of sequences of probability measures on the Borel $\sigma$-algebra of a  given Hausdorff topological space. The collection is here called $\mc{A}$-uniformly tight  if, for each $\e > 0$, there exist $n_0 \in \N$ and a compact set $K$ such that 
 $\nu_{n,\alpha}(K) \geq 1 - \e$ whenever $n \geq n_0$ and $\alpha \in \mathcal{A}$.

\begin{theorem}\label{t.wlp.one}
Let $\ovbar\coninit \in (0,\infty)^3$ denote a triple of positive reals. 
\begin{enumerate}
\item  Suppose that $n \in \N$ satisfies
$n > 2^{-3/2} \coninit_1^3 \vee 8 (\coninit_2  + 1)^3$.
 Let    $f \in \initcond_{\ovbar\coninit}$.  Then  the  measure  $\nu_{n;(*:f,0)}^{([-1,1],1)}$ is supported on
the space $\mc{C}$ of continuous real-valued functions on $[-1,1]$.
% $\mc{C} = \mc{C}_{*,*} \big( [-1,1],\R \big)$.
%\item Let $\mc{C}$ be given the topology of uniform convergence. For any $\e > 0$,  there exists a compact $K \subset \mc{C}$ 
%and $n_0 = n_0(\e) \in \N$ such that $\nu_{n;(*:f,0)}^{([-1,1],1)}(K) \geq 1 - \e$ whenever $n \geq n_0$ and $f \in  \initcond_{\ovbar\coninit}$.]
\item The collection of sequences of probability measures
$\big\{ \nu_{n;(*:f,0)}^{([-1,1],1)}: n \in 2\N  \big\}$ indexed by $f \in \initcond_{\ovbar\coninit}$ is $\initcond_{\ovbar\coninit}$-uniformly tight. Here, the space $\mc{C}$
is endowed with the topology of uniform convergence.
\item A law on $\mc{C}$ is said to belong to the {\em weak limit point} set 
$\wlp_{\ovbar{\coninit}}$ if, for some sequence $f_n \in  \initcond_{\ovbar\coninit}$, $n \in 2\N$, it equals the weak limit of the laws    $\nu_{n;(*:f_n,0)}^{([-1,1],1)}$ along some {\em even-indexed} subsequence of $n \in 2\N$. By~$(2)$, $\wlp_{\ovbar{\coninit}} \not= \emptyset$. 
%is  non-empty.
% (and every $f_n$ sequence contributes). 
For any $\nu \in \wlp_{\ovbar{\coninit}}$, let $X$ be $\nu$-distributed. Then, for~$r~\geq~r_0$,
\begin{equation}\label{e.nur}
\nu \left( \, \sup_{\begin{subarray}{c} x,y \in [-1,1], \\
    x < y < x + e^{-1}  \end{subarray}} \frac{\big\vert X(y) - X(x) \big\vert}{(y-x)^{1/2} \big( \log (y-x)^{-1} \big)^{2/3}} \, \geq \, r \,  \right) \, \leq \,   2^{45} c^{-4/3} r^{-2} \big( \log r \big)^{4/3} \, ,
\end{equation}
where Theorem~\ref{t.nmodcon} provides the constant $r_0 = r_0(\ovbar\coninit)$.
%Consider the random variable~$S$ given by the supremum of the ratio of 
% $\big\vert X(y) - X(x) \big\vert$ and $(y-x)^{1/2} \big( \log (y-x)^{-1} \big)^{2/3}$ as the variables $x$ and $y$ vary over~$[-1,1]$ subject to $x < y$.
% Then $S$ is almost surely finite. Indeed, its probability of exceeding any $y > 1$ is at most $D y^{-2} \big( \log y \big)^{4/3}$, where $D \in (0,\infty)$ is a constant that may be chosen independently of  $\nu \in \wlp_{\ovbar{\coninit}}$. 
\end{enumerate}
\end{theorem}


Brownian motion on a unit interval has modulus of continuity of order $x^{1/2} \big( \log x^{-1} \big)^{1/2}$,
and it may be expected that some version of Theorem~\ref{t.wlp.one}(3) is valid with the logarithmic power of two-thirds replaced by one-half. Indeed, in the special case of narrow wedge initial data, such a result has been proved: see~\cite[Theorem~$2.13$]{BrownianReg}, or \cite[Theorem~$1.11(1)$]{BrownianReg}
for a result concerning the {\rm Airy}$_2$ process.




\subsubsection{Tail behaviour of polymer weight suprema and infima}

Theorem~\ref{t.differenceweight} quantifies polymer weight changes in response to horizontal endpoint perturbation after the weight has been adjusted by the addition of the parabola~$Q(z) = 2^{-1/2} z^2$. 
In our fourth result, we verify that the point-to-point polymer weight profile indeed strongly hews to this given parabola. 
The regime where this is verified is that in which the polymer endpoints differ by at most an order of $n^{1/18}$.
Within this zone, the inference is made uniformly as the endpoints vary over any given unit-order region.
\begin{proposition}\label{p.maxminweight}
Let $n \in \N$ be even and satisfy 
$n \geq 10^{29} \vee 2(c/3)^{-18}$. Let $x,y \in \R$ 
satisfy
$\big\vert x - y  \big\vert \leq   3^{-1} 2^{-2/3} \rsc  n^{1/18}$.  Let $t \in \big[  33 \, , \, 4 n^{1/18} \big]$. 
Then
\begin{equation}\label{e.weightuvsupremum} 
 \PP \bigg( \sup_{u,v \in [0,1]} \Big( \weight_{n;(x+u,0)}^{(y+v,1)} + Q( y+v - x - u ) \Big) \geq t \bigg)  \leq    139 C  \exp \big\{ - c_1 2^{-9} t^{3/2} \big\}  
\end{equation}
and
\begin{equation}\label{e.weightuvinfimum}
  \PP \bigg(  \inf_{u,v \in [0,1]} \Big( \weight_{n;(x+u,0)}^{(y+v,1)} + Q(y+v-x - u) \Big) \leq - t  \bigg) 
   \leq  261 C \exp \big\{ - c_1 2^{-5/2} t^{3/2} \big\} \, . 
\end{equation}
\end{proposition}
In~\cite[Propositions~$10.1$ and~$10.5$]{SlowBondSol}, comparable bounds are proved for exponential and Poissonian LPP, with bounds  of the form
$\exp \big\{ - O(1) t \big\}$. These propositions have the flexibility of treating extremal weights of polymers whose endpoints are permitted to vary over compact regions in space as well as time, rather than merely time, as it is the case for Proposition~\ref{p.maxminweight}.

 


\subsection{The road map}



Theorem~\ref{t.differenceweight}, which is a key result underlying Theorems~\ref{t.nmodcon} and~\ref{t.wlp.one}, is proved using ideas similar to the proof of the Kolmogorov continuity criterion. The authors of~\cite{QR13} note in Section~$1.1$ that the task of checking the Kolmogorov criterion on the basis of suitable two-point information for such processes as {\rm Airy}$_1$
has turned out to be surprisingly difficult. 
Similar subtleties arise in our context:
two-point information has to be presented in a way that is valid on arbitrarily small scales, without the index $n$ needing to rise. The crucial tool that will enable the derivation of Theorem~\ref{t.differenceweight}
is a powerful two-point estimate with the necessary attributes, Proposition~\ref{p.locreg}.


Section~\ref{s.basicnot} introduces notation for the use of scaled coordinates and presents some basic results about polymer weight.

 In Section~\ref{s.lineensembles},  the engine for our main results,  Proposition~\ref{p.locreg}, namely the two-point estimate for narrow wedge weight profiles, is stated and proved. In this section, we will explain how the narrow wedge profile may be embedded as the uppermost curve in a certain system of ordered random continuous curves called a line ensemble. A suitably normalized version of any such line ensemble has the {\em Brownian Gibbs} property, which in essence means it is a system of mutually avoiding Brownian bridges. Its curves moreover have a globally parabolic shape, and a definition of {\em regular} ensemble is made to capture these attributes. The short proof of Proposition~\ref{p.locreg} harnesses the Brownian Gibbs property in an essential way. Certain further properties of regular  ensembles are needed, and these also appear in Section~\ref{s.lineensembles} as Proposition~\ref{p.mega}, quoted from~\cite{BrownianReg}. 


In three further sections  are then respectively proved 
Proposition~\ref{p.maxminweight}; Theorem~\ref{t.differenceweight}; and Theorems~\ref{t.nmodcon} and~\ref{t.wlp.one}.



\subsubsection{Comment on the companion papers~\cite{BrownianReg},~\cite{NonIntPoly} and~\cite{Patch}.} 
Via the upcoming Proposition~\ref{p.mega} and Lemma~\ref{l.pardom}, this article draws on Brownian Gibbs results developed in~\cite{BrownianReg}. That article is long and it is worth pointing out that the concerned results in~\cite{BrownianReg} are simple and have short proofs.
The present article's main conclusions about scaled Brownian LPP are applied in the later two companion papers. The article  may be read on its own,
or viewed as part of this four-paper study, an overview of which appears in~\cite[Section~$1.2$]{BrownianReg}.


\subsubsection{Acknowledgments.}
%The author thanks Riddhipratim Basu, Shirshendu Ganguly and Jeremy Quastel for valuable conversations at many stages of this project. 
%submit 
The author thanks Riddhipratim Basu, Ivan Corwin,  Shirshendu Ganguly and Jeremy Quastel for valuable conversations, and three referees for helpful comments. 



\section{The basics: notation, scaling, polymers and their weight}\label{s.basicnot}
In consecutive subsections, we introduce notation; describe Brownian LPP in scaled coordinates; offer a principle that aids in working with these coordinates, and an application; discuss basics about polymers; and provide a simple result about them.
\subsection{General notation and structure}
%\vspace{-3mm}
\subsubsection{Notation}
Let $i,j \in \Z$ with $i \leq j$. Recall that $\llbracket i,j \rrbracket$ denotes the integer interval $\{ i,\cdots  , j \}$.

For $k \geq 1$, we write $\R^k_\leq$
for the subset of $\R^k$ whose elements $(z_1,\cdots,z_k)$
are non-decreasing sequences. When the sequences are increasing, we instead write $\R^k_<$. We also use the notation $A^k_\leq$ and $A^k_<$.
Here, $A \subset \R$ and the sequence elements are supposed to belong to $A$.
We will typically use this notation when $k=2$.


A bar over a symbol indicates a vector, as in the usage
$\ovbar\coninit = \big( \coninit_1,\coninit_2,\coninit_3 \big)$
% \in (0,\infty)^3 
in Theorems~\ref{t.nmodcon} and~\ref{t.wlp.one}.

\subsubsection{The role of hypotheses invoked during proofs}\label{s.calcderexplain}

Our proofs invoke several inputs, notably  three $\rmreg$ conditions that specify the notion of a regular ensemble, and Propositions~\ref{p.mega} and~\ref{p.locreg}. 
Whenever such results are invoked, certain conditions on the concerned hypotheses will be needed. We will always note explicitly what these conditions are, whenever such an application is made.
Clearly, it is necessary that the hypotheses of the result that is being proved collectively imply all the conditions that are invoked during its proof. 
The work needed to do this for a given result may be called the {\em calculational derivation} of that result. 
These derivations have almost no conceptual content, reach conclusions that in their overall form are plausible, consist of largely trivial steps, and will be of interest to only the most committed of readers (perhaps only those who are actually applying the results). 
In some cases, however, the derivations occupy a fair amount of space. We have chosen to separate the principal calculational derivations from the body of the proofs in this article.
The concerned results are  Theorem~\ref{t.differenceweight}, 
Proposition~\ref{p.maxminweight}, Proposition~\ref{p.dyadic}, and Lemmas~\ref{l.regfluc} and~\ref{l.equicty}.  
%Their calculational derivations are presented in an appendix to this paper. 
%submit 
Their calculational derivations are presented in 
a supplement to this paper, Appendix~$A$.
%to this paper which appears only in the version on the author's webpage: see~\url{math.berkeley.edu/~alanmh/papers/ModCon.pdf}.


\subsection{Scaling: staircases to zigzags,  energy to weight, and geodesics to polymers}

\subsubsection{Staircases.}

Taking  $i,j \in \N$ with $i \leq j$, and 
$x,y \in \R^2_\leq$,
we have ascribed in Section~\ref{s.brlpp} an energy to  any non-decreasing list $\big\{ z_k: k \in \llbracket i+1,j \rrbracket \big\}$ of values $z_k \in [x,y]$.
In order to emphasise the geometric aspects of this definition, and in the hope that it may aid the visualization of the concerned concepts,
 we associate to each list a  subset of $[x,y] \times [i,j] \subset \R^2$, which will be the range of a piecewise affine path,  
 that we call a staircase.
 
 To define the staircase associated to $\big\{ z_k: k \in \llbracket i+1,j \rrbracket \big\}$, 
we again adopt the convention that $z_i = x$ and  $z_{j+1} = y$. 
The staircase is specified as the union of certain horizontal planar line segments, and certain vertical ones.
The horizontal segments take the form $[ z_k,z_{k+1} ] \times \{ k \}$ for $k \in \llbracket i , j \rrbracket$.
The right and left endpoints of each consecutive pair of horizontal segments are interpolated by a vertical planar line segment of unit length. It is this collection of vertical line segments that form
the vertical segments of the staircase.

The resulting staircase may be depicted as the range of an alternately rightward and upward moving path from starting point $(x,i)$ to ending point $(y,j)$. 
The set of staircases with these starting and ending points will be denoted by $\staircase_{(x,i) \to (y,j)}$.
Such staircases are in bijection with the collection of non-decreasing lists already considered. Thus, any staircase $\phi \in \staircase_{(x,i) \to (y,j)}$
is assigned an energy $E(\phi) = \sum_{k=i}^j \big( B ( k,z_{k+1} ) - B( k,z_k ) \big)$ via the associated $z$-list. 





\subsubsection{Energy maximizing staircases are called geodesics.}
A staircase  $\phi \in \staircase_{(x,i) \to (y,j)}$ whose energy  attains the maximum value $M^1_{(x,i) \to (y,j)}$ is called a geodesic from $(x,i)$ to~$(y,j)$.
It is a simple consequence of the continuity of the constituent Brownian paths $B(k,\cdot)$
that this geodesic exists for all choices of $(x,y) \in \R^2_\leq$.
It is also true, and is proved in~\cite[Lemma~$A.1$]{Patch},
%l.severalpolyunique
 that, for any given such choice of the pair $(x,y)$, there is an almost surely unique geodesic from  $(x,i)$ to~$(y,j)$.
However, this uniqueness will not be needed in the present article.


\subsubsection{The scaling map.}
For $n \in \N$, consider the $n$-indexed {\em scaling} map $R_n:\R^2 \to \R^2$ given by
$$
 R_n \big(v_1,v_2 \big) = \Big( 2^{-1} n^{-2/3}( v_1 - v_2) \, , \,   v_2/n \Big) \, .
$$ 
 
The scaling map acts on subsets $C$ of $\R^2$ by setting
$R_n(C) = \big\{ R_n(x): x \in C \big\}$.

\subsubsection{Scaling transforms staircases to zigzags.}
The image of any staircase under $R_n$
will be called an $n$-zigzag. The starting and ending points of an $n$-zigzag $Z$ are defined to be the image under $R_n$
of such points for the staircase $S$ for which $Z = R_n(S)$.
 
Note that the set of horizontal lines is invariant under $R_n$, while vertical lines are mapped to lines of gradient  $- 2 n^{-1/3}$.
As such, an $n$-zigzag is the range of a piecewise affine path from the starting point to the ending point which alternately moves rightwards  along horizontal line segments  and northwesterly along sloping line segments, where each sloping line segment has gradient  $- 2 n^{-1/3}$.
%; the first and last segment in this journey may be either horizontal or sloping.
%submit omit from `the first'.

 
 \subsubsection{Compatible triples.}
 Let $(n,t_1,t_2) \in \N \times \R^2_<$, which is to say that $n \in \N$ and $t_1,t_2 \in \R$ with $t_1 < t_2$.
 Taking $x,y \in \R$, does there exist an $n$-zigzag from $(x,t_1)$ and $(y,t_2)$?
 As far as the data $(n,t_1,t_2)$ is concerned, such an $n$-zigzag may exist only if 
 \begin{equation}\label{e.ctprop}
     \textrm{$t_1$ and $t_2$ are integer multiplies of $n^{-1}$} \, .
\end{equation}
We say that data $(n,t_1,t_2)  \in \N \times \R^2_<$ is a {\em compatible triple} if it verifies the last condition. 
We will consistently impose this condition, whenever we seek to study $n$-zigzags whose lifetime is $[t_1,t_2]$.
The use of compatible triples should be considered to be a fairly minor, microscopic, detail. As the index $n$ increases, the $n^{-1}$-mesh becomes finer, so that the space of $n$-zigzags better approximates a field of functions, defined on arbitrary finite intervals of the vertical coordinate, and taking values in the horizontal coordinate.     

An important piece of notation associated to a compatible triple is $\tot$, which will denote the difference $t_2 - t_1$. The law of the underlying Brownian ensemble $B: \Z \times \R \to \R$ is invariant under integer shifts in the first, curve indexing, coordinate. This translates to an invariance in law of scaled objects under vertical shifts by multiples of $n^{-1}$, something that makes the parameter $\tot$
of far greater relevance than $t_1$ or $t_2$.


\begin{figure}[ht]
\begin{center}
\includegraphics[height=7cm]{NonIntPolyScaling.pdf}
\caption{Let $(n,t_1,t_2)$ be a compatible triple and let $x, y \in \R$. The endpoints of the geodesic in the left sketch are such that, when the scaling map~$R_n$ is applied to produce the right sketch,  the result is an $n$-polymer from $(x,t_1)$ to $(y,t_2)$.
%$\rho_{n;(x,t_1)}^{(y,t_2)}$ results.
  }
\label{f.scaling}
\end{center}
\end{figure}  


\subsubsection{Staircase energy scales to zigzag weight.}
Let $n \in \N$ and $(i,j) \in \N^2_<$.
Any $n$-zigzag $Z$ from $(x,i/n)$ to $(y,j/n)$  is ascribed a scaled energy, which we will refer to as its weight, 
$\weight(Z) = \weight_n(Z)$, given by 
\begin{equation}\label{e.weightzigzag}
 \weight(Z) =  2^{-1/2} n^{-1/3} \Big( E(S) - 2(j - i)  - 2n^{2/3}(y-x) \Big) 
\end{equation}
where $Z$ is the image under $R_n$ of the staircase $S$.

\subsubsection{Maximum weight.} Let $n \in \N$. The quantity
 $\weight_{n;(x,0)}^{(y,1)}$ specified in~(\ref{e.weightmzeroone}) is nothing other than 
 the maximum weight ascribed to any $n$-zigzag from $(x,0)$ to $(y,1)$.
 
 Let $(n,t_1,t_2) \in \N \times \R^2_<$ be a compatible triple. 
Suppose that $x,y \in \R$ satisfy 
 $y \geq x - 2^{-1} n^{1/3} \tot$. We now offer a definition of  $\weight_{n;(x,t_1)}^{(y,t_2)}$ such that this quantity equals maximum weight of any $n$-zigzag from $(x,t_1)$ to $(y,t_2)$.
 We must set 
\begin{equation}\label{e.weightm}
  \weight_{n;(x,t_1)}^{(y,t_2)} \,     =  \,   2^{-1/2} n^{-1/3} \Big(  M^1_{(n t_1 + 2n^{2/3}x,n t_1) \to (n t_2 + 2n^{2/3}y,n t_2)} - 2n \tot -  2n^{2/3}(y-x) \Big) \, .
\end{equation}
 \subsubsection{Highest weight zigzags are called polymers.}\label{s.polymer}
 An $n$-zigzag that attains this maximum will be called an $n$-polymer, or usually, simply a polymer.
 Thus, geodesics map to polymers under the scaling map. %For  given endpoints, almost sure uniqueness of the polymer is known by~\cite[Lemma~$4.6(1)$]{Patch}.  
 %l.densepolyunique
%% of the geodesic, (and thus from scaling also of the polymer), is known by [Patch2, Lemma~$7.1$]. 
% The unique polymer from  $(x,t_1)$ to $(y,t_2)$ may be called $\rho_{n;(x,t_1)}^{(y,t_2)}$: it is depicted in Figure~\ref{f.scaling}. We do not need polymer uniqueness and when we occasionally allude to polymers, 
We will write~$\rho_{n;(x,t_1)}^{(y,t_2)}$ for {\em any} $n$-polymer  $(x,t_1)$ to $(y,t_2)$ (see Figure~\ref{f.scaling}), since we do not invoke polymer uniqueness results in this article. 
\subsubsection{Parameter settings in applications of results will be indicated in boldface.}\label{s.boldface}
Often we apply results involving several parameters. Typically these include the index $n$, times $t_1$ and $t_2$, and spatial locations such as $x$ and $y$.
Whenever we apply results, we will always state what these parameter settings are. When we do so, we will use boldface to indicate the variables in the result being applied, expressing these in terms of non-boldface variables, which assume their values from the current context. This device permits notational conflicts to be deescalated (so that notational choices need not proliferate, as they would were these conflicts to be   eliminated by other means).
\subsection{The scaling principle}
Let $(n,t_1,t_2) \in \N \times \R^2_<$ be a compatible triple. The quantity $n \tot$ is a positive integer, in view of the defining property~(\ref{e.ctprop}).
The scaling map $R_k: \R^2 \to \R^2$ has been defined whenever $k \in \N$, and thus we may speak of $R_n$  and $R_{n \tot}$.
The map $R_n$ is the composition of $R_{n \tot}$ and the transform $S_{\tot^{-1}}$ given by $\R^2 \to \R^2: (a,b) \to \big(a\tot^{-2/3},b\tot^{-1}\big)$. That is, the system of $n\tot$-zigzags is transformed into the system of $n$-zigzags
by an application of  $S_{\tot^{-1}}$.  Note from~(\ref{e.weightm}) that $\weight_{n;(x,t_1)}^{(y,t_2)} =  \tot^{1/3} \weight_{n \tot ;(x \tot^{-2/3},\kappa)}^{(y \tot^{-2/3},\kappa + 1)}$, where $\kappa = t_1 \tot^{-1}$; indeed this weight transformation law is valid for all zigzags, rather than just polymers, in view of~(\ref{e.weightzigzag}).
 
We may summarise these inferences by saying that the system of $n\tot$-zigzags, including their weight data, is transformed into the $n$-zigzag system, and its accompanying weight data, by the transformation $\big( a,b,c \big) \to \big( a \tot^{-1/3}  ,b \tot^{-2/3} , c \tot^{-1} \big)$, where the coordinates refer to the changes suffered in weight, 
%and
 horizontal and vertical coordinates.
 This fact leads us to what we call the {\em scaling principle}. 
 
 \noindent{\em The scaling principle.} 
Let $(n,t_1,t_2) \in \N \times \R^2_<$ be a compatible triple.
 Any statement concerning the system of $n$-zigzags, including weight information, is equivalent to the corresponding statement concerning the system of $n\tot$-zigzags, provided that the following changes are made:
 \begin{itemize}
 \item the index $n$ is replaced by $n\tot$;
 \item any time is multiplied by $\tot^{-1}$;
 \item any weight is multiplied by $\tot^{1/3}$;
 \item and any horizontal distance is multiplied by $\tot^{-2/3}$.
 \end{itemize}
 
\subsubsection{The scaling principle applied:  uniform control on polymer weight for a general time-pair.}\label{s.spa}
Proposition~\ref{p.maxminweight}
provides a uniform control on polymer weights whose starting and ending points lie in $[x,x+1] \times \{0\}$ and  $[y,y+1] \times \{1\}$.
We now illustrate the scaling principle by using it to extend the proposition to treat the case where these intervals are replaced by   $[x,x+ \tot^{2/3}] \times \{ t_1 \}$ and  $[y,y + \tot^{2/3}] \times \{t_2\}$ for a general time pair $(t_1,t_2)$.

%We illustrate scaling by extending the definition~(\ref{e.lwr}) of the local weight regularity event to a general pair of times, and using the scaling principle to pass from Proposition~\ref{p.maxminweight}
%to a corollary that treats this general time pair.




We phrase this more general result as an upper bound on the probability of a {\em polymer weight regularity} event. To define the new event, 
we again consider a compatible triple $(n,t_1,t_2) \in \N \times \R^2_<$. 
For $x,y \in \R$, $w_1,w_2 \geq 0$ and  $r > 0$, let $\maxmin_{n;([x,x+w_1],t_1)}^{([y,y+w_2],t_2)}( r )$ denote the event that, for all $(u,v) \in [0,w_1] \times [0,w_2]$,
$$
\Big\vert \, \tot^{-1/3} \weight_{n;(x+u,t_1)}^{(y+v,t_2)} +  2^{-1/2} \tot^{-4/3}  \big(y+v-x - u \big)^2 \, \Big\vert \, \leq \, r \, .
$$
We write $\neg \, A$ for the complement of the event $A$.
%When $w_1 = 0$, so that the interval $[x,x+w_1]$ is a singleton, we write $x$ in place of $\{ x \}$ or $[x,x]$ in using this notation.  
\begin{corollary}\label{c.maxminweight}
Let $(n,t_1,t_2) \in \N \times \R^2_<$ be a compatible triple.
Suppose further that the integer
$n\tot$ is even and that it is at least $10^{29} \vee 2(c/3)^{-18}$.
 Let $x,y \in \R$ and  $a,b \in \N$ be   such that
$\big\vert x - y  \big\vert \tot^{-2/3} + \max\{ a,b\} - 1 \leq   3^{-1} 2^{-2/3} \rsc  (n\tot)^{1/18}$.
 Let $r \in \big[  33 \, , \, 4 (n \tot)^{1/18} \big]$.
Then
$$
 \PP \Big( \neg \, \maxmin_{n;([x,x+a \tot^{2/3}],t_1)}^{([y,y+b\tot^{2/3}],t_2)}(r) \Big) \leq  
 ab \cdot  400 C \exp \big\{ - c_1 2^{-9} r^{3/2} \big\} \, .
$$
\end{corollary}
\noindent{\bf Proof.} 
%of Corollary~\ref{c.maxminweight}.} 
It is immediate from  Proposition~\ref{p.maxminweight} that  
\begin{equation}\label{e.negmaxmin}
 \PP \Big( \neg \, \maxmin_{n;([x,x+1],0)}^{([y,y+1],1)}(r) \Big) \leq  
  400 C \exp \big\{ - c_1 2^{-9} r^{3/2} \big\} \, .
\end{equation}
when
$n \geq 10^{29} \vee 2(c/3)^{-18}$,
$\big\vert x - y  \big\vert \leq   3^{-1} 2^{-2/3} \rsc  n^{1/18}$ and $r \in \big[  33 \, , \, 4 n^{1/18} \big]$.

By the scaling principle and invariance under vertical shift, we know that
$$
 \PP \Big( \maxmin_{n;([x,x+ \tot^{2/3}],t_1)}^{([y,y+\tot^{2/3}],t_2)}(r)
  \Big) \, = \,  
 \PP \bigg( \maxmin_{n \tot;([0,1],0)}^{\big( \big[ (y-x)\tot^{-2/3} ,  (y-x)\tot^{-2/3} + 1 \big] , 1 \big)}(r)
  \bigg) \, .
$$
Consider (\ref{e.negmaxmin}) with parameter settings ${\bf n} = n \tot$, ${\bf x} = 0$, ${\bf y} =  (y-x)\tot^{-2/3}$ and ${\bf r} = r$. 
(This is the first use of boldface notation as specified in Subsection~\ref{s.boldface}. Its use here deprives ${\bf n} = n \tot$ of ambiguity of meaning, for example.)
We find then that  
\begin{equation}\label{e.probmaxmin}
 \PP \Big( \neg \, \maxmin_{n;([x,x+ \tot^{2/3}],t_1)}^{([y,y+\tot^{2/3}],t_2)}(r)
  \Big) \leq 
  400 C \exp \big\{ - c_1 2^{-9} r^{3/2} \big\}
\end{equation}
provided that 
$n\tot \geq 10^{29} \vee 2(c/3)^{-18}$,
$\big\vert x - y  \big\vert \tot^{-2/3} \leq   3^{-1} 2^{-2/3} \rsc  (n\tot)^{1/18}$ and $r \in \big[  33 \, , \, 4 (n\tot)^{1/18} \big]$.


This last bound is then summed over the $ab$ choices of pairs 
$$
\big({\bf x},{\bf y} \big) \in \big\{ x, x + \tot^{2/3}, \cdots,x+(a-1)\tot^{2/3}\big\} \times \big\{ y, y + \tot^{2/3},  \cdots, y+(b -1) \tot^{2/3} \big\}
$$
in order to obtain the corollary. Note that we hypothesise that 
$\big\vert x - y  \big\vert \tot^{-2/3} + \max\{ a,b\} - 1$ be at most   $3^{-1} 2^{-2/3} \rsc  (n\tot)^{1/18}$ in order that the bound~(\ref{e.probmaxmin}) be valid for these parameter choices. \qed

Actually, when we apply this corollary in the present article, it will be in the case that $t_1 = 0$ and $t_2 = 1$, so in fact the use of the scaling principle is unnecessary in this regard.
It is useful, however, to have a general form for the corollary: for example, it is used in~\cite{NonIntPoly}.


\subsection{Polymers}

\subsubsection{Polymer concatenation}

Let $n \in \N$ and $(t_1,t_2,t_3) \in \R^3_\leq$ be such that $(n,t_1,t_2)$ and $(n,t_2,t_3)$ are compatible triples.
Let $x,y,z \in \R$.
In accordance with the convention stated in Subsection~\ref{s.polymer}, we may consider $n$-polymers $\rho_{n;(x,t_1)}^{(y,t_2)}$ and $\rho_{n;(y,t_2)}^{(z,t_3)}$.
The union of these two subsets of $\R^2$ is clearly an $n$-zigzag from $(x,t_1)$ and $(z,t_3)$.
In the union, the journey over the latter polymer follows that over the former. For this reason, we regard the union polymer as the concatenation of the two given polymers, and denote it by 
$\rho_{n;(x,t_1)}^{(y,t_2)} \circ \rho_{n;(y,t_2)}^{(z,t_3)}$. The new polymer's weight equals $\weight_{n;(x,t_1)}^{(y,t_2)} + \weight_{n;(y,t_2)}^{(z,t_3)}$.

\subsubsection{Polymer splitting}

Opposite to the operation of polymer concatenation is the splitting of a given polymer into two pieces. 
Let  $(n,t_1,t_2) \in \N \times \R^2_\leq$ be a compatible triple, and let $(x,y) \in \R^2$
satisfy  $y \geq x - 2^{-1} n^{1/3} \tot$. Let $t \in (t_1,t_2)$
be 
such that $(n,t_1,t)$ and $(n,t,t_2)$ are also compatible triples.
For any polymer $\rho_{n;(x,t_1)}^{(y,t_2)}$, we may select an element $(z,t) \in \rho_{n;(x,t_1)}^{(y,t_2)}$.
The removal of $(z,t)$ from $\rho_{n;(x,t_1)}^{(y,t_2)}$ creates two connected components. 
Taking the closure of each of these amounts to adding the point $(z,t)$ to each of them. The resulting sets are $n$-zigzags from $(x,t_1)$ to $(z,t)$, and from $(z,t)$ to $(y,t_2)$; in fact,
it is straightforward to see that they are $n$-polymers. 


\subsubsection{Polymer crossing and rewiring}\label{s.polymercross}

We now make some comments about the implications of the event that two polymers cross. 
We do so for line-to-point polymers. 
For $\ovbar\coninit \in (0,\infty)^3$, let $f \in \initcond_{\ovbar\coninit}$.
Let $(n,t_1,t_2) \in \N \times \R^2_\leq$ be a compatible triple, and let $y \in \R$.
An $n$-zigzag $\phi$ from $(x,t_1)$, where $x \in \R$, to $(y,t_2)$, whose $f$-rewarded weight $\weight(\phi) + f(x)$ attains the maximum value 
$\weight_{n;(*:f,t_1)}^{(y,t_2)}$, is called an $f$-rewarded line-to-point polymer.
Such polymers are born free, but not equal: an endowment of $f$ is bestowed according to the place of birth. Pursuing a similar convention to that used in the point-to-point case, 
{\em any} such polymer will be denoted by $\rho_{n;(*:f,t_1)}^{(y,t_2)}$.
% The almost sure uniqueness of this 
%%born free 
%polymer for given $y \in \R$ is assured by~%\cite[Lemma~$4.6(2)$]{Patch}, 
% %l.densepolyunique
% but this information is irrelevant for our present study.

Suppose that two $f$-rewarded line-to-point polymers cross. That is, suppose that $(x_1,x_2) \in \R^2_<$
and $(y_1,y_2) \in \R_<^2$ are such that there exist such polymers, labelled  $\rho_{n;(*:f,t_1)}^{(y_1,t_2)}$ and  $\rho_{n;(*:f,t_1)}^{(y_2,t_2)}$ by our convention,
whose journeys are $(x_2,t_1) \to (y_1,t_2)$ and $(x_1,t_1) \to (y_2,t_2)$. The two polymers necessarily meet, and indeed the union of the horizontal segments of the two polymers also meet.
If $(z,t)$ is such a point of intersection, the operation of polymer splitting at $(z,t)$ may be applied to the two polymers, resulting in decompositions that may be respectively labelled $\rho_1 \circ \rho_2$
and $\rho_3 \circ \rho_4$. 
%See Figure~[]. 
The zigzags $\rho_1$ and $\rho_3$
share their $f$-rewarded weights, $\weight(\rho_1) + f(x_2)$ and  $\weight(\rho_3) + f(x_1)$, because the weight maximality of  $\rho_1 \circ \rho_2$
and $\rho_3 \circ \rho_4$ each enforce one of the two inequalities between these quantities. 
Thus,  $\rho_1 \circ \rho_2$ and  $\rho_3 \circ \rho_2$
share their $f$-rewarded weight, and so do $\rho_3 \circ \rho_4$ and $\rho_1 \circ \rho_4$. The new, rewired, zigzags $\rho_3 \circ \rho_2$ and $\rho_1 \circ \rho_4$
are thus seen to be $f$-rewarded line-to-point polymers.

In summary, when two $f$-rewarded line-to-point polymers cross, the rewiring just undertaken results in an alternative pair of such polymers so that the old pair and the new share their set of starting and ending points.
%When the almost sure uniqueness of $f$-rewarded polymers ending at a given point is known, this observation may be developed to prove the absence of such crossing among these polymers, and to build a picture of a tree of coalescing $f$-rewarded polymers. We do not develop these ideas here, but we will make use of the rewiring of crossing polymers on one occasion.


 


%This definition raises the same two questions that the point-to-point scenario did a few moments ago. Does the new polymer exist? And is it unique?





\subsection{A simple lemma concerning polymer weight}

\begin{lemma}\label{l.basic}
Let $(n,t_1,t_2) \in \N \times \R^2_<$
be a compatible triple. 
\begin{enumerate}
\item The random function $(x,y) \to \weight_{n;(x,t_1)}^{(y,t_2)}$,
which is defined on the set of $(x,y) \in \R^2$ 
satisfying $y \geq x - 2^{-1} n^{1/3} \tot$, is continuous almost surely.
\item
Further consider an intermediate time $t \in (t_1,t_2)$
such that $(n,t_1,t)$ and $(n,t,t_2)$ are compatible triples.
Let $x,y,z \in \R$. Then 
$$
 \weight_{n;(x,t_1)}^{(y,t_2)} \geq  \weight_{n;(x,t_1)}^{(z,t)} +  \weight_{n;(z,t)}^{(y,t_2)} \, ,
$$
provided that these three weights are well defined. (The explicit conditions that ensure that the definitions make sense are 
$y \geq x - 2^{-1} n^{1/3} \tot$, $z \geq x - 2^{-1} n^{1/3} (t - t_1)$ and  $y \geq z - 2^{-1} n^{1/3} (t_2 - t)$.)
 \item Let  $\ovbar\coninit \in (0,\infty)^3$ and  $f \in \initcond_{\ovbar\coninit}$.  Suppose that $n \in \N$ satisfies
$n > 2^{-3/2} \coninit_1^3 \vee 8 (\coninit_2  + 1)^3$. Then  $[-1,1] \to \R: y \to \weight_{n;(*:f,0)}^{(y,1)}$ is almost surely finite and continuous.
\end{enumerate}
\end{lemma}
\noindent{\bf Proof. (1):}
By~(\ref{e.weightm}), it is enough to prove, for each $i,j \in \N$, $i \leq j$, that $M^1_{(x,i) \to (y,j)}$ is a continuous function of $(x,y) \in \R_\leq^2$.
Let $x_1$ and $x_2$ satisfy $x_1 \leq x_2 \leq y$.  It is a simple matter to verify that 
$$
 B(i,x_2) - B(i,x_1) \leq  M^1_{(x_1,i) \to (y,j)} -   M^1_{(x_2,i) \to (y,j)} \leq \sup_{k \in \llbracket i,j \rrbracket}     M^1_{(x_1,i) \to (x_2,k)} \, ; 
$$
%the latter quantity may then be bounded above by noting that
$$
\textrm{and} \, \, \, \, \, \, \, \, \,  \sup_{k \in \llbracket i,j \rrbracket}     M^1_{(x_1,i) \to (x_2,k)} \leq \sum_{k=i}^j \Big(  \sup_{z \in [x_1,x_2]} B(k,z)  \, - \,   \inf_{z \in [x_1,x_2]} B(k,z)  \Big) \, .
$$
Continuity of $M^1_{(x,i) \to (y,j)}$ in the $x$-variable thus follows from continuity of the two-sided Brownian motions $B(k,\cdot)$.
This continuity in the $y$-variable follows similarly.
%, and these two continuities demonstrate the sought joint continuity of the energy maximum. 

\noindent{\bf (2):} The weight $\weight_{n;(x,t_1)}^{(z,t)} + \weight_{n;(z,t)}^{(y,t_3)}$ of the concatenation of  two polymers $\rho_{n;(x,t_1)}^{(z,t)}$ and $\rho_{n;(z,t)}^{(y,t_3)}$
%, whose endpoints are dictated by our convention, 
   offers a lower bound on  $\weight_{n;(x,t_1)}^{(y,t_2)}$. 


\noindent{\bf (3):} In the proof of~\cite[Lemma~$4.6(2)$]{Patch}, which appears in~\cite[Appendix~$A$]{Patch}, it is noted that   $\mathsf{W}_{n;(*:f,0)}^{(y,1)}$ equals
$$
  2^{-1/2} n^{-1/3}  \sup_{u \in (-\infty,n + 2 n^{2/3}y]} \Big(    M^1_{(u , 0) \to (n+2 n^{2/3}y,n)} - n -   2 n^{2/3}y + u    +  h(u) \Big)    \, .
$$
Here,  %$v= 2 n^{2/3}y$,  
$h:\R \to \R \cup \{ - \infty \}$ is given by
$h(x) = 2^{1/2} n^{1/3}  f\big(n^{-2/3}x/2 \big)$.
Using a notation for unscaled line-to-point energy, namely
 $$
  M^1_{(*:g,0) \to (y,n)}  : = \sup \Big\{ E(\phi) + g(x): \phi \in  \upright^1_{(x,0) \to (y,n)} \, , \, x \leq y \Big\} \, ,
$$
the quantity  $\mathsf{W}_{n;(*:f,0)}^{(y,1)}$ is seen to equal $2^{-1/2} n^{-1/3}  M^1_{(*:g,0) \to (n+2 n^{2/3}y,n)}$ where the function $g$ is given by
 $g(u) =  - n -   2 n^{2/3}y + u    +  h(u)$. 
It is further noted in the same proof  that  $\limsup_{u \to -\infty} g(u)/\vert u \vert < 0$
is satisfied when $n > 2^{-3/2} \coninit_1^3$; and that, since $f \in \initcond_{\ovbar\coninit}$, the condition that $g(u) > -\infty$ for some $u \leq n+2n^{2/3}y$ (where $y \in [-1,1]$ is given) is verified when
$n \geq 8(\coninit_2  - y)^3$. We may thus apply~\cite[Lemma~$A.2$]{Patch} to learn that $\mathsf{W}_{n;(*:f,0)}^{(y,1)}$ almost surely assumes finite real values whenever $y \in [-1,1]$
under our present hypotheses. Regarding the continuity of this function of $y \in [-1,1]$, note first that, for $n$ given satisfying these hypotheses, the location of the maximizer  `$*:f$' is tight as $f$ varies over $\initcond_{\ovbar\coninit}$: this is a consequence of the square-root growth of $M^1_{(x,0) \to (y,n)}$ in the variable $y -x$, which is explained in and after equation~(28) of~\cite{Patch},
 which growth cannot compete with the linear decrease in the function~$g$.
The question of the continuity of $y \to \mathsf{W}_{n;(*:f,0)}^{(y,1)}$
has in essence  been reduced to the first part of the present lemma; we omit the details of this reduction.
\qed
\section{Line ensembles, their Brownian Gibbs property, and a key two-point estimate}\label{s.lineensembles}
In four subsections: we discuss the embedding of the narrow wedge polymer weight profile in a certain line ensemble; explain the Brownian Gibbs property enjoyed by a normalized version of that line ensemble, and an associated notion of {\em regular} ensemble; 
we gather the needed inputs from elsewhere, which assert  that the narrow wedge profile is embedded in a regular ensemble (Proposition~\ref{p.scaledreg}), 
and certain useful properties of regular ensembles  (Proposition~\ref{p.mega} and Lemma~\ref{l.pardom});  and we give the short, Brownian Gibbs, proof of the vital two-point estimate, Proposition~\ref{p.locreg}.
\subsection{Polymer weight profiles as the uppermost curves in line ensembles}\label{s.polymerweight}
Let $(n,t_1,t_2) \in \N \times \R^2_\leq$ be a compatible triple and let $x \in \R$.
Define the  forward polymer weight profile 
$$
\mc{L}_{n;(x,t_1)}^{\uparrow;t_2} (1,\cdot) :  \big[ x - 2^{-1} n^{1/3} \tot  ,\infty\big) \to \R
$$
 with base-point $(x,t_1)$ and end height $t_2$ by setting 
 $\mc{L}_{n;(x,t_1)}^{\uparrow;t_2}(1,y) = \weight_{n;(x,t_1)}^{(y,t_2)}$ for $y \geq x - 2^{-1} n^{1/3} \tot$. We call this weight profile `forward', and adorn the notation with the symbol $\uparrow$, to reflect that it is the spatial location~$y$
 associated to the more advanced time $t_2$ that is treated as the variable: we stand at $(x,t_1)$ and look forward in time to witness the weight profile as a function of $(\cdot,t_2)$.

Retaining the triple  $(n,t_1,t_2) \in \N \times \R^2_\leq$  but now fixing  $y \in \R$ (and treating $x \in \R$ as a variable),
we also introduce the {\em backward} polymer weight profile
$$
\mc{L}_{n;t_1}^{\downarrow;(y,t_2)}(1,\cdot)  :  \big( - \infty ,  y + 2^{-1} n^{1/3} \tot \big] \to \R
$$
 with base-point $(y,t_2)$ and end height $t_1$
by setting 
$\mc{L}_{n;t_1}^{\downarrow;(x,t_2)}(1,x) =  \weight_{n;(x,t_1)}^{(y,t_2)}$ for each $x \leq y +  2^{-1} n^{1/3} \tot$.
In other words, we now stand at $(y,t_2)$ and 
 look backwards in time at those polymers,  ending at our location, which begin at time (and height) $t_1$;  
 it is the weight profile of these polymers that is being recorded.


This new and elaborate looking notation may seem  merely to describe the already denoted weight profile  $\weight_{n;(x,t_1)}^{(y,t_2)}$, viewed as a function either of $x$ or $y$.
Its conceptual significance is suggested by our calling the argument of either profile `$(1,\cdot)$' rather than simply `$(\cdot)$'.
Indeed,  we will view~$\mc{L}_{n;(x,t_1)}^{\uparrow;t_2}$ as an ensemble of $n \tot + 1$ curves of which the lowest indexed curve, just defined, is the uppermost; and the backward object is just the same.
Either ensemble collectively has the Brownian Gibbs property, a fundamental tool for the analysis of the weight profile that is its uppermost curve. 

It is useful to retain a vivid picture of both of the processes $\mc{L}_{n;(x,t_1)}^{\uparrow;t_2} (1,\cdot)$ and $\mc{L}_{n;t_1}^{\downarrow;(x,t_2)}(1,\cdot)$
  as random curves that locally resemble Brownian motion but that globally follow the shape of a parabola.
 The parabola in question is  $- 2^{-1/2} (y-x)^2 \tot^{-4/3}$. The forward process adopts values of order $\tot^{1/3}$ for argument values $y$ that differ from $x$ by order $\tot^{2/3}$, and is forced downwards rapidly by parabolic curvature outside this region. When $\tot$ is small, for example, the weight profile is sharply peaked, and it broadens out as $\tot$ rises.   
(This description neglects the role of the index $n$, but roughly it develops accuracy as $n$ rises.) 
%We will discuss this matter a little further soon.)   

It is valuable to bring the forward and backward weight profiles for differing values of $\tot$ on to the same footing, by using a parabolic change of coordinates that, for example, flattens out the sharp peak witnessed when $\tot$ is small. The coordinate change will also bring the peak centre to the origin (from $x$ or $y$, according to the forward or backward case). The above weight profiles are already scaled objects, and so we introduce the term {\em normalized} to refer to the profiles viewed after this new, $\tot$-determined, change of coordinates.

Indeed, we  define the normalized forward polymer weight profile   
$$
 \scaledle_{n;(x,t_1)}^{\uparrow;t_2}(1,\cdot) :  \big[-  2^{-1} (n \tot)^{1/3}  , \infty \big) \to \R \, ,
$$
%with base $(x,t_2)$ and duration $t_2 - t_1 > 0$.
by setting 
$$
\scaledle_{n;(x,t_1)}^{\uparrow;t_2}\big( 1, z \big)
 = \tot^{-1/3} \mc{L}_{n;(x,t_1)}^{\uparrow;t_2}\big(  x + \tot
^{2/3} z \big) \, .
$$
Its backwards counterpart 
$\scaledle_{n;t_1}^{\downarrow;(y,t_2)}(1,\cdot)  :  \big( - \infty ,  2^{-1} (n \tot)^{1/3}  \big] \to \R$
is obtained by setting $\scaledle_{n;t_1}^{\downarrow;(y,t_2)}(1,z)$ equal to  $\tot^{-1/3} 
\mc{L}_{n;t_1}^{\downarrow;(y,t_2)}(1,   y + \tot
^{2/3} z \big)$.  



%Its backwards counterpart 
%$$
%\scaledle_{n;t_1}^{\downarrow;(y,t_2)}(1,\cdot)  :  \big( - \infty ,  2^{-1} (n \tot)^{1/3}  \big] \to \R
%$$
%is obtained by setting $\scaledle_{n;t_1}^{\downarrow;(y,t_2)}(1,z) =  \tot^{-1/3} 
%\mc{L}_{n;t_1}^{\downarrow;(y,t_2)}(1,   y + \tot
%^{2/3} z \big)$.  

Brownian motion is invariant under the parabolic change of coordinates, while the parabola  $x \to - 2^{-1/2} (y-x)^2 \tot^{-4/3}$ maps to $x \to -2^{1/2}x^2$.
Thus, our normalized processes should be pictured as locally Brownian as before, but with curvature dictated by the curve $-2^{-1/2} x^2$.
This picture in fact expands its domain of validity as the index increases, encompassing an expanding region about the origin, where the relevant indexing variable is now $n \tot$, rather than $n$. 
These heuristic comments find rigorously expressed counterparts in the next section.




\subsection{Brownian Gibbs ensembles and a regularity property}\label{s.bg}

Our weight profiles 
$\mc{L}_{n;(x,t_1)}^{\uparrow;t_2} (1,\cdot)$, 
 $\scaledle_{n;(x,t_1)}^{\uparrow;t_2}(1,\cdot)$, and their backward counterparts, may be embedded as uppermost curves in systems (or `ensembles') of random curves.
 (In  \cite[Figure~$4$]{NonIntPoly}, such a scaled and a normalized forward ensemble are illustrated.) 
  The normalized forward and backward ensembles satisfy the Brownian Gibbs property; moreover, these objects adhere well enough to the informal description of being locally Brownian and globally parabolic that we describe them as {\em regular} ensembles. 
 
In the next paragraphs: 
\begin{itemize}
\item we offer in outline the definition of the curves, indexed by higher values $k > 1$, in ensembles such as 
$\mc{L}_{n;(x,t_1)}^{\uparrow;t_2} (k,\cdot)$ and
 $\scaledle_{n;(x,t_1)}^{\uparrow;t_2}(k,\cdot)$ (our treatment is informal because only the uppermost ensemble curves, indexed by $k=1$, concern us in this article);
 \item we explain the implication for the uppermost curve of an ensemble being Brownian Gibbs;
\item and we specify in Definition~\ref{d.regularsequence} what it means for a Brownian Gibbs ensemble to be regular. 
%\item in Proposition~\ref{p.scaledreg}, we cite the result that shows that our normalized ensembles are regular;
%\item and in Proposition~\ref{p.mega}, we cite three further properties, needed for our proofs, that regular ensembles enjoy. 
\end{itemize} 
%Logically, it is not necessary to answer these questions here. In the first case, this is  because in this article we only use results concerning regular ensembles that concern their lowest indexed curve.
%In the second, it is because Definition~\ref{d.regularsequence}
%and Proposition~\ref{p.mega} provide all the information we will use about regular ensembles. However, it may be useful for the reader to have a sense in overview of these important ideas. Before turning to a precise discussion of what is really needed, we thus offer informal answers to the above two questions. 
 
\subsubsection{Embedding weight profiles into ensembles as the uppermost curve.}\label{s.embedding}  For $(i,j) \in \N^2_\leq$ and $(x,y) \in \R^2_\leq$, recall that $M^1_{(x,i) \to (y,j)}$ is the energy maximum over staircases from $(x,i)$ to $(y,j)$. It has a counterpart $M^k_{(x,i) \to (y,j)}$, the maximum collective energy of a $k$-tuple of staircases with these endpoints satisfying a natural disjointness condition. The scaling relation~(\ref{e.weightm}) is extended to define the weight associated to the maximizing $k$-tuple after scaling.
This weight is then defined to equal the sum (over $i$) of the $k$ lowest indexed ensemble curves  $\mc{L}_{n;(x,t_1)}^{\uparrow;t_2} (i,\cdot)$ evaluated at $\cdot = y$.
 
We attempt a heuristic explanation of the upcoming appearance of the Brownian Gibbs property. The ensemble $\intint{n + 1} \times [0,\infty) \to \R: (k,y) \to  M^k_{(0,0) \to (y,n)} - M^{k-1}_{(0,0) \to (y,n)}$  (where $M^0 = 0$ is taken) is a microscopic counterpart to the scaled system  
$\intint{n+1} \times [0,\infty) \to \R: (k,y) \to  \mc{L}_{n;(0,0)}^{\uparrow;1}(k,y)$, because it is
%, up to a translation in $y$, equal to 
the inverse image under the scaling map $R_n$ of the latter ensemble. 
In~\cite{O'ConnellYor}, this microscopic counterpart was identified in law as Dyson's Brownian motion with $n+1$ particles: a system of $n+1$ one-dimensional Brownian motions, all begun at the origin at time zero, and conditioned on mutual avoidance at all positive times. The linear scaling map $R_n$ preserves the diffusion rate of locally Brownian processes, so that the scaled ensemble $\mc{L}_{n;(0,0)}^{\uparrow;1}$ maintains the basic character of Dyson's Brownian motion: it is an ordered system of standard Brownian motions, conditioned on mutual avoidance, with boundary conditions that ensure that the first few uppermost curves are at unit distance, with the system's curves  globally following the parabola $-2^{-1/2} x^2$.



% which is the inverse image under scaling of 

\subsubsection{Line ensembles and their Brownian Gibbs property.}  
Let $n \in \N$ and 
let $I \subseteq \R$ be closed.
A $\intint{n}$-indexed line ensemble defined on $I$ is a random collection of continuous curves  $\mc{L}:\intint{n} \times I \to \R$ specified under a probability measure $\PP$. The $i\textsuperscript{th}$ curve is thus $\mc{L}(i,\cdot): I \to \R$. (The adjective `line' has been applied to these systems perhaps because of their origin in such models as Poissonian LPP, where the counterpart object has piecewise constant curves. We will omit it henceforth.)
An ensemble is called {\em ordered} if $\mc{L}(i,x) > \mc{L}(i+1,x)$ whenever $i \in \intint{n-1}$ and $x$ lies in the interior of $I$.
The curves may thus assume a common value at any finite endpoint of $I$.
We will consider ordered ensembles that satisfy a key  condition called the Brownian Gibbs property.
We specify this property only in the special case that we need, in regard to the uppermost curve $\mc{L}(1,\cdot)$.  


For $a,b \in \R$, $a < b$, and $y,z \in \R$,
let $\mc{B}^{[a,b]}_{y,z}$ denote the law of Brownian bridge $B:[a,b] \to \R$ with $B(a) = y$ and $B(b) =z$, given by conditioning standard Brownian motion to have these endpoints.

For any $[a,b] \subseteq I$, and $y,z \in \R$, 
consider
%let $\chi(\mc{L},[a,b],x,y,g)$ denote 
the conditional distribution of the marginal  process $\mc{L}(1,\cdot):[a,b] \to \R$ given that $\mc{L}(1,a) = x$ and $\mc{L}_N(1,b) =y$ and further given the form $g:[a,b] \to \R$ of $\mc{L}_N(2,\cdot)$ on $[a,b]$. 
The Brownian Gibbs property of $\mc{L}$ asserts that
this law
%$\chi(\mc{L},[a,b],x,y,g)$ 
equals Brownian bridge $B$ under $\mc{B}^{[a,b]}_{y,z}$ conditioned by $B(u) > g(u)$ for all $u \in [a,b]$.



%[[[ Colloquially, we may say that an ordered ensemble is called Brownian Gibbs if it arises from a system of Brownian bridges or Brownian motions defined on $I$ by conditioning on the mutual avoidance of the curves at all times in $I$. ]]]
 

 
 
\subsubsection{Defining $(c,C)$-regular ensembles} 
The next definition specifies a  $(\bar\phi,\rsc,\rsC)$-regular ensemble from~\cite[Definition~$2.4$]{BrownianReg},
%d.regularsequence  
in the special case where the vector $\bar\phi$  equals  $(1/3,1/9,1/3)$.




\begin{definition}\label{d.regularsequence} 
%Let $n \in \N$ and $\xnmac \in [0,\infty)$. 
%
Consider a Brownian Gibbs ensemble of  the form 
$$
\mc{L}: \intint{\nmac} \times \big[ - \xnmac , \infty \big) \to \R  \,  ,
$$
defined on a probability space under the law~$\PP$.
The number $\nmac = \nmac(\mathcal{L})$ of ensemble curves and the absolute value $\xnmac$ of the finite endpoint may take any values in $\N$ and $[0,\infty)$.
 
Let $\rsC$ and $\rsc$ be two positive constants. The ensemble $\mc{L}$
is said to be $(\rsc,\rsC)$-regular if the following conditions are satisfied.
\begin{enumerate}
\item {\bf Endpoint escape.} $\xnmac \geq  \rsc N^{1/3}$.
\item {\bf One-point lower tail.} If $z \in [ -\xnmac, \infty)$ satisfies $\vert z \vert \leq \rsc \nmac^{1/9}$, then
$$
\PP \Big( \mc{L} \big( 1,z\big) + 2^{-1/2}  z^2 \leq - s \Big) \leq \rsC \exp \big\{ - \rsc s^{3/2} \big\}
$$
for all $s \in \big[1, \nmac^{1/3} \big]$.
\item {\bf One-point upper tail.}  If $z \in [ -\xnmac, \infty)$ satisfies $\vert z \vert \leq \rsc \nmac^{1/9}$, then
$$
\PP \Big( \mc{L} \big( 1,z\big) +  2^{-1/2} z^2 \geq  s \Big) \leq \rsC \exp \big\{ - \rsc s^{3/2} \big\}
$$
for all $s \in [1, \infty)$.
\end{enumerate}
A Brownian Gibbs ensemble of the form 
$$
\mc{L}: \intint{\nmac} \times \big( -\infty , \xnmac  \big] \to \R
$$
is also said to be $(\rsc,\rsC)$-regular if the reflected ensemble $\mc{L}( \cdot, - \cdot)$ is. This is equivalent to the above conditions when instances of $[ - \xnmac, \infty)$
are replaced by $(-\infty, \xnmac]$.
\end{definition}

We will refer to these three regular ensemble conditions as $\rmreg(1)$,  $\rmreg(2)$ and $\rmreg(3)$. 


\subsection{Inputs concerning regular ensembles}

\subsubsection{The normalized forward and backward ensembles are $(c,C)$-regular}\label{s.regular}


In Subsection~\ref{s.embedding}, we informally described how $\mc{L}_{n;(0,0)}^{\uparrow;1}$
is a globally parabolic object whose curves are mutually avoiding Brownian motions with a boundary condition suitable to ensuring that for example $\mc{L}_n(1,0)$ and $\mc{L}_n(1,0) - \mc{L}_n(2,0)$
are random but unit-order quantities. We capture this notion by asserting that this ensemble is {\em regular}. When the time-pair $(t_1,t_2) \in \R_\leq^2$  (as well as $x \in \R$) is general, it is the normalized ensemble  $\scaledle_{n;(x,t_1)}^{\uparrow;t_2}$ which is regular. 
Our assertion to this effect is~\cite[Proposition~$4.2$]{NonIntPoly}.  
%p.scaledreg
\begin{proposition}\label{p.scaledreg}
Let $(n,t_1,t_2) \in \N \times \R^2_<$ be a compatible triple, and let $x \in \R$. 
The normalized forward weight profile   $\scaledle_{n;(x,t_1)}^{\uparrow;t_2}(1,\cdot)$, defined on  $\big[- 2^{-1} (n \tot)^{1/3}  , \infty \big)$, may be represented as the lowest indexed curve in an ensemble 
$$
 \scaledle_{n;(x,t_1)}^{\uparrow;t_2}: \intint{n \tot + 1} \times \big[- 2^{-1} (n \tot)^{1/3}  , \infty \big) \to \R 
$$
that enjoys the  Brownian Gibbs property.
Denoting this ensemble by $\mc{L}$, we naturally have  $\nmac(\mc{L}) = n \tot  + 1$ and $\xnmac = 2^{-1} (n \tot)^{1/3}$.
 
 
 There exist positive constants $\rsC$ and $\rsc$, which may be chosen independently of all such choices of the parameters $t_1$, $t_2$, $x$ and $n$,
such that the ensemble~$\mc{L}$ is $(\rsc,\rsC)$-regular. 

Similarly, the backward weight profile 
$\scaledle_{n;t_1}^{\downarrow;(y,t_2)}(1,\cdot)  :  \big( - \infty ,  2^{-1} (n \tot)^{1/3}  \big] \to \R$ may be embedded in an ensemble
$$
\scaledle_{n;t_1}^{\downarrow;(y,t_2)}(1,\cdot)  : \intint{n \tot + 1} \times  \big( - \infty ,   2^{-1} (n \tot)^{1/3}  \big] \to \R \, .
$$
This new ensemble also enjoys the properties just described for its forward counterpart, uniformly in the concerned parameters.
\end{proposition}


Hypothesis bounds in most of our results have been  
stated explicitly up to the appearance of 
two positive constants $c$ and $C$. The value is this pair is  fixed  by Proposition~\ref{p.scaledreg}.
Since bounding the constants would render hypotheses to be explicit, we mention that they are determined in~\cite[Appendix~$A.1$]{BrownianReg}
via Ledoux~\cite[(5.16)]{Ledoux} and Aubrun's~\cite[Proposition~$1$]{Aubrun} bounds on the lower and upper tail of the maximum eigenvalue of a matrix in the Gaussian unitary ensemble. In applications, we will harmessly suppose that $C \geq 1$ and $c \leq 1/2$.



\subsubsection{Basic properties of $(c,C)$-regular ensembles}\label{s.nontrivial}

%Let $\para:\R \to \R$ denote the parabola $\para(x) = 2^{-1/2} x^2$.


%Set $C_1 =140C$ and 
Recall from Subsection~\ref{s.pwc} that $c_1 = 2^{-5/2}c \wedge \tfrac{1}{8}$. 


\begin{proposition}\label{p.mega}
Suppose that  $\mc{L} = \mc{L}_N$, mapping either $\intint{N} \times [-\xnmac,\infty)$ or  $\intint{N} \times (-\infty,\xnmac]$, to $\R$,
is a $(\rsc,\rsC)$-regular ensemble, where $N \in \N$ and $\xnmac \geq 0$.
\begin{enumerate}
\item (Uniform curve lower bound) 
 Whenever   $(t,r,y) \in \R$ satisfy $N \geq (c/3)^{-18} \vee  6^{36}$, 
  $t \in \big[ 0 ,N^{1/18} \big]$, $r \in \big[ 2^{3/2} \, , \, 2N^{1/18} \big]$
  and $\vert y \vert \leq 2^{-1} \rsc N^{1/18}$,
$$
\PP \Big( \inf_{x \in [y-t,y+t]} \big( \mc{L}_N(1,x) + 2^{-1/2} x^2 \big) \leq - r \Big) \, \leq \, \Big( t \vee   (3 - 2^{3/2})^{-1} 5^{1/2}   \Big) \cdot 10 C \exp \big\{ - c_1 r^{3/2} \big\} \, .
$$
\item (No Big Max) 
For  $\vert y \vert \leq 2^{-1} c  N^{1/9}$, $r \in \big[0,4^{-1} \rsc  N^{1/9}\big]$, $t \in \big[ 2^{7/2} , 2 N^{1/3} \big]$ and $N \geq c^{-18}$,
$$
\PP \Big( \sup_{x \in [y-r,y+r]} \big( \mc{L}_N ( 1,x ) + 2^{-1/2}x^2 \big) \geq t \Big) \leq  (r + 1) \cdot  6  \rsC \exp \big\{ - 2^{-11/2} \rsc  t^{3/2} \big\} \, . 
$$
\item (Collapse near infinity) 
For $\eta \in (0,\rsc]$, let
$\ell = \ell_\eta:\R \to \R$ denote the even function which is affine on $[0,\infty)$ and has gradient $ - 5 \cdot 2^{-3/2} \eta \nmac^{1/9}$ on this interval, and which satisfies
$\ell(\eta \nmac^{1/9}) = \big( - 2^{-1/2} + 2^{-5/2} \big) \eta^2 \nmac^{2/9}$. If  $\nmac \geq 2^{45/4} \rsc^{-9}$, then  
\begin{eqnarray*}
 & & \PP \Big( \mc{L}_N \big(1,z\big) > \ell(z) \, \, \textrm{for some} \, \,  z \in  D \setminus \big[ - \eta  \nmac^{1/9} , \eta \nmac^{1/9} \big] \Big) \\
  & \leq &  
6C \exp \Big\{ - c \eta^3  2^{-15/4}   \nmac^{1/3} \Big\} \, .
\end{eqnarray*}
The set $D$ is the spatial domain of $\mc{L}$, either $[ - \xnmac , \infty )$  or  $(-\infty,\xnmac]$.  
\end{enumerate}
\end{proposition}

These three assertions are proved in~\cite{BrownianReg}. Respectively, they appear as, or are special cases of, the following results in that article:
Proposition~$A.2$,
%p.strongothercurves
Proposition~$2.28$,
%p.nobigmax.gen
%Proposition~$2.16$
%%p.aestimateinference
and
Proposition~$2.30$.
%p.collapsenearinfinity


A few words about the assertions' meaning. 
The first is a bound on the  lower tail of  the minimum value of  the lowest indexed curve on a compact interval.
The result is a strengthening of the defining property $\rmreg(2)$, which treats the one-point case. 
%(In fact, this first part may also apply to a curve of any given index, but we have no use for information concerning these other curves in the present article.)   
The second is a  similar strengthening of the one-point upper tail $\rmreg(3)$. In regard to the third, note that $\rmreg(2)$ and $\rmreg(3)$ do not assert that the lowest indexed curve hews to the parabola $-2^{-1/2}z^2$
globally, but only in an expanding region about the origin, of width $2cN^{1/9}$ centred at the origin, where $N$ is the ensemble curve cardinality. Proposition~\ref{p.mega}(3) offers a substitute control on curves far from the origin, showing them to decay at a rapid but nonetheless linear rate in the region beyond scale $N^{1/9}$.
  
Two further basic properties of regular ensembles are needed. One concerns a {\em parabolic symmetry} for whose explanation a little notation is helpful. 
Write $\para:\R \to \R$ for the parabola $\para(u) = 2^{-1/2} u^2$, and
let $l:\R^2 \to \R$ be given by $l(u,v) = - 2^{-1/2}v^2 - 2^{1/2}v(u-v)$. Note that $u \to l(u,v)$
is the tangent line of the parabola $u \to - \para(u)$ at the point $\big(v,-\para(v)\big)$. Note also that, for any $u,v \in \R$,
\begin{equation}\label{e.plp}
\para(u) = - l(u,v) + \para(u-v) \, .
\end{equation}

For $\xnmac \geq 0$, consider a $(c,C)$-regular ensemble $\mc{L}_N:\intint{N} \times [-\xnmac,\infty) \to \R$. 
For any $y_N > - \xnmac$, define $\lshift_{N,y_N}:\intint{N} \times [-\xnmac - y_N,\infty) \to \R$ to be the shifted ensemble given by 
$$
\lshift_{N,y_N}(i,u) = \mc{L}_{N}(i,u + y_N) - l(u+y_N,y_N)  \, .
$$



\begin{lemma}\label{l.pardom}
Let  $\rsc, \rsC > 0$ and $N \in \N$.
Suppose that  $\mc{L}_N:\intint{N} \times [-\xnmac,\infty) \to \R$
is  a    $\big(\rsc,\rsC\big)$-regular ensemble.
\begin{enumerate}
\item Whenever $y_N  \in \R$
satisfies $\vert y_N \vert \leq \rsc/2 \cdot N^{1/9}$, the ensemble $\lshift_{N,y_N}$ is    $\big(\rsc/2,\rsC\big)$-regular.
\item 
For any $[a,b] \subseteq [-\xnmac,\infty)$, and $y,z \in \R$,
the conditional distribution of the marginal process $\mc{L}_N(1,\cdot):[a,b] \to \R$ given that $\mc{L}_N(1,a) = y$ and $\mc{L}_N(1,b) =z$ stochastically dominates the Brownian bridge law  $\mc{B}^{[a,b]}_{y,z}$. 
\end{enumerate}
\end{lemma} 
\noindent{\bf Proof (1).} This \cite[Lemma~$2.26$]{BrownianReg}.

\noindent{\bf Proof (2).}
By the Brownian Gibbs property of $\mc{L}_N$,
the conditional distribution of the marginal  process $\mc{L}_N(1,\cdot):[a,b] \to \R$ given that $\mc{L}_N(1,a) = x$ and $\mc{L}_N(1,b) =y$ and further given the form $g:[a,b] \to \R$ of $\mc{L}_N(2,\cdot)$ on $[a,b]$ equals Brownian bridge $B$ under $\mc{B}^{[a,b]}_{y,z}$ conditioned by $B(u) > g(u)$ for all $u \in [a,b]$. A stochastic monotonicity result~\cite[Lemma 2.6]{AiryLE} implies that this conditional distribution stochastically dominates the law specified by $g \equiv - \infty$. The latter law is~$\mc{B}^{[a,b]}_{y,z}$.  \qed



%Recalling Subsection~[[]], the law 
%$\chi(\mc{L}_N,[a,b],x,y,g)$ equals Brownian bridge $B$ under $\mc{B}^{[a,b]}_{y,z}$ conditioned by $B(u) > g(u)$ for all $u \in [a,b]$. A stochastic monotonicity result~\cite[Lemma 2.6]{AiryLE} implies that this conditional distribution stochastically dominates the law specified by $g \equiv - \infty$. The latter law is~$\mc{B}^{[a,b]}_{y,z}$.  \qed

%\begin{proposition}\label{p.collapsenearinfinity}
%Let the sequence of Brownian Gibbs line ensembles $\mc{L}_n: \intint{n} \times \big[ - \xnmac , \infty \big) \to \R$ under the law~$\PP$ be  $\bar\phimac$-regular 
%with constant parameters $(\rsc,\rsC) \in (0,\infty)^2$. Then condition $\rmreg(4)$ holds. 
%\end{proposition}


\subsection{Two-point estimate for the uppermost curve in a regular ensemble}


Here is the critical input for the proof of  Theorem~\ref{t.differenceweight}.

 

\begin{proposition}\label{p.locreg}
Suppose that  $\mc{L} = \mc{L}_N$, mapping either $\intint{N} \times [-\xnmac,\infty)$ or  $\intint{N} \times (-\infty,\xnmac]$, to $\R$,
is a $(\rsc,\rsC)$-regular ensemble, where $N \in \N$ and $\xnmac \geq 0$.
%For  $[x,x+\delta]$ a subset of $A = [-\xnmac,\infty)$, or of $A =  (-\infty,\xnmac]$, and for $f: A \to \R$, define  
%$$
%\omega_{[x,x+\delta]}\big( f , \delta \big) \, = \,  \sup \Big\{ \big\vert f(x+s) - f(x) \big\vert :  s \in  [0,\delta] \Big\} \, .
%$$
For $x \geq -\xnmac + 2$ and $t > 0$, define 
$$
\boundgood_t(x) = \bigcap_{x-2 \leq y \leq x+2} \Big\{ -t \leq  \mc{L}_N(1,y) + 2^{-1/2} y^2 \leq t  \, \Big\} \, .
$$
If $\vert x \vert \leq  2^{-1 }\rsc  N^{1/9}$, $\e \in (0,1]$, $K \geq 9$ and  
$N \geq 6^3 c^{-3}$, then
$$
 \PP \, \bigg( \, \Big\vert \mc{L}_N(1,x+\e) + 2^{-1/2} (x+\e)^2 - \mc{L}_N(1,x) + 2^{-1/2} x^2 \Big\vert \, \geq \,  K\e^{1/2} \, , \, \boundgood_{K/4}(x) \, \bigg) 
 $$
 is at most $2^{3/2} \pi^{-1/2} K^{-1} \exp \big\{ - 2^{-3} K^2 \big\}$.
\end{proposition}
 Theorem~\ref{t.differenceweight} (and Theorem~\ref{t.wlp.one}), 
 and Proposition~\ref{p.locreg} applied via Proposition~\ref{p.scaledreg},  all give expression to the one-half power law that governs polymer weight: when the endpoints of polymers are varied by short horizontal displacements of order~$\e$, the change in polymer weight has an order of~$\e^{1/2}$.   Proposition~\ref{p.locreg} is notably flexible, in that the parameters for horizontal scale, $\e$, and scaled fluctuation, $K$, may be selected without imposing any dependence on the lower bound demanded on the ensemble curve cardinality~$N$. This favourable feature comes at the price that the result gauges the small probability of high two-point difference only when we impose a global boundedness event $\boundgood_{K/4}(x)$
on the ensemble $\mc{L}_N$. We will have more to say about the role of  Proposition~\ref{p.locreg}  and the implications of its strengths and its drawback early in Section~\ref{s.polyweightreg}, when 
Theorem~\ref{t.differenceweight} is proved.

\noindent{\bf Proof of Proposition~\ref{p.locreg}.}
We first argue that an application of Lemma~\ref{l.pardom}(1) reduces to the case that $x = 0$.
To see this, note that~(\ref{e.plp}) implies that  $\lshift_{N,y_N}(i,u) + \para(u)$ equals
$\mc{L}_N(i,u + y_N) + \para(u+y_N)$, whenever $y_N > - \xnmac$. Selecting $y_N$ in Lemma~\ref{l.pardom}(1) to be $x$ in Proposition~\ref{p.locreg}, the proposition's conclusion is seen to be unchanged when the adjustments $x \to 0$ and $\mc{L}_N \to \lshift_{N,x}$ are made.
%In the case of a regular ensemble~$\mc{L}_n$,  the last expression consists of the bracketed  process, for which the influence of curvature has been cancelled, at least when $x + y_n = n^{o(1)}$, to which is added the basic parabolic decay term. 
For this reason, we may, and will, consider only $x =0$. We must also work now under the assumption that $\mc{L}_N$ is $(c/2,C)$-regular. This information is used alongside the hypothesis  
$N \geq 6^3 c^{-3}$ to ensure that 
$c/2 \cdot  N^{1/3} \geq 3$, so that the interval $[-3,3]$ lies in the spatial domain $[-\xnmac,\infty)$ or $(-\infty,\xnmac]$~of~$\mc{L}_N$. 




For a stochastic process $X$ whose domain of definition includes $[0,\e]$, define the events
$$
\down_{\e,K}[X] = \Big\{  X(\e) + 2^{-1/2} \e^2  \leq X(0) - K \e^{1/2} \Big\} 
$$
and  
$$
\up_{\e,K}[X] = \Big\{ X(\e) + 2^{-1/2} \e^2  \geq X(0) + K \e^{1/2} \Big\} \, . 
$$


For brevity, we write $W:[-\xnmac,\infty) \to \R$, $W(u) = \mc{L}_N(1,u)$, so that $W$ maps $[-\xnmac,\infty)$ or $(-\infty,\xnmac]$ to $\R$; and for the same reason, we also denote $t = K/4$. 
To obtain Proposition~\ref{p.locreg} for $x=0$, it is enough to verify two bounds:
\begin{equation}\label{e.downbound}
\PP \Big(  \down_{\e,K}[W] \, , \, \boundgood_t(0) \, \Big) 
\leq 2^{1/2} \pi^{-1/2} K^{-1} \exp \big\{ - 8^{-1} K^2 \big\} 
\end{equation}
and
\begin{equation}\label{e.upbound}
\PP \Big(  \up_{\e,K}[W] \, , \, \boundgood_t(0) \, \Big) 
\leq 2^{1/2} \pi^{-1/2} K^{-1} \exp \big\{ - 8^{-1} K^2 \big\} \, .
\end{equation}
\noindent{\em Deriving~(\ref{e.downbound}).}
Note that
\begin{eqnarray*}
 & & \PP \Big(  \down_{\e,K}[W] \, , \, \boundgood_t(0) \, \Big)  \leq  
 \PP \Big( \down_{\e,K}[W]  \, , \, 
  W(0) \leq t   \, , \, W(2) + 2^{3/2} \geq - t \, \Big) \\
   & \leq & \sup \bigg\{ \, \PP \Big( \, \down_{\e,K}[W] \, \Big\vert \, W(0) = y \, , \, W(2) = z \Big) : y \leq t \, , \, z \geq - t - 2^{3/2} \bigg\} \\
    & {\bm \leq} & \sup \bigg\{ \, \mc{B}_{y,z}^{[0,2]} \Big( \, \down_{\e,K}[B] \, \Big) : y \leq t \, , \, z \geq - t - 2^{3/2} \bigg\}   
     \,  =  \, \mc{B}_{t,-t - 2^{3/2}}^{[0,2]} \Big( \, \down_{\e,K}[B]  \, \Big) \, . 
\end{eqnarray*}
The third bound (which is highlighted ${\bm \leq}$) follows from Lemma~\ref{l.pardom}(2), while the final equality is a consequence of the coupling of Brownian bridge laws via affine shift.
Brownian bridge $B:[0,2] \to \R$ subject to $B(0) = t$
and $B(2) = -t - 2^{3/2}$ may be mapped via a further affine shift to Brownian bridge $\mc{B}_{0,0}^{0,2}$ with vanishing endpoint values. We thus see that 
\begin{eqnarray}
 & & \mc{B}_{t,-t - 2^{3/2}}^{[0,2]} \Big( \, \down_{\e,K}[B]  \, \Big) \, \leq \, \mc{B}_{t,-t - 2^{3/2}}^{[0,2]} \Big( \,  B(\e)  \leq t - K \e^{1/2}  \, \Big) \nonumber \\
 & = &  \mc{B}_{0,0}^{[0,2]} \Big( \,  B(\e)  \leq  - K \e^{1/2} \, + \, \e/2 \cdot \big(2t + 2^{3/2}\big) \, \Big) 
   \leq  \mc{B}_{0,0}^{[0,2]} \Big( \,   B(\e)  \leq  - 2^{-1} K \e^{1/2} \, \Big) \, , \label{e.infquant}
\end{eqnarray}
where the bound $\e \leq (2t + 2^{3/2})^{-2} K^2$ that permits the final inequality is due to $K = 4t$, $t \geq 2^{1/2}$ (in the guise that $2t + 2^{3/2} \leq 4t$) and $\e \leq 1$. Since $B(\e)$ under $\mc{B}_{0,0}^{[0,2]}$
is normally distributed with mean zero and variance $2^{-1}\e(2-\e) \leq \e$, the right-hand side of~(\ref{e.infquant}) is at most $\nu ( x ,\infty) \leq (2\pi)^{-1/2} x^{-1} e^{-x^2/2}$ with $x=K/2$, where $\nu$ is the standard normal distribution, and the inequality~\cite[Section~$14.8$]{Williams} is classical.  We have  obtained~(\ref{e.downbound}).

%Using the free endpoint $*$ notation, we write $\mc{B}_{0,*}^{[0,2]}$ for the law of standard Brownian motion $B:[0,2] \to \R$ (with $B(0) = 0$). Note then that
%\begin{eqnarray*}
% & & \mc{B}_{0,0}^{[0,2]} \Big( \,  \inf \big\{ B(s) : 0 \leq s \leq \e \big\} \leq  - 2^{-1} K \e^{1/2} \, \Big) \\
% & \leq &    
%\mc{B}_{0,*}^{[0,2]} \Big( \,  \inf \big\{ B(s) : 0 \leq s \leq \e \big\} \leq  - 2^{-1} K \e^{1/2} \, \Big\vert \, B(2) \leq 0 \, \Big) \\
% & \leq & 2 \, 
%\mc{B}_{0,*}^{[0,2]} \Big( \,  \inf \big\{ B(s) : 0 \leq s \leq \e \big\} \leq  - 2^{-1} K \e^{1/2} \,  \Big) = 4  \, 
%\mc{B}_{0,*}^{[0,2]} \Big( \,  B(1)  \leq  - 2^{-1} K  \,  \Big)  \, ,
%\end{eqnarray*}
%the first inequality by monotonicity in the coupling of bridge laws via affine shift, and 
%the final equality by Brownian scaling and the reflection principle. Bounding the final term above using 
%a classical upper bound on the tail of the standard normal distribution~[], and combining the last three displays, we obtain~(\ref{e.downbound}).



\noindent{\em Deriving~(\ref{e.upbound}).}
In summary of the last argument, $W$ may fall no more suddenly between zero and $\e$ than does a suitable Brownian bridge that begins at time zero. But neither may it rise suddenly between this same pair of times, because such a rise is a fall when viewed from right to left, and this fall entails a fall that is at least as great on the part of a suitable Brownian bridge whose rightmost time is~$\e$. That is, the argument for~(\ref{e.upbound}) is  almost symmetrical to that for~(\ref{e.downbound}). It takes the form
\begin{eqnarray*}
 & & \PP \Big(  \up_{\e,K}[W] \, , \, \boundgood_t(0) \, \Big)  \leq  
 \PP \Big( \up_{\e,K}[W]  \, , \, 
  W(-2) + 2^{3/2} \geq - t   \, , \, W(\e) + 2^{-1/2}\e^2 \leq  t \, \Big) \\ 
   & \leq & \sup \bigg\{ \, \PP \Big( \, \up_{\e,K}[W] \, \Big\vert \, W(-2) = y \, , \, W(\e) = z \Big) : y \geq - t - 2^{3/2} \, , \, z \leq  t -  2^{-1/2}\e^2  \bigg\} \\
    & {\bm \leq} & \sup \bigg\{ \, \mc{B}_{y,z}^{[-2,\e]} \Big( \, \up_{\e,K}[B] \, \Big) : y \geq -t - 2^{3/2} \, , \, z \leq  t -  2^{-1/2}\e^2  \bigg\}   
     \,  =  \, \mc{B}_{-t - 2^{3/2},t -  2^{-1/2}\e^2 }^{[-2,\e]} \Big( \, \up_{\e,K}[B]  \, \Big) \\
 %     & = &
 %\mc{B}_{0,2t + 2^{3/2} -  2^{-1/2}\e^2 }^{[0,2 + \e]} \Big( \,  B(\e)  \geq   K \e^{1/2} - 2^{-1/2}\e^2 \, \Big)  \\
      & {\bm =}  &
 \mc{B}_{0,0}^{[0,2 + \e]} \Big( \,  B(\e) \leq  - K \e^{1/2} + 2^{-1/2}\e^2 + \tfrac{\e}{2 + \e} ( 2t + 2^{3/2} -  2^{-1/2}\e^2 ) \, \Big) \leq  \mc{B}_{0,0}^{[0,2]} \Big( \,   B(\e)  \leq  - 2^{-1} K \e^{1/2} \, \Big)  \, ,
\end{eqnarray*}
where Lemma~\ref{l.pardom}(2) again implies the third bound, which is again highlighted ${\bm \leq}$. To obtain the latter equality (which is highlighted~${\bm =}$), consider the map that sends $B:[-2,\e] \to \R$ to $W:[0,2+\e] \to \R$, where $W$ is the affine shift of $[0,2+\e] \to \R: y \to B(\e - y)$ 
for which $W(0) = W(2 + \e) = 0$, and note that this map sends the law  $\mc{B}_{-t - 2^{3/2},t -  2^{-1/2}\e^2 }^{[-2,\e]}$ to $\mc{B}_{0,0}^{[0,2 + \e]}$ and the event $\up_{\e,K}[B]$ to the event that   $W(\e) \leq - K \e^{1/2} + 2^{-1/2}\e^2 + \tfrac{\e}{2 + \e} ( 2t + 2^{3/2} -  2^{-1/2}\e^2 )$. 
It is now  $\e \leq 1 \wedge  (t + 2^{1/2} +  2^{-1/2})^{-2} 2^{-2}K^2$ that permits the final displayed  inequality,
% since $2^{-1/2} \e^2 + \tfrac{\e}{2+\e} (  2t + 2^{3/2} - \e^{3/2}) \leq  2^{-1/2} \e^2 + \tfrac{\e}{2} (  2t + 2^{3/2})$ whose right-hand side is at most $\e(t + 2^{1/2} + 2^{-1/2})$ when $\e \leq 1$
 with the assumptions that $t \geq 2^{1/2} + 2^{-1/2}$ (in the guise that $t + 2^{1/2} + 2^{-1/2}$ is at most~$2t$), $K = 4t$ and $\e \leq 1$ implying this condition. Since the last displayed quantity is the right-hand side of~(\ref{e.infquant}), the rest of the derivation of~(\ref{e.downbound}) applies, and~(\ref{e.upbound}) is obtained.

In summary,~(\ref{e.downbound}) and~(\ref{e.upbound})
imply Proposition~\ref{p.locreg} with $x=0$, to whose derivation the proof of this proposition has been reduced. \qed






\section{Collective control on polymer weights: the proof of Proposition~\ref{p.maxminweight}}


The planar line segment with endpoints $(x,0)$ and $(y,1)$
crosses the horizontal line whose  height is one-half
at the location $(x+y)/2$. We record this location in the form $z =  (x+y)/2$. 
We will prove the lower-tail bound~(\ref{e.weightuvinfimum}) by bounding the polymer weight 
 $\weight_{n;(x+u,0)}^{(y+v,1)}$ for any given $(u,v) \in [0,1]^2$ below by considering routes from $(x+u,0)$ to $(y+v,1)$ that pass via $(z,1/2)$. The two polymer weights in the lower bound
 concern journeys from $(z,1/2)$ to $(x+u,0)$ (after time reversal) and from $(z,1/2)$ to $(y+v,1)$. Rooting in this way at $(z,1/2)$, we may gauge the probability of low weight values for polymers emanating from $(z,1/2)$ and ending in a compact interval at time zero or one by applying Proposition~\ref{p.mega}(1) to the duration one-half normalized ensembles rooted at $(z,1/2)$, of forward or backward type according to whether a time one or time zero endpoint is being considered. 

Thus, we let $u,v \in [0,1]$. Note that
\begin{eqnarray*}
 & & 2^{-1/2} \big(2^{2/3}(z -x -u) \big)^2 + 2^{-1/2} \big(2^{2/3}(y+ v - z) \big)^2 \\
 %submit omit
%  & = &  2^{-1/2} \Big( 2^{2/3} \big( (y-x)/2 - u \big) \Big)^2 +    2^{-1/2} \Big( 2^{2/3} \big(  (y-x)/2 + v \big) \Big)^2 \\
  %submit omit
% & = & 2^{5/6} 2^{-1} (y-x)^2 + 2^{5/6}(y-x)(v-u) +2^{5/6} \big( u^2 + v^2 \big)  \\
  & = & 2^{-1/6}  (y+v-x - u)^2 +2^{-1/6} ( u + v  )^2 \, .
\end{eqnarray*}
Note further that
\begin{eqnarray*}
 \weight_{n;(x+u,0)}^{(y+v,1)} & \geq & \weight_{n;(x+u,0)}^{(z,1/2)} + \weight_{n;(z,1/2)}^{(y+v,1)}  
  =  \mc{L}_{n;0}^{\downarrow;(z,1/2)}(1,x+u) + 
 \mc{L}_{n;(z,1/2)}^{\uparrow;1}(1,y+v) \\
  & = & 2^{-1/3} \scaledle_{n;0}^{\downarrow;(z,1/2)}\big(1, 2^{2/3} (x+u - z) \big) + 
  2^{-1/3} \scaledle_{n;(z,1/2)}^{\uparrow;1}\big(1,  2^{2/3} (y+v -z) \big) \, .
\end{eqnarray*}
The  inequality here invokes Lemma~\ref{l.basic}(2) with ${\bf t_1} = 0$, ${\bf t_2} = 1$, ${\bf t} = 2^{-1}$, ${\bf x} = x+u$, ${\bf y} = y + v$ and ${\bf z} = z$. The two equalities invoke the definitions of the four ensembles whose top curves are being evaluated.
Regarding the inequality, we may note that the use of  Lemma~\ref{l.basic}(2) entails that certain bounds on ${\bf z}$ be satisfied. We omit reference to these bounds now because they are anyway implicated later in the argument, when we come to analyse the above two right-hand terms. Finally, note that, in order to enable our use of  Lemma~\ref{l.basic}(2) with the choice ${\bf t} = 2^{-1}$,
we have imposed in Proposition~\ref{p.maxminweight} the assumption that $n \in \N$ be even, in order that the triples $(n,0,2^{-1})$ and  $(n,2^{-1},1)$ be compatible. 


 

Adding to the above inequality the $2^{-1/3}$-rd multiple of the display that preceded it, we find that
\begin{eqnarray}
 & & \weight_{n;(x+u,0)}^{(y+v,1)} + 2^{-1/2}  (y+v-x - u)^2 + 2^{-1/2} ( u + v  )^2 \nonumber \\
  & \geq & 2^{-1/3} \Big( \scaledle_{n;0}^{\downarrow;(z,1/2)}\big(1, 2^{2/3} (x+u - z) \big) +  2^{-1/2} \big(2^{2/3}(z -x -u) \big)^2 \Big) \label{e.weightbound} \\
   & &  \quad + \,   2^{-1/3} \Big( \scaledle_{n;(z,1/2)}^{\uparrow;1}\big(1,  2^{2/3} (y+v -z) \big) + 2^{-1/2} \big(2^{2/3}(y+ v - z) \big)^2 \Big) \, . \nonumber
\end{eqnarray}


Note that
\begin{eqnarray}
 & &  \PP \bigg(  \inf_{u \in [0,1]} \Big( \scaledle_{n;0}^{\downarrow;(z,1/2)}\big(1, 2^{2/3} (x+u - z) \big) +  2^{-1/2} \big(2^{2/3}(z -x -u) \big)^2 \Big) \leq - s \bigg) \label{e.pinf} \\
 & =  &  \PP \bigg(  \inf_{u \in [0,2^{2/3}]} \Big( \scaledle_{n;0}^{\downarrow;(z,1/2)}\big(1, 2^{2/3} (x - z) + u \big) +  2^{-1/2} \big(2^{2/3}(x - z) + u \big)^2 \Big) \leq - s \bigg) \, . \nonumber
\end{eqnarray}
The latter term equals
$$
\PP \Big( \inf_{x' \in [y-t,y+t]} \big( \mc{L}_N(1,x') + 2^{-1/2}(x')^2 \big) \leq - r \Big)
$$
when $t = 2^{-1/3}$; when $t \geq 2^{-1/3}$, the new expression is an upper bound. 
Here, we take $\mc{L}_N =  \scaledle_{n;0}^{\downarrow;(z,1/2)}$, $y =  2^{2/3}(x - z) + 2^{-1/3}$ and $r = s$.



We seek then to apply 
Proposition~\ref{p.mega}(1) 
to the $(c,C)$-regular ensemble $\mc{L}_N =  \scaledle_{n;0}^{\downarrow;(z,1/2)}$, 
doing so 
%with $k=1$ and for 
with this choice of $(r,y,t)$.
It is 
Proposition~\ref{p.scaledreg}
that permits this choice of ensemble. If we set $t_1 = 0$ and $t_2 = 1/2$, so that $\tot = 1/2$, the number of curves in the ensemble   $\mc{L}_N =  \scaledle_{n;t_1}^{\downarrow;(z,t_2)}$ equals $\lfloor n \tot \rfloor + 1$ and thus is at least $n \tot$.
For the application to be valid, our parameters must thus satisfy 
\begin{equation}\label{e.tothyp}
\tot n \geq 1 
  \vee  (c/3)^{-18} \vee  6^{36} \, , \, 
   2^{-1/3} \leq (n\tot)^{1/18} \, , \, s \in \big[ 2^{3/2} \, , \, 2(n \tot)^{1/18} \big] \, ,
\end{equation}
and  $\big\vert 2^{2/3}(x - z) + 2^{-1/3} \big\vert = \big\vert 2^{2/3}(x - y)/2 + 2^{-1/3} \big\vert \leq \rsc/2 \cdot (n \tot)^{1/18}$.
 From this application of Proposition~\ref{p.mega}(1), we find that the probability in~(\ref{e.pinf}) is at most 
\begin{equation}\label{e.twoub}
  \Big( 2^{-1/3} \vee (3 - 2^{3/2})^{-1} 5^{1/2} \Big) \cdot 10 C  \exp \big\{ - c_1 s^{3/2} \big\} \, . 
\end{equation}

By applying   Proposition~\ref{p.mega}(1) to the ensemble $\mc{L}_N =  \scaledle_{n;(z,1/2)}^{\uparrow;1}$, 
with ${\bf y}$ now chosen equal to  $2^{2/3}(y - z) + 2^{-1/3}$, and with $(r,t)$ again set to be $\big(s,2^{-1/3}\big)$, we find that the quantity
$$
 \PP \bigg(  \inf_{v \in [0,1]} \Big( \scaledle_{n;(z,1/2)}^{\uparrow;1}\big(1,  2^{2/3} (y+v -z) \big) + 2^{-1/2} \big(2^{2/3}(y+ v - z) \big)^2 \Big) \leq - s \bigg) 
$$
is also bounded above by~(\ref{e.twoub}). This application of the proposition requires in addition to the bounds in~(\ref{e.tothyp}) that $\big\vert 2^{2/3}(y - z) + 2^{-1/3} \big\vert = \big\vert 2^{2/3}(y - x)/2 + 2^{-1/3} \big\vert \leq \rsc/2 \cdot (n \tot)^{1/18}$.

Since $2^{-1/2}(u + v)^2 \leq 2^{3/2}$ whenever $u,v \in [0,1]$, we find from the inequality~(\ref{e.weightbound}) and the upper bound by~(\ref{e.twoub}) on the two probabilities that
\begin{eqnarray*}
 & & \PP \bigg(  \inf_{u,v \in [0,1]} \Big( \weight_{n;(x+u,0)}^{(y+v,1)} + 2^{-1/2}  (y+v-x - u)^2 \Big) \leq - 2 \cdot 2^{-1/3}s \, - \, 2^{3/2} \bigg) \\
  & \leq & 2  \Big(  2^{-1/3} \vee (3 - 2^{3/2})^{-1} 5^{1/2} \Big)  \cdot 10 C  \exp \big\{ - c_1 s^{3/2} \big\} \, .
\end{eqnarray*}
Setting $t = 2 \cdot 2^{2/3}s$ and using $s \geq 2^{5/6}$ (so that $t \geq 2^{2/3}s + 2^{3/2}$), 
and noting  $20  \Big( 2^{-1/3} \vee  5^{1/2} (3 - 2^{3/2})^{-1}    \Big) \leq 261$, 
% 5^{1/2} (3 - 2^{3/2})^{-1}  = 13.033
we obtain~(\ref{e.weightuvinfimum}).

Let $\high_{n;([x,x+1],0)}^{([y,y+1],1)}(t)$ denote the event that  $\sup_{u,v \in [0,1]} \Big( \weight_{n;(x+u,0)}^{(y+v,1)} + 2^{-1/2} ( y+v - x - u )^2 \Big) \geq t$.
Clearly it is this event whose probability we must bound above as we turn to derive~(\ref{e.weightuvsupremum}). The event entails the presence of a high weight polymer that crosses a square, but both of its endpoints may have exceptional locations. The derivation of~(\ref{e.weightuvsupremum}) will proceed by noting that, typically, one of the endpoints can be made typical. Indeed, when the $\high$ event occurs,
so that a high weight polymer runs between say $(x+U,0)$ and $(y+V,1)$, where the pair $(U,V) \in [0,1]^2$ is random, a fairly high weight polymer will also typically exist between the deterministic location $(2x-y,-1)$
and $(y+V,1)$. This is because a rather high lower bound on the weight of such a polymer is obtained by considering the pair of polymers, from $(2x-y,-1)$ to $(x+U,0)$, and from $(x+U,0)$ to $(y+V,1)$, whose weights are typically not too low, and high. The probability of the presence of this fairly high weight polymer may then be gauged by the No Big Max Proposition~\ref{p.mega}(2), because this event entails that the duration-two normalized forward ensemble rooted at $(2x-y,-1)$ assumes a high value within a compact interval.

To begin implementing this approach, we consider the event
$\high_{n;([x,x+1],0)}^{([y,y+1],1)}(t)$, and let $(U,V) \in [0,1]^2$ be the lexicographically minimal pair of $(u,v) \in [0,1]^2$  that realize this event (a definition which makes sense because, by Lemma~\ref{l.basic}(1), the set of such pairs is closed).

Now {\em reset} the value of $z$ to be $2x -y$, so that 
the planar line segment interpolating $(z,-1)$ and $(y,1)$ passes through $(x,0)$.
Note that
\begin{eqnarray}
 & &  2^{-1/2} (z -x -U)^2 + 2^{-1/2} (x+ U - y - V)^2 \label{e.eqfive} \\ 
 %submit omit
%  & = & 2^{-1/2} (x - y  -U)^2 + 2^{-1/2} (x+ U - y - V)^2 \nonumber \\
 %submit omit
%  & = & 2^{1/2} (x - y)^2   -  2^{1/2}  (x - y)V + 2^{-1/2} \big( 2U^2 + V^2 - 2UV \big) \nonumber \\
 %submit omit
%  & = & 2^{1/2} (x - y - V/2)^2    + 2^{-1/2} \big( 2U^2 + V^2/2 - 2UV  \big) \nonumber \\   
  & = & 2^{-3/2} (z - y - V)^2    + 2^{-1/2} \big( 2U^2 + V^2/2 - 2UV  \big) \, . \nonumber
  \end{eqnarray}

Let $\notlow_{n;(z,-1)}^{([x,x+1],0)}(t/2)$ denote the event that  $\inf_{u \in [0,1]} \Big( \weight_{n;(z,-1)}^{(x+u,0)} + 2^{-1/2} ( x +u - z )^2 \Big) \geq - t/2$.
Note that
$$
 \neg \, \, \notlow_{n;(z,-1)}^{([x,x+1],0)}(t/2) \,  = \, \bigg\{ \inf_{u \in [0,1]} \Big( \scaledle_{n;(z,-1)}^{\uparrow;0}\big(1,x+u - z\big) + 2^{-1/2} ( x +u - z )^2 \Big) < - t/2   \bigg\} \, .
$$
We apply   Proposition~\ref{p.mega}(1)
% Proposition~\ref{p.strongothercurves} 
to the ensemble $\scaledle_{n;(z,-1)}^{\uparrow;0}$,  the choice admissible by  Proposition~\ref{p.scaledreg},
in order to find an upper bound on the probability of the displayed event. The application is made with %${\bf k} = 1$, 
${\bf y} = x - z + 1/2$, ${\bf t} = 1/2$ and ${\bf r} = t/2$.
Since the ensemble $\scaledle_{n;(z,-1)}^{\uparrow;0}$ has $n+1$, and therefore at least $n$, curves, we see that the next bounds suffice for the application to be made:
 $n  \geq (c/3)^{-18} \vee  6^{36}$, 
  $1/2 \leq n^{1/18}$, $t/2 \in \big[ 2^{3/2} \, , \, 2n^{1/18} \big]$
  and $\big\vert x - z + 1/2 \big\vert =  \big\vert y - x + 1/2 \big\vert
 \leq 2^{-1} \rsc   n^{1/18}$. 
 (In regard to the latter, recall that $z$ is now $2x-y$.) We learn from the application that
$$
 \PP \Big(  \neg \, \, \notlow_{n;(z,-1)}^{([x,x+1],0)}(t/2) \Big) \, \leq \,   
  (3 - 2^{3/2})^{-1} 5^{1/2}  \cdot 10 C \exp \big\{ - c_1 2^{-3/2} t^{3/2} \big\} \, .
$$





When $\notlow_{n;(z,-1)}^{([x,x+1],0)}(t/2) \cap \high_{n;([x,x+1],0)}^{([y,y+1],1)}(t)$ occurs, consider the concatenation $\rho_{n;(z,-1)}^{(x+U,0)} \circ \rho_{n;(x+U,0)}^{(y+V,1)}$ 
of any pair of polymers with the endpoints implied by our convention governing this notation. The concatenation 
has weight at least 
\begin{eqnarray*}
 & &  \Big( -t/2  - 2^{-1/2} ( x + U - z )^2 \Big) \, + \, \Big( t -  2^{-1/2} ( y+V - x - U )^2  \Big) \\
 & \geq & t/2 -  2^{-3/2} (z - y - V)^2  -   2^{-1/2} \big( 2U^2 + V^2/2 - 2UV  \big)  \\
  & \geq & t/2 -  2^{-3/2} (z - y - V)^2    - 5 \cdot 2^{-3/2} 
 \, ,
\end{eqnarray*}
the displayed inequalities due to~(\ref{e.eqfive}) and $U ,V \in [0,1]$.
Thus,
$$
  \high_{n;([x,x+1],0)}^{([y,y+1],1)}(t) \, \cap \, \notlow_{n;(z,-1)}^{([x,x+1],0)}(t/2) \subseteq \bigg\{ \sup_{v \in [0,1]} \Big( \weight_{n;(z,-1)}^{(y+v,1)} + 2^{-3/2} (z - y - v)^2 \Big)  \geq t/2  - 5 \cdot 2^{-3/2}  \bigg\} \, .
$$
The right-hand event equals 
\begin{eqnarray}
 & &  \bigg\{ \sup_{v \in [0,1]} \Big( \mc{L}_{n;(z,-1)}^{\uparrow;1}(1,y+v) + 2^{-3/2} (z - y - v)^2 \Big)  \geq t/2 - 5 \cdot 2^{-3/2} \bigg\} \label{e.lnrhs} \\ 
  & = &   \bigg\{ \sup_{v \in [0,1]} \Big(  \scaledle_{n;(z,-1)}^{\uparrow;1}\big(1, 2^{-2/3} (y+v - z) \big) + 2^{-1/2} \big( 2^{-2/3}(z - y - v) \big)^2 \Big)  \geq 2^{-4/3}t - 5 \cdot 2^{-11/6} \bigg\} \nonumber \\
  & = &   \bigg\{ \sup_{v \in [0,2^{-2/3}]} \Big(  \scaledle_{n;(z,-1)}^{\uparrow;1}\big(1, 2^{-2/3} (y - z) + v \big) + 2^{-1/2} \big( 2^{-2/3}(z - y) - v \big)^2 \Big)  \geq 2^{-4/3}t - 5 \cdot 2^{-11/6} \bigg\} \, . \nonumber 
\end{eqnarray}

We now apply the No Big Max Proposition~\ref{p.mega}(2) 
%Proposition~\ref{p.nobigmax.gen}
to the ensemble $\mc{L}_N =  \scaledle_{n;(z,-1)}^{\uparrow;1}$,  the application permitted by Proposition~\ref{p.scaledreg}.
In the application, we set ${\bf y} =  2^{-2/3} (y - z) + 2^{-5/3}$, ${\bf r} = 2^{-5/3}$ and ${\bf t} =  2^{-4/3}t - 5 \cdot 2^{-11/6}$. The curve cardinality of the ensemble in queston is $2n+1 \geq 2n$.
As such, it is sufficient for the application to be valid that
$$
\big\vert 2^{-2/3} (y - z) + 2^{-5/3} \big\vert =  
\big\vert 2^{1/3} (y - x) + 2^{-5/3} \big\vert  \leq c/2 \cdot (n\tot)^{1/9} \, , \, 2^{-5/3} \leq \rsc/4 \cdot (n\tot)^{1/9} 
$$
and $2^{-4/3}t - 5 \cdot 2^{-11/6} \in \big[ 2^{7/2} , 2 (n\tot)^{1/3} \big]$
as well as $\tot n \geq c^{-18}$ where here $\tot$ equals $2$ (in accordance with the time-pair $t_1 = -1$ and $t_2 = 1$ being considered).
This application tells us that the $\PP$-probability of the event~(\ref{e.lnrhs}) is at most
$$
   \big( 2^{-5/3} + 1 \big) \cdot  6  \rsC \exp \big\{ - 2^{-11/2} \rsc  \big(  2^{-4/3}t - 5 \cdot 2^{-11/6} \big)^{3/2} \big\} \leq  8  \rsC \exp \big\{ -     2^{-9} \rsc t^{3/2} \big\}  \, ,
$$
where we used $2^{-4/3}t - 5 \cdot 2^{-11/6} \geq 2^{-7/3} t$ when $t \geq 5 \cdot 2^{1/2}$. 


We find then that
$$
 \PP \Big( \high_{n;([x,x+1],0)}^{([y,y+1],1)}(t) \Big) \,  \leq \, \PP \Big( \high_{n;([x,x+1],0)}^{([y,y+1],1)}(t) \cap \notlow_{n;(z,-1)}^{([x,x+1],0)}(t/2) \Big) \, + \, \PP \Big( \neg \, \, \notlow_{n;(z,-1)}^{([x,x+1],0)}(t/2)  \Big)
$$
is bounded above by
$$
  8  \rsC \exp \big\{ -     2^{-9} \rsc t^{3/2} \big\} 
 \, + \,
  10 (3 - 2^{3/2})^{-1} 5^{1/2}    C \exp \big\{ - c_1 2^{-3/2} t^{3/2} \big\} \, .
$$
We now  use $c_1 \leq \rsc$ and $8 + 10 (3 - 2^{3/2})^{-1}  5^{1/2}     \leq 139$ to obtain~(\ref{e.weightuvsupremum}). This completes the proof of Proposition~\ref{p.maxminweight}. \qed

The reader may have noticed that every application of a result concerning a $(c,C)$-regular ensemble in the preceding proof invoked Proposition~\ref{p.scaledreg} 
in order to justify that the ensemble in question indeed enjoys this property. Every subsequent such application is no different, and henceforth we omit mention of Proposition~\ref{p.scaledreg}'s role.



\section{Polymer weight regularity: proving Theorem~\ref{t.differenceweight}}\label{s.polyweightreg}


We begin this section by introducing a notation $\paradelta\weight$ to denote the difference in {\em parabolically adjusted} weight of two polymers 
crossing between the opposite endpoints of two intervals. (The superscript $\cup$ is intended to suggest a parabola.)
When $(x_1,x_2)$ and $(y_1,y_2)$ belong to $\R^2_\leq$, 
we set  
\begin{equation}\label{e.paradelta}
\paradelta\weight_{n;([x_1,x_2],0)}^{([y_1,y_2],1)} \, := \, \Big( \weight_{n;(x_2,0)}^{(y_2,1)} + 2^{-1/2}(y_2 - x_2)^2 \Big) - \Big( \weight_{n;(x_1,0)}^{(y_1,1)}  + 2^{-1/2}(y_1 - x_1)^2 \Big) \, .
\end{equation}
We will abuse this notation when one of the concerned intervals collapses a point, writing for example
 $\paradelta\weight_{n;(x_1,0)}^{([y_1,y_2],1)}  = \weight_{n;(x_1,0)}^{(y_2,1)} - \weight_{n;(x_1,0)}^{(y_1,1)} +  2^{-1/2}(y_2 - x_1)^2 -  2^{-1/2}(y_1 - x_1)^2$. 
 
 We also write $y + U = \{ y+u:u \in U \}$ when $y \in \R$ and $U \subset \R$.

Any integer is called 
a dyadic rational of scale zero. A dyadic rational of scale $i \in \N$, $i \geq 1$, has for the form $p 2^{-i}$ where $p \in \Z$ is odd. 
A dyadic interval of scale $i \in \N$ is a closed interval of length~$2^{-i}$ that has an endpoint which is a dyadic rational of scale~$i$.

Recall from Subsection~\ref{s.spa} the polymer weight regularity events $\pwr$.

\begin{proposition}\label{p.dyadic}
Let $n \in \N$, $n \geq (4/c)^9$, let $x,y \in \R$ satisfy  $\big\vert x - y  \big\vert \leq \rsc/4 \cdot n^{1/9}$,  
 and let $K_0 \geq 9$. 
 %[[ be a real parameter satisfying   $\Kzero  \geq  3 \cdot 2^{19/2}$. ]] 
 Let $i,k_0 \in \N$ with $i \geq k_0$ (which is at least one). 
%Set $t_0 = 2^{-8}K_0/3$. 
Consider the quantities
\begin{equation}\label{e.deltaone}
\PP \Big( \sup \Big\vert  \paradelta\weight_{n;(x+ z,0)}^{(y+ U,1)} \Big\vert \geq   K_0 2^{-i/2}  \, , \,  \maxmin_{n;([x,x+1],0)}^{([y-2,y+3],1)}(K_0/4)   \Big)  
\end{equation}
 and 
\begin{equation}\label{e.deltatwo}
\PP \Big( \sup \Big\vert  \paradelta\weight_{n;(x+ U,0)}^{(y+ z,1)} \Big\vert \geq  K_0 2^{-i/2}   \, , \,  \maxmin_{n;([x-2,x+3],0)}^{([y,y+1],1)}(K_0/4)  \Big) \, , 
\end{equation}
where in each case the supremum is taken over all 
dyadic rationals $z \in [0,2^{-k_0}]$ of scale $i$ and dyadic intervals $U \subseteq [0,2^{-k_0}]$ of scale at least $i$. 
Each of these quantities is at most 
$2^{2(i-k_0)} \exp \big\{ - 2^{-3}  \Kzero^2 \big\}$.
\end{proposition}
This result is naturally a key technical ingredient in the proof of Theorem~\ref{t.differenceweight}.
The theorem concerns polymer weight differences when small changes are made in endpoint locations. The proposition is similar, but restricts to endpoint locations that are dyadic rationals.
The theorem will follow from the proposition by noting that one may skip between the two nearby endpoint locations $x$ and $x + \e$ (and similarly for $y$ and $y + \e$)
by jumping through a possibly infinite sequence of intermediate dyadic rational  locations where no dyadic scale need be visited more than twice and the minimal dyadic scale is of the order of the difference~$\e$.
This property of this `stepping stone' sequence makes the union bounds over the estimate in Proposition~\ref{p.dyadic} manageable. 
This inference of the theorem from the proposition is similar to the derivation of the Kolmogorov continuity criterion, in which moment bounds on the difference of a stochastic process between a generic pair of times imply H\"older continuity of the process: see~\cite[Thoerem~$8.13$]{Durrett10}. 



%[Durrett, Probability: Theory and Examples, Edition 4.1, $services.math.duke.edu/~rtd/PTE/PTE4_1.pdf$ , Theorem 8.13, page 304]. Note that this is edition 4.1, while the cited is called the `fourth edition'.

One further aspect of the plan for proving Theorem~\ref{t.differenceweight} deserves mention before we proceed. 
%To explain this aspect, it is useful to begin by mentioning that a key motor for the proof of Proposition~\ref{p.dyadic}
%is  the local curve regularity Theorem~\ref{p.mega}(3). In this result,  the spatial scale $\e > 0$ is permitted to be arbitrarily small without forcing the ensemble curve cardinality $N$ to be higher in an $\e$-dependent way. This favourable circumstance 
Note that in the theorem the parameter $R$, which measures the degree of polymer weight fluctuation,
must verify an $n$-dependent upper bound. Although this bound in a sense is insignificant for the purpose of analysing high $n$ behaviour,
Proposition~\ref{p.dyadic} has been stated so that there is no comparable hypothesis:
the quantities $K_0$ and $2^{-i}$ are counterparts to $R$ and $\e$, and the proposition holds for all high~$n$, where the lower bound on $n$ deteriorates neither as the dyadic scale~$2^{-i}$ decreases, nor as the parameter $K_0$ increases.
Now this is a valuable property, but it comes at a certain price, about which more in a moment. 
The reason that the property is valuable is that, for a given high value of $n$, Proposition~\ref{p.dyadic}
may be applied as $i$ increases to infinity, while in the meantime, $K_0$ also increases; indeed, this is how we will derive 
 Theorem~\ref{t.differenceweight}, with a union bound over the infinite number of applications of the proposition indexed by~$i$ being controllable due to the ongoing increase in $K_0$.
%  to apply it simultaneously to the infinitely many terms of the stepping stone sequence. 
  As for the price to be paid, we mention that,
in order that the property obtains, it has been necessary in the events whose probabilities are gauged in~(\ref{e.deltaone}) and~(\ref{e.deltatwo})
to include the global polymer weight regularity events $\pwr$; this in turn is because the proposition's proof  will invoke the two-point Proposition~\ref{p.locreg}, in which the spatial scale $\e > 0$ is permitted to be arbitrarily small without forcing the ensemble curve cardinality $N$ to be higher in an $\e$-dependent way, a favourable circumstance which is only possible at the expense of introducing the global regularity event $\boundgood_{K/4}$, counterpart to the above $\pwr$ events, into the probability upper bound in that result.
In any case, it would seem that we can derive Theorem~\ref{t.differenceweight} from 
Proposition~\ref{p.dyadic}  only by invoking the $\pwr$ event. In fact, we do impose this event, but, at the very end of the derivation, we gauge the 
 probability of the complementary event $\neg \, \pwr$ via Corollary~\ref{c.maxminweight}; thus, this probability cost is paid only once, rather than with each of the infinitely many applications of Proposition~\ref{p.dyadic}. 
 

\noindent{\bf Proof of Proposition~\ref{p.dyadic}.}
Consider a given dyadic interval $U \subseteq [0,2^{-k_0}]$ of a scale $j$ such that $j  \geq i$ and write $U = [u_1,u_2]$.
For a given dyadic rational $z \in [0,2^{-k_0}]$, note that 
$$
 \paradelta\weight_{n;(x+ z,0)}^{(y+ U,1)}  =  \mc{L}^{\uparrow;1}_{n;(x+z,0)}\big(1,y+ u_2 \big) + 2^{-1/2}(y+u_2 - x+z)^2 -  \mc{L}^{\uparrow;1}_{n;(x+z,0)}\big(1, y + u_1 \big)  - 2^{-1/2}(y+u_1 - x+z)^2  
$$
and that
\begin{equation}\label{e.twoomegas}
  \paradelta\weight_{n;(x+ U,0)}^{(y+ z,1)}   = \mc{L}^{\downarrow;(y+z,1)}_{n;0}\big(1,x+u_2 \big)
+ 2^{-1/2}(x+u_2 - y+z)^2  
   -  \mc{L}^{\downarrow;(y + z,1)}_{n;0}\big(1,x + u_1 \big) - 2^{-1/2}(x+u_1 - y+z)^2   \, . 
\end{equation}
%Since $\vert U \vert = u_2 - u_1 = 2^{-j}$, these parabolically adjusted weight differences are respectively bounded above by
%\begin{eqnarray}
% & & \omega_{[y+u_1,y+u_2]}\Big( v \to \mc{L}^{\uparrow;1}_{n;(x+z,0)}(1,v)  + 2^{-1/2} (v - x - z)^2 , 2^{-j} \Big) \nonumber \\
%\textrm{and} & & 
%\omega_{[x+u_1,x+u_2]}\Big( v \to  \mc{L}^{\downarrow;(y+z,1)}_{n;0}(1,v)  + 2^{-1/2} (v - y - z)^2 , 2^{-j} \Big) \, . \label{e.twoomegas}
%\end{eqnarray}
%%Recall that $U = [u_1,u_2]$ is a given dyadic interval of scale $j \geq i \geq 2$ with $U \subset [0,1]$, we 
Let $K > 0$ be a parameter that we will later specify. We now seek to apply 
Proposition~\ref{p.locreg}
%Proposition~\ref{p.aestimateinference} 
in order to bound the $\PP$-probability that the last two displayed quantities
exceed $K \vert U \vert^{1/2} = K 2^{-j/2}$.
In order to do so for the first quantity, the proposition will be applied to the ensemble
$\mc{L}_N =  \scaledle^{\uparrow;1}_{n;(x+z,0)}$.
%,  with Proposition~\ref{p.scaledreg} showing that this choice is admissible.
 Proposition~\ref{p.locreg}'s 
% Proposition~\ref{p.aestimateinference}'s 
 parameters in this case are set 
 %${\bf k} = 1$, 
 ${\bf x} = y+u_1 - x - z$, ${\bm \e} = 2^{-j}$ and ${\bf K} = K$.
% this choice forces ${\bf t} =  2^{-8} K/3$. 
 Note that the event whose probability is bounded above by the proposition is a subset of $\boundgood_{K/4}({\bf x})$. With the present choice of ensemble $\mc{L}_n$,   the event  $\boundgood_{K/4}({\bf x})$ equals $\maxmin_{n;(\{x+z\},0)}^{([y+u_1 - 2,y+u_1 + 2],1)}(K/4)$. 
 (Note that here $\{ x+z \}$ is a singleton set, so that a space of polymers emanating from the point $(x+z,0)$ is at stake.)
 Thus,  $\maxmin_{n;([x,x+1],0)}^{([y-2,y+3],1)}(K/4) \subseteq \boundgood_{K/4}({\bf x})$.
 As such, 
 %this application of 
 Proposition~\ref{p.locreg} implies that
 \begin{eqnarray}
  & &\PP \bigg(   \Big\vert  \paradelta\weight_{n;(x+ z,0)}^{(y+ U,1)} 
  \Big\vert   \geq  K 2^{-j/2}  \, , \,   \maxmin_{n;([x,x+1],0)}^{([y-2,y+3],1)}(K/4) \bigg) \nonumber \\
  & \leq & \PP \bigg(   \Big\vert  \paradelta\weight_{n;(x+ z,0)}^{(y+ U,1)} 
  \Big\vert   \geq  K 2^{-j/2}  \, , \,  \boundgood_{K/4}({\bf x})  \bigg)   \leq  
 2^{3/2} \pi^{-1/2}   K^{-1}  \exp \big\{ - 2^{-3}  K^2 \big\}  
  \, . \label{e.concone}
 \end{eqnarray}
The hypotheses of Proposition~\ref{p.locreg} that are invoked to obtain this bound are 
$$
n + 1 \geq 6^3 c^{-3} \, , \, \vert  y + u_1 - x - z \vert \leq 2^{-1} \rsc n^{1/9} \, , \,  2^{-j} \in (0,1] 
  \, \, \, \textrm{and} \, \, \, K \geq  9 \, ;
$$
note that $j \geq 0$ 
%[[was $j \geq 1$]] 
is used to validate the third of these.

Another application of  Proposition~\ref{p.locreg}
% Proposition~\ref{p.aestimateinference} 
 is made in regard to the quantity~(\ref{e.twoomegas}).
On this occasion, the ensemble $\mc{L}_n$ is set equal to $\scaledle^{\downarrow;(y+z,1)}_{n;0}$, and the parameters are set:
%${\bf k} = 1$, 
 ${\bf x} = x + u_1  - y - z$, ${\bm \e} = 2^{-j}$ and ${\bf K} = K$. 
 In this instance, the event  $\boundgood_{K/4}({\bf x})$ equals  
$\maxmin_{n;([x+u_1 - 2,x + u_1 + 2],0)}^{(y+z,1)}(K/4)$, so that  $\maxmin_{n;([x-2,x+3],0)}^{([y,y+1],1)}(K/4) \subseteq \boundgood_{K/4}({\bf x})$.
The outcome of the application in this case is the conclusion that
\begin{eqnarray}
 & & \PP \bigg(  \Big\vert \paradelta\weight_{n;(x+ U,0)}^{(y+ z,1)} \Big\vert \geq K 2^{-j/2} \, , \,    \maxmin_{n;([x-2,x+3],0)}^{([y,y+1],1)}(K/4)  \bigg)  \nonumber  \\
  & \leq &
 2^{3/2} \pi^{-1/2}    K^{-1}  \exp \big\{ - 2^{-3}  K^2 \big\} 
  \, , \label{e.conctwo}
\end{eqnarray}
while the hypothesis $\vert x + u_1  - y - z \vert \leq 2^{-1} \rsc  n^{1/9}$ is used to make the application.

The dyadic scale $j$ is at least the scale $i$ by assumption, and we now denote $\ell = j - i \geq 0$. 
We recall from the statement of Proposition~\ref{p.dyadic} that we consider a parameter $\Kzero \geq 9$. 
%[[ that is supposed to satisfy $\Kzero \geq  3 \cdot 2^{19/2}$. ]] 
We now set the value of our parameter~$K$, choosing it to be $\Kzero 2^{(j-i)/2}$. Our conclusions~(\ref{e.concone}) and~(\ref{e.conctwo}) tell us that
$$
 \PP  \Big( \Big\vert  \paradelta\weight_{n;(x+ z,0)}^{(y+ U,1)} 
  \Big\vert   \geq  \Kzero 2^{-i/2}  \, , \,  \maxmin_{n;([x,x+1],0)}^{([y-2,y+3],1)}(K_0/4) \Big) 
$$
and 
\begin{equation}\label{e.backfluc}
 \PP  \Big(  \Big\vert \paradelta\weight_{n;(x+ U,0)}^{(y+ z,1)} \Big\vert \geq  \Kzero 2^{-i/2}  \, , \,  \maxmin_{n;([x-2,x+3],0)}^{([y,y+1],1)}(K_0/4) \Big)
\end{equation}
are both at most
$2^{3/2} \pi^{-1}   \Kzero^{-1} \exp \big\{ - 2^{-3} \cdot 2^\ell \Kzero^2 \big\}$, 
where we used $K/4 \geq \Kzero/4$.


We will now sum the stated bound on quantities of the form~(\ref{e.backfluc})
%, and use~(\ref{e.maxminbound}), 
in order to find an upper bound on the expression~(\ref{e.deltatwo})
%, namely
%$$
% \PP  \Big( \sup \Big\vert 
% \mc{L}^{\downarrow;(y+z,1)}_{n;0}\big(1,x+u_2 \big) -  %\mc{L}^{\downarrow;(y + z,1)}_{n;0}\big(1,x + u_1 \big)  
% \Big\vert \geq  \Kzero 2^{-i/2}   \, , \,  \maxmin_{n;([x-2,x+3],0)}^{([y,y+1],1)}(t_0)   \Big) 
%$$
where recall that, in this expression, the supremum is taken over choices of scale~$i$ dyadic rational $z \in [0,2^{-k_0}]$ and dyadic interval $U = [u_1,u_2] \subset [0,2^{-k_0}]$ of scale at least~$i$. 
Indeed, 
since the number of dyadic rationals of scale $i$ in $[0,2^{-k_0}]$
is at most $2^{i-k_0} + 1$, while the number of scale~$j$ dyadic intervals contained in $[0,2^{-k_0}]$ equals $2^{j-k_0}$,
we may sum over $j \geq i$, also using that $\Kzero \geq 2^{3/2}$, to find that~(\ref{e.deltatwo}) is at most 
$$
 (2^{i - k_0} +1) \cdot 2^{i-k_0} \cdot \tfrac{1}{e-2} \cdot
 2^{3/2} \pi^{-1} K_0^{-1}     \exp \big\{ - 2^{-3}  \Kzero^2 \big\} \, .
% \, + \, 10450 \, C \exp \big\{ - c_1 2^{-5/2} t_0^{3/2} \big\} \, .
$$
Using $i \geq k_0$ and $K_0 \geq 9$,
 this quantity is found to be bounded above by
$$
 2^{2(i-k_0)+ 5/2} 3^{-2} (e-2)^{-1}  \pi^{-1}  \exp \big\{ - 2^{-3}  \Kzero^2 \big\}  \leq 2^{2(i-k_0)}  \exp \big\{ - 2^{-3}  \Kzero^2 \big\}    \, .
$$
% 2^{5/2} (e-2)^{-1} \pi^{-1} = 2.506\cdots so 2^{5/2} 3^{- 2} (e-2)^{-1} \pi^{-1} \leq 1
 We have obtained the upper bound claimed in Proposition~\ref{p.dyadic} on the probability~(\ref{e.deltatwo}) and, since
 this upper bound on~(\ref{e.deltaone}) is similarly obtained,  we have completed the proof of 
this proposition. \qed

\medskip


%In the both of the probability upper bounds in the preceding proposition, the complements of both of the concerned $\maxmin$ events are contained in $\neg \, \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}(t_0)$. 

We now state an estimate also needed for the proof of Theorem~\ref{t.differenceweight}. Suppose that $n$ is an even integer that satisfies
\begin{equation}\label{e.twentyfiveapp}
n \geq 10^{29} \vee 2(c/3)^{-18} \, , \,  \big\vert x - y  \big\vert + 4 \leq   3^{-1} 2^{-2/3} \rsc  n^{1/18} \, \, \textrm{and} \, \, r_0 \in \big[  33 \, , \,  4 n^{1/18} \big] \, .
\end{equation}
Corollary~\ref{c.maxminweight} with ${\bf n} = n$, ${\bf t_1} = 0$,  ${\bf t_2} = 1$, ${\bf x} = x-2$, ${\bf y} = y-2$, ${\bf a} = {\bf b} = 5$ and ${\bf r} = r_0$ implies that 
\begin{equation}\label{e.maxminbound}
 \PP \Big( \neg \,  \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}(r_0) \Big) \leq 5^2 \cdot  400 \, C \exp \big\{ - c_1 2^{-9} r_0^{3/2} \big\} \, .
\end{equation}
Note that $\big\vert x - y  \big\vert + 4 \leq   3^{-1} 2^{-2/3} \rsc  n^{1/18}$
is implied by  $\big\vert x - y  \big\vert \leq  2^{-1} 3^{-1} 2^{-2/3} \rsc  n^{1/18}$
and $4 \leq 2^{-1} 3^{-1} 2^{-2/3} \rsc  n^{1/18}$ and the latter is implied by 
$n \geq \big( 2^{11/3} 3 \big)^{18}$.

\medskip

\noindent{\bf Proof of Theorem~\ref{t.differenceweight}.}
Write $I = [x,x+\e]$ and $J = [y,y+\e]$, and let $u \in I$ and $v \in J$ be arbitrary. Recalling that $\e \leq 2^{-4}$ is less than one, we
consider the  binary expansion $u - x = \sum_{j=1}^\infty s_j 2^{-j}$. If the expansion is not unique, we choose its terminating version for definiteness.
Let the increasing sequence $u_0,u_1,\cdots$ 
enumerate the set 
$$
 \bigg\{ \,  x +  \sum_{j=1}^k s_j 2^{-j} : k \in \N \, \bigg\} \, .
$$
This sequence may be finite or infinite. It begins
$u_0 = x$, and, when it is infinite, each term $u_n$ equals the sum of $x$ and the quantity given by the truncation of the binary expansion of $u-x$
that contains $n$ instances of the digit one.
Let $n_1 \in \N \cup \{ \infty \}$ denote the maximal index of a term in the $u$-sequence. If $n_1 < \infty$, then $u_{n_1} = u$, and if $n_1 = \infty$, then $u_n \nearrow u$, and we set $u_\infty = u$.

Similarly, we specify an increasing sequence  $v_0,v_1,\cdots$ by replacing $(x,u)$ by $(y,v)$ above, and let~$n_2$ denote the maximal index of a term in the $v$-sequence. If $n_2 = \infty$, set $v_\infty = v$.

Call the planar points $\big\{ (u_i,0): 0 \leq i \leq n_1 \big\}$ lower pegs, and the points  $\big\{ (v_i,1): 0 \leq i \leq n_2 \big\}$ upper pegs.
Think of a  planar line segment {\em cord}  that runs in the first instance between $(u_0,0) = (x,0)$
and $(v_0,1) = (y,1)$.  Permitting the cord to be pegged at its lower and upper end to any of the pegs, we see that the cord begins in its leftmost possible location.
The rightmost available location is given by lower peg $(u_\infty,0) = (u,0)$ and upper peg $(v_\infty,1) = (v,1)$.
We now specify a possibly infinite sequence of cord moves by which  the cord will achieve, or at least converge towards, this rightmost location.
Let $(L_i,U_i) \in \{0,\cdots,n_1\} \times \{0,\cdots,n_2 \}$ denote the indices of lower and upper peg locations at step $i \in \N$, where the original location is indexed by $i = 0$,
so that $(L_0,U_0) = (0,0)$.
Let $k \in \N$ and consider the value of $(L_k,U_k)$. If this value is $(n_1,n_2)$, then the cord movement is complete and the value of  $(L_{k+1},U_{k+1})$
is not recorded. In the other case, there are two possible moves for the cord at the next step: a lower peg advance, in which  
$L_{k+1} = L_k + 1$ and $U_{k+1} = U_k$, or an upper peg advance, in which $U_{k+1} = U_k + 1$ and $L_{k+1} = L_k$. It may be that one of these moves is inadmissible, because $L_k = n_1$, which renders the lower peg advance unavailable, or $U_k = n_2$, which does likewise for the upper peg advance.
If this is so, then $(L_{k+1},U_{k+1})$ is set equal to the value given by the only available advance.
In the case where both advances are possible, note that each move entails displacing a peg to the right by a distance of the form $2^{-i}$ for some $i \in \N$.
The decision of which advance to make is taken so that this distance is the larger for the available two advances,
with say the upper advance being made if the distances are equal.
In this way, we specify the value of $(L_{k+1},U_{k+1})$; we may also record the dyadic scale, $D_{k+1} \in \N$, of the advance associated to this index increase $k \to k+1$:
this scale is the value of $i \in \N$ such that the peg displacement made in the peg advance resulting in the new peg locations $(L_{k+1},U_{k+1})$ equals $2^{-i}$.
  
The sequence of location pairs  $\big( u_{L_k} , v_{U_k} \big)$ either reaches its terminal state $(u,v)$ after finitely many moves, or it converges to this state as $k$ increases.
Note also that the dyadic scale sequence $D_1,D_2,\cdots$ is a non-decreasing $\N$-valued sequence that assumes any given value at most twice. This sequence depends on the pair $(u,v)$, and we may indicate this dependence by writing $D_k = D_k(u,v)$.

Moreover, we define a dyadic scale $i_0 \in \N$ by setting $i_0 \geq 0$ to be minimal such that $2^{i_0} \e \geq 1$. Then, since the first peg is displaced by a distance $2^{-D_1}$ which is at most $\e < 2^{1 - i_0}$, we see that $D_1 \geq i_0$.
We see then that the dyadic scales   $\big\{ D_j: j \geq 1 \big\}$ of the distances of peg moves for the advancing cord grow linearly from around $i_0$: 
\begin{equation}\label{e.djlb}
D_j \geq i_0 - 1 + j/2 \, \, \,  \textrm{for} \, \, \,  j \geq 1 \, . 
\end{equation}
To any cord location we may associate the parabolically adjusted weight $\weight_{n;(z,0)}^{(z',1)} + 2^{-1/2} (z' - z)^2$ of the polymer whose endpoints $(z,0)$ and $(z',1)$ are the pegs to which the cord is pinned.
Using the notation~(\ref{e.paradelta}), we may further set, for $k \geq 0$, 
\begin{equation}\label{e.wkplusone}
W_{k+1} = W_{k+1}(u,v) = \paradelta\weight_{n;([u_{L_k},u_{L_{k+1}}],0)}^{([v_{U_k},v_{U_{k+1}}],1)}   \, ,
\end{equation}
this being the difference in parabolically adjusted weight of this polymer as a result of the cord move from its index $k$ to $k+1$ location.



Lemma~\ref{l.basic}(1) implies that, for given $n$, $\lim_k \weight_{n;(L_k,0)}^{(U_k,1)} = \weight_{n;(u,0)}^{(v,1)}$.
Thus,
\begin{equation}\label{e.sumwk}
 \weight_{n;(u,0)}^{(v,1)} -   \weight_{n;(x,0)}^{(y,1)} + 2^{-1/2}(v-u)^2 - 2^{-1/2}(y-x)^2 = \sum_{k=1}^\infty W_k \, ,
\end{equation}
where it is understood that the right-hand sum may have only finitely non-zero terms. 


For each $k \in \N$ (at least one), we set $W^*[k]$ to be the supremum of the values of $\vert W_k \vert$ over all choices of $(u,v)$ in our construction. We now argue that there exists a pair $(u^*[k],v^*[k]) \in I \times J$ such that $W^*[k] = \big\vert W_k(u^*[k],v^*[k]) \big\vert$; in other words, we argue that the supremum specifying $W^*[k]$ is attained. First note that, if $W^*[k]=0$, any choice of $(u^*[k],v^*[k]) \in I \times J$ works. Suppose instead then that $W^*[k] > 0$. For any given $(u,v) \in I \times J$, the value $W_k(u,v)$ takes one of the forms $\paradelta\weight_{n;(x + \Theta,0)}^{(y + z_1,1)}$ or $\paradelta\weight_{n;(x + z_2,0)}^{(y + \Lambda,1)}$, where in the former case, $\Theta$ is a dyadic rational interval and $z_1 \in [0,\e]$ is a dyadic rational whose scale is by our construction at most that of~$\Theta$; and, in the latter, these statements are equally true of $\Lambda$ and $z_2$.
Now the number of such expressions for which the length of the interval $\Theta$ or $\Lambda$ in the indexing pair $(\Theta,z_1)$ or $(z_2,\Lambda)$ exceeds an arbitrary given positive value~$\delta$ is finite. On the other hand, since the map $I \times J \to \R: (u,v) \to \weight_{n;(u,0)}^{(v,1)}$ is uniformly continuous,
there exists a random value $\delta > 0$ such that none of the parabolically adjusted weight differences whose indexing pair contains an interval $\Theta$ or $\Lambda$
of length less than $\delta$
has value exceeding the positive quantity $W^*[k]/2$. The value $W^*[k]$ is thus seen to be the maximum of a certain finite set of such weight differences, and thus, it is indeed achieved.  

For given $(u,v) \in I \times J$, there are many choices of $(u^*[k],v^*[k]) \in I \times J$, and we pick the lexicographically minimal pair for definiteness.  We further specify the dyadic scale
$D^*[k] = D_k(u^*[k],v^*[k])$.

 

By~(\ref{e.djlb}), $D_\ell(u,v) \geq i_0  - 1 + k$ provided that $\ell \geq 2k$, whatever the value of $(u,v) \in [x,x+\e] \times [y,y+\e]$ may be.
Thus, when $\ell \in \{ 2k,2k+1 \}$,
the quantity $W^*[\ell]$ takes the form $\big\vert \paradelta\weight_{n;(x+ z,0)}^{(y+ U,1)} \big\vert$ or  $\big\vert \paradelta\weight_{n;(x+ U,0)}^{(y+ z,1)} \big\vert$
where  $z \in [0,2^{1-i_0})$ is a 
dyadic rational of scale $D^*[\ell]$ at least $i_0 - 1 + k$ and $U \subset [0,2^{1-i_0})$ is a dyadic interval whose scale is at least that of $z$. 
For this reason, it is tempting -- though, as we shortly explain, mistaken -- to use Proposition~\ref{p.dyadic}
with ${\bf k_0} = i_0 - 1$ and ${\bf i} = D^*[\ell]$ to find an upper bound on the probability 
$$
 \PP \Big( W^*[\ell] \geq K_0 \, 2^{-D^*[\ell]/2}  \, , \,  \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}\big( 2^{-2} K_0 \big) \Big) \, ,
$$
where recall from the proposition that $K_0 \geq 9$ is a parameter.
Indeed, the proposition formally implies that, 
whenever $k \in \N$ and $\ell \in \{ 2k,2k+1 \}$,
this probability is at most
$$
 2 \cdot 
 2^{2 (D^*[\ell] - i_0 +1  )} \cdot   \exp \big\{ - 2^{-3}  \Kzero^2 \big\}  \, .
$$
This application is erroneous, however, because  $D^*[\ell]$ is random and thus the choice ${\bf i} = D^*[\ell]$ is inadmissible. 
We adjust to cope with this problem by introducing a parameter $j \in \N$ that is supposed to be at least $i_0 - 1 +k$. For any given such $j$, we may now apply
 Proposition~\ref{p.dyadic}
with ${\bf k_0} = i_0 - 1$ and ${\bf i} = j$. We thus find that, for $k \in \N$, $\ell \in \{ 2k,2k+1 \}$ and $j \geq i_0 - 1 +k$, 
\begin{eqnarray*}
 & &\PP \Big( W^*[\ell] \geq K_0 \, 2^{-j/2}  \, , \, D^*[\ell] = j  \, , \, \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}\big( 2^{-2} K_0 \big) \Big) \\
 & \leq &  
 2^{1 + 2 (j - i_0 +1  )}    \exp \big\{ - 2^{-3}  \Kzero^2 \big\}  \, . 
\end{eqnarray*}



With such $j$ remaining fixed,
we now choose the parameter $K_0$ as a function of $\ell \in \N$ and $j$,
setting $K_0 = S \cdot 2^{-i_0/2 - k/4} \cdot 2^{j/2}$. 
(Since $k = \lfloor \ell/2 \rfloor$, this choice is indeed determined by $\ell$.) For reasons soon to be explained, we set the new quantity $S$ equal to $2^{9/2}$.
  Using $j \geq i_0 - 1 + k$, we see that $K_0 \geq  2^{k/4 - 1/2} S$ (and thus $K_0 \geq 9$, as is needed).
Since the event $\maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}(K_0/4)$ is increasing in $K_0 > 0$, 
we~find~that
\begin{eqnarray*}
 & & \PP \Big( W^*[\ell] \geq  S \cdot 2^{- i_0/2 - k/4}   \, , \, D^*[\ell] = j  \, , \,  \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}\big( 2^{- 2 - 1/4} S \big) \Big) \\
 & \leq &  
 2^{1 + 2 (j - i_0 +1  )}  \exp \big\{ - 2^{-3 -i_0 - k/2 + j} S^2 \big\}  \, .
\end{eqnarray*}
Summing over $k \geq 1$, the two values of $\ell$ for each $k$, and the values $j \in \N$ that are at least $i_0 - 1 +k$, we learn that
\begin{eqnarray}
 & &\PP \Big( \sum_{\ell = 0}^\infty W^*[\ell] \geq  2S \sum_{k=0}^\infty 2^{-i_0/2 - k/4}  \, , \,  \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}\big(  2^{- 9/4} S    \big) \Big) \nonumber  \\
 & \leq & 2 \, \sum_{\ell = 0}^\infty \sum_{j = i_0 - 1 + \lfloor \ell/2 \rfloor}^\infty 
  2^{1 + 2(j - i_0 + 1)}  
 \exp \big\{  - 2^{-3 -i_0 - \ell/4 + j} S^2  \big\} \nonumber \\
 & \leq & 8 \, \sum_{\ell = 0}^\infty  
 2^{2 \lfloor \ell/2 \rfloor}
 \exp \big\{  - 2^{-3 -i_0 - \ell/4 + i_0 - 1 + \lfloor \ell/2 \rfloor} S^2 
     \big\} \nonumber \\
     & \leq & 8 \, \sum_{\ell = 0}^\infty  
 2^\ell
 \exp \big\{  - 2^{-5 + \ell/4} S^2 \big\} \label{e.sumexpress} \, .
 \end{eqnarray}
The final inequality is trivial, but a brief explanation is needed to verify the second.  Note that the ratio of the summands on this inequality's left-hand side  indexed by $(\ell,j+1)$ and $(\ell,j)$ is at most one-half provided that 
 $2^{-3 - i_0 - \ell/4 + j} S^2 \geq 3 \log 2$; since $j \geq i_0 - 1 + k$, while $k = \lfloor \ell/2 \rfloor$ and $\ell \geq 0$, the latter bound is seen to be valid when  $S \geq 2^{5/2} 3^{1/2} (\log 2)^{1/2}$. Since $S$  equals $2^{9/2}$, the last condition holds; and thus the bound in question emerges because its right-hand side is the sum of the concerned geometric series. 
 
     
Consider then the expression $2^\ell
 \exp \big\{  - 2^{-5 + \ell/4} S^2 \big\}$.  
The ratio of each  summand, indexed by $\ell \geq 1$, to its predecessor is at most $2 \exp \big\{ - S^2 \cdot 2^{-5} ( 2^{1/4} - 1 ) \big\}$
%$$
% 2 \exp \big\{ - S^2 \cdot 2^{-5} ( 2^{1/4} - 1 ) \big\}
%$$
which when, as is presently supposed, $S \geq 2^{5/2 + 2} = 2^{9/2}$ is at most $2 \exp \big\{ - 2^{2 \cdot 2} ( 2^{1/4} - 1 ) \big\}
%$= 0.068512$
\leq 3/4$; so that~(\ref{e.sumexpress}) is at most
$$
 4  \cdot 8 \, \exp \big\{  - 2^{-5} S^2 
     \big\} =  32 \,
 \exp \big\{ - 2^{-5} S^2 \big\} \, .
$$
By~(\ref{e.sumwk}) and the definition of the sequence $\big\{ W^*[\ell]: \ell \geq \N , \ell \geq 1 \big\}$, 
$$
  \sum_{\ell = 1}^\infty W^*[\ell] \geq  \sup_{(u,v) \in [x, x+\e] \times [y,y+\e]} \Big\vert \paradelta\weight_{n;([x,u],0)}^{([y,v],1)} \Big\vert \, .
$$
Thus,
\begin{eqnarray*}
 & &\PP  \, \bigg(  \, \sup_{(u,v) \in [x, x+\e] \times [y,y+\e]} \Big\vert \paradelta\weight_{n;([x,u],0)}^{([y,v],1)} \Big\vert \, \geq \, 2^{1-i_0/2}  (1-2^{-1/4})^{-1}S   \, , \,  \\
 & & \qquad  \qquad  \qquad  \qquad     \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}\big(  2^{-9/4} S   \big) \, \bigg) \,  \leq  \, 
 32 \,
 \exp \big\{ - 2^{-5} S^2 \big\}  \, .
  \end{eqnarray*}
We find that
\begin{eqnarray*}
 & &
  \PP \, \bigg( \, \sup 
 \Big\vert \paradelta\weight_{n;([u_1,u_2],0)}^{([v_1,v_2],1)} \Big\vert  
  \, \geq  \,  2 \cdot
  2^{1-i_0/2}  (1-2^{-1/4})^{-1}S        \, , \,  \\
 & & \qquad  \qquad  \qquad  \qquad     \maxmin_{n;([x-2,x+3],0)}^{([y-2,y+3],1)}\big(   2^{- 9/4} S    \big) \, \bigg) \,  \leq  \,    
   32 \,
 \exp \big\{ - 2^{-5} S^2 \big\}   \, ,
\end{eqnarray*}
where the supremum is over arbitrary $u_1,u_2 \in [x,x+\e]$ and $v_1,v_2 \in [y,y+\e]$.

Applying~(\ref{e.maxminbound}), which is something that requires that $n$ be even, and recalling that $\e \geq 2^{-i_0}$,
\begin{eqnarray*}
 & & 
  \PP \, \Big( \, \sup 
 \Big\vert \paradelta\weight_{n;([u_1,u_2],0)}^{([v_1,v_2],1)} \Big\vert  
  \, \geq \, \e^{1/2}
  2^2  (1-2^{-1/4})^{-1}S   
      \Big) \\
 & \leq &
  \PP \, \Big( \, \sup 
 \Big\vert \paradelta\weight_{n;([u_1,u_2],0)}^{([v_1,v_2],1)} \Big\vert  
  \, \geq \,  
  2^{2-i_0/2}  (1-2^{-1/4})^{-1}S   
      \Big) \\
  &  \leq  &   
   32 \,
 \exp \big\{ - 2^{-5} S^2 \big\}   
   \, + \, 
5^2 \cdot  400 \, C \exp \big\{ - c_1 2^{-9} r_0^{3/2} \big\} \, ,
\end{eqnarray*}
where $r_0 =    2^{- 9/4} S$. 
The right-hand side is at most
\begin{eqnarray*}
  & &  32 \,
 \exp \big\{ - 2^{-5} S^2 \big\}    \, + \, 
10000  \,  C \exp \big\{ -  c_1 2^{-9 - 27/8}   S^{3/2}  \big\} 
 \\
&  \leq & 10032 \, C  \exp \big\{ - c_1 2^{-13}   S^{3/2}   \big\} \, ,
\end{eqnarray*}
the displayed bound due to $S \geq 1$, $C \geq 1$ and $c_1 \leq 1$. 
Setting $R =  2^2(1-2^{-1/4})^{-1}S$ and noting that $2^{-13-3}   (1-2^{-1/4})^{3/2} \geq 2^{-20}$ 
% 2^{15} (1 - 2^{-1/4})^{-3/2} = 516333.\cdots \leq 2^{19}
completes the proof of Theorem~\ref{t.differenceweight}. \qed




\section{Profile regularity for general initial data: proving Theorems~\ref{t.nmodcon} and~\ref{t.wlp.one}}

%We begin this section by developing a preliminary, before giving the proof of  Theorem~\ref{t.wlp.one}. 
For the proofs of these two theorems, it is needed  that, typically, every $f$-rewarded polymer 
that ends in the interval $[-1,1] \times \{ 1 \}$ begins in a compact subset of the $x$-axis $\R \times \{ 0 \}$.
We first introduce a suitable regular fluctuation event $\regfluc$, and then derive a result to this effect, Lemma~\ref{l.regfluc}.

\begin{definition}\label{d.regfluc}
Recall Definition~\ref{d.if} and the notational usage
of  $\rho_{n;(*:f,0)}^{(y,1)}$  from Subsection~\ref{s.polymercross}. Let  $\ovbar\coninit \in (0,\infty)^3$ and $f \in \initcond_{\ovbar\coninit}$.
For $R \geq 0$, define the event 
$\regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R)$
that 
any $f$-rewarded line-to-point polymer $\rho_{n;(*:f,0)}^{(-1,1)}$ that ends at $(-1,1)$ begins at a location $(x,0)$ where $x \geq - (R+1)$; and any such polymer $\rho_{n;(*:f,0)}^{(1,1)}$ that ends at $(1,1)$ begins at $(x,0)$, where $x \leq R+1$.
\end{definition}


% = \Big\{ \rho_{n;(*:f,0)}^{(-1,1)}(0) \geq  -(R+1)  \, , \,   \rho_{n;(*:f,0)}^{(1,1)}(0) \leq   R + 1  \Big\} \, .
%$$
%In fact, the notation used in this definition is slightly abusive. 
%The almost sure uniqueness of $f$-rewarded line-to-point polymers with given endpoint is proved in \cite[Lemma~$4.6(2)$]{Patch}; 
%l.densepolyunique
%if we invoke this result, then naturally the polymers  $\rho_{n;(*:f,0)}^{(-1,1)}$
%and  $\rho_{n;(*:f,0)}^{(1,1)}$ are seen to be well defined almost surely. Preferring as do to avoid invoking polymer uniqueness, our interpretation of the above event is instead that: 

We remark that our $\regfluc$ event entails that any $f$-rewarded line-to-point polymer that ends at a location $(y,1)$ with $y \in [-1,1]$ must begin at a location $(x,0)$, where $\vert x \vert  \leq R+1$. Indeed, were such a polymer $\rho_{n;(*:f,0)}^{(y,1)}$ to begin at $(x,0)$, with $x < -(R+1)$, then, in the event $\regfluc$, it would cross  any example of $\rho_{n;(*:f,0)}^{(-1,1)}$.
The rewiring of these two polymers described in  Subsection~\ref{s.polymercross} would then furnish an example of  $\rho_{n;(x,0)}^{(-1,1)}$ with $x < -(R+1)$, 
% an $f$-rewarded line-to-point polymer ending at $(-1,1)$ that begins at $(x,0)$, where $x < - (R+1)$, 
in conflict with the occurrence of $\regfluc$.
%Thus, such polymer crossing  cannot happen when $\regfluc$ occurs.
 
\begin{lemma}\label{l.regfluc}
Let $n \in \N$, $R > 0$ and $\ovbar\coninit \in (0,\infty)^3$ satisfy 
$$
  n \geq  c^{-18} \max \Big\{  (\coninit_2 + 1)^9 \, , \,   10^{23} \coninit_1^9     \, , \, 3^{9}  \Big\} \, ,  \, R  \geq \max \Big\{ \,    39 \coninit_1  \,  , \, 5  \, , \,   3 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\} \, , 
$$
  and
 $R \leq 6^{-1}c n^{1/9}$.
Then, for any $f \in \initcond_{\ovbar\coninit}$,
$$
 \PP \Big( \neg \, 
\regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R)  \Big) \leq 38 R \rsC       \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2}  \big\}  \, .
$$
\end{lemma}
\noindent{\bf Proof.} The event  $\neg \, 
\regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R)$ equals $A_1 \cup A_2$, where 
 $A_1$ is the event that $y \to \mc{L}^{\downarrow;(-1,1)}_{n;0}(1,y) + f(y)$ achieves its maximum for a value of $y$ that is less than  $-1 - R$,
and  $A_2$ is the event that $y \to \mc{L}^{\downarrow;(1,1)}_{n;0}(1,y) + f(y)$ achieves its maximum for a value of $y$ that is at greater than $1 + R$.

Note the inclusion
\begin{equation}\label{e.twoleft}
\Big\{ \sup_{x \in [-\coninit_2,\coninit_2]}  \big( \mc{L}^{\downarrow;(-1,1)}_{n;0}(1,x) + f(x)  \big) > - R^2/2 \, , \, \sup_{x \leq - 1 -R} \big( \mc{L}^{\downarrow;(-1,1)}_{n;0}(1,x) + f(x) \big)  \leq - R^2/2  \Big\} \, \subseteq \, A_1^c \, .
\end{equation}
Upper bounds on the failure probability of the left-hand events will now be found.
The first event will be shown to be probable because, in view of Definition~\ref{d.if}, the function $f$ is known to assume a not highly negative value somewhere in a compact interval about the origin.
The second event is probable due to the at most linear growth of $f$ far from the origin, combined with decay estimates on the curve $\mc{L}^{\downarrow;(-1,1)}_{n;0}(1,x)$ for large $x$.
These estimates take two forms: when $x$ is large, but less than order $n^{1/9}$, the curve hews to a parabola, in accordance with the No Big Max Proposition~\ref{p.mega}(2), applied to the normalized cousin of the ensemble in question;
when $x$ becomes even larger, the curve may escape the reaches of this parabola, but it continues to decay rapidly, in accordance with collapse near infinity Proposition~\ref{p.mega}(3). 

%, in each case by recalling that
%$\scaledle_{n;0}^{\downarrow;(-1,1)}(\cdot,\cdot) = \mc{L}^{\downarrow;(-1,1)}_{n;0}(\cdot,-1+ \cdot)$, $n \in \N$, is a regular ensemble. 


Since $f \in \initcond_{\ovbar\coninit}$, there exists $x_0 \in [-\coninit_2,\coninit_2]$ such that $f(x_0) \geq - \coninit_3$.
As such, the first left-hand event in~(\ref{e.twoleft}) fails with a probability that satisfies
\begin{eqnarray*}
 & & \PP \Big( \sup_{x \in [-\coninit_2,\coninit_2]}  \big( \mc{L}^{\downarrow;(-1,1)}_{n;0}(1,x) + f(x) \big) \leq - R^2/2   \Big) \leq 
\PP \Big(  \mc{L}^{\downarrow;(-1,1)}_{n;0}(1,x_0)  \leq - R^2/2 + \coninit_3   \Big) \\
 & = & \PP \Big(  \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x_0 + 1)  \leq - R^2/2 + \coninit_3   \Big) \\
& \leq & 
\PP \Big(   \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x_0 + 1)  + 2^{-1/2} (x_0 + 1 )^2  \leq - R^2/2 + 2^{-1/2} (\coninit_2 + 1)^2 +  \coninit_3   \Big) \\
 & \leq & 
\PP \Big(    \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x_0 + 1)  + 2^{-1/2} (x_0 + 1 )^2    \leq - R^2/4   \Big) \leq   \rsC  \exp \big\{ - 2^{-3} \rsc R^3 \big\} \, , 
\end{eqnarray*}
where the penultimate inequality depends on $R^2/4 \geq  2^{-1/2} (\coninit_2 + 1 )^2 +  \coninit_3$.
The final inequality  was  obtained
by applying the one-point lower tail $\rmreg(2)$ with parameter choices ${\bf z} = x_0$
and ${\bf s} = R^2/4$
to the $(c,C)$-regular ensemble  $\scaledle_{n;0}^{\downarrow;(-1,1)}$.
Since the ensemble has $n+1$ curves, this application of $\rmreg(2)$  may be made provided that $\vert x_0 \vert + 1 \leq \rsc n^{1/9}$ and $R^2/4 \in [1,n^{1/3}]$.
The first of these conditions due to $n \geq c^{-9} (\coninit_2 + 1)^9$ alongside 
$\vert x_0 \vert \leq \coninit_2$; the second we assume.

 
 
The failure probability of the second left-hand event in~(\ref{e.twoleft}) may be gauged as follows: since $f(x)$ is at most $\coninit_1 \big( 1 + \vert x \vert \big)$ for any $x \in \R$, we may note that
\begin{eqnarray}
 & &  \PP \Big( \sup_{x \leq - 1 -R} \big( \mc{L}^{\downarrow;(-1,1)}_{n;0}(1,x) + f(x) \big) > - R^2/2 \Big)  \nonumber \\
 & = & \PP \Big( \sup_{x \leq - R} \big( \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x) + f(x-1) \big) > - R^2/2 \Big)  \nonumber \\
  & \leq & \PP \Big( \sup_{x \leq - R} \big(  \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x) + \coninit_1 ( 2 + \vert x \vert ) \big) > - R^2/2 \Big) \, ; \label{e.aboutsplit}
\end{eqnarray}
the latter term may then be bounded above by
$$
 \sum  \PP \Big( \sup_{x \in -  R [2^j,2^{j+1}] }  \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x) > - R^2/2 -   \coninit_1 \big( 2 +    2^{j+1} R  \big) \Big) \, \, + \, E_1 + E_2 \, ,
$$
 where the first sum is indexed by a parameter $j$ that varies over the integer interval $\llbracket 0,k \rrbracket$ where $k \in \N$ to chosen to be  maximal subject to 
 $2^{k+1} R \leq  3^{-1} c  n^{1/9}$. (Such a $k$ exists because we suppose that $2R \leq  3^{-1} c  n^{1/9}$.)
 The term $E_1$ corresponds to part of a dyadic scale that has been sliced in two by the value  $-3^{-1} c  n^{1/9}$: this term is specified by the expression in~(\ref{e.aboutsplit}) when the supremum in the variable $x$ is chosen to be  over  the interval $\big[ - 3^{-1} \rsc  n^{1/9} , - 2^{k+1}R \big]$. The remaining term $E_2$ is a long-range error term corresponding to the interval $\big[ - \xnmac ,  - 3^{-1} \rsc  n^{1/9} \big]$.   Since $R \leq 3^{-1} \rsc  n^{1/9}$, 
 $$
 E_2  \leq  \PP \Big( \sup \Big\{   \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x) + \coninit_1 ( 2 + \vert x \vert ) 
  : x \in \big[ - \xnmac ,  - 3^{-1} \rsc  n^{1/9} \big] \Big\} \geq - 2^{-1} (c/3)^2 n^{2/9}  \Big) \, .
 $$ 
This right-hand side will be bounded above by applying collapse-near-infinity Proposition~\ref{p.mega}(3)
% $\rmreg(4)$ 
to the $(n+1)$-curve $(c,C)$-regular ensemble  $\scaledle_{n;0}^{\downarrow;(-1,1)}$.
We apply  Proposition~\ref{p.mega}(3)
%$\rmreg(4)$ 
 with its parameter ${\bm \eta}$ chosen so that  ${\bm \eta} (n+1)^{1/9} = -  3^{-1} \rsc  n^{1/9}$. In order to make the application, we first claim that the affine function $x \to \ell(x)$
in 
the proposition
%  $\rmreg(4)$ 
lies below the function 
\begin{equation}\label{e.affinefunction}
x \to - 2^{-1} (c/3)^2 n^{2/9} -   \coninit_1 \big( 2 + \vert x \vert    \big) 
\end{equation}  
whenever $x \leq -  3^{-1} \rsc  n^{1/9}$.
 To verify this, note that, when $x = - 3^{-1} \rsc  n^{1/9}$, the assertion  takes the form $\coninit_1 \big( 2 + 3^{-1} \rsc  n^{1/9} \big) \leq \big( 2^{-1/2} - 2^{-5/2} - 2^{-1} \big) (\rsc/3)^2 n^{2/9}$, which holds due to the supposed $1 \leq 3^{-1} \rsc  n^{1/9}$ and $\coninit_1 \leq \big( 2^{-1/2} - 2^{-5/2} - 2^{-1} \big) (\rsc/9)n^{1/9}$. Confirming the claim is then a matter of checking that the gradient of $\ell$ exceeds that of the function~(\ref{e.affinefunction}), which holds due to $\coninit_1 \leq 5 \cdot 2^{3/2} c/3 \cdot n^{1/9}$.
 
We may thus apply  Proposition~\ref{p.mega}(3)
 %$\rmreg(4)$
   when $n + 1  \geq 2^{45/4} \rsc^{-9}$, finding that 
$$
 E_2 \leq 
6C \exp \big\{ -  2^{-15/4} 3^{-3}  \rsc^4 n^{1/3} \big\} \, .
$$ 
 Note that
 \begin{eqnarray}
  & & 
    \PP \Big( \sup_{x \in -  R [2^j,2^{j+1}] }  \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x) > - R^2/2 -   \coninit_1 \big( 2 +    2^{j+1} R  \big) \Big) \label{e.nrphi} \\
  & \leq & 
    \PP \Big( \sup_{x \in -  R [2^j,2^{j+1}] } \big(  \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x)  + 2^{-1/2} x^2 \big)  >  R^2 \big(   2^{2j -1/2}   - 1/2   \big)  -   \coninit_1 \big( 2 +    2^{j+1} R  \big) \Big) \nonumber \\  
  & \leq & 
    \PP \Big( \sup_{x \in -  R [2^j,2^{j+1}] } \big(  \scaledle^{\downarrow;(-1,1)}_{n;0}(1,x)  + 2^{-1/2} x^2 \big)  >  2^{-1} R^2 \big(   2^{2j -1/2}   - 1/2   \big)   \Big) \nonumber \\
       & \leq &  6 C (   2^{j-1} R +1 )     \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{2j - 1/2} -  2^{-1} \big)^{3/2}  \big\} \, , \nonumber
\end{eqnarray}
where in the second inequality we used $R \geq 1 \vee 39 \coninit_1$ in the form 
$$
2^{-1} R^2 \big( 2^{2j - 1/2} - 1/2 \big) \geq \coninit_1 \big( 2 + 2^{j+1}R  \big) \, \, \, \,  
\textrm{for each $j \geq 0$} \, .
$$ 
The final inequality arises from an application of 
%No Big Max 
Proposition~\ref{p.mega}(2) 
%Proposition~\ref{p.nobigmax.gen} 
to the ensemble
$\scaledle_{n;0}^{\downarrow;(-1,1)}$. 
The parameters of the application are set to be 
$$
{\bf y} = - 2^{-1} R \big( 2^j + 2^{j+1} \big) \, , \, {\bf r} = 2^{-1} R \big( 2^{j+1} - 2^j \big) \, \,  \textrm{and} \, \, {\bf t} =  2^{-1} R^2 \big( 2^{2j - 1/2} - 2^{-1} \big) \, .
$$
The application's hypotheses are implied by  
$$
3 \cdot 2^j R  \leq c n^{1/9} \, , \, 
 2^{j+1} R  \leq \rsc n^{1/9} \, , \, 2^{-1} R^2 \big( 2^{2j - 1/2} - 1/2 \big) \in \big[ 2^{7/2} , 2 n^{1/3} \big] \, \textrm{ and }  \, n \geq c^{-18} \, .
$$
  The first three of these conditions are valid when $j \in \llbracket 0,k \rrbracket$ in light of the assumed bound $2^{k+1} R \leq 3^{-1} c n^{1/9}$ (and $c \leq 1$); indeed, they are also valid when $j = k+1$, a fact that we will use momentarily.



 
 The term $E_1$ is bounded above by~(\ref{e.nrphi}) with $j = k+1$, so that the preceding argument shows that
$$
 E_1 \leq 
 6 C (   2^k R +1 )    \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{2k + 3/2} -  2^{-1} \big)^{3/2}  \big\}  \, .
$$  
Thus,
 \begin{eqnarray*}
 & & \PP \Big( \sup_{x \leq - 1 -R} \big( \mc{L}^{\downarrow;(-1,1)}_{n;0}(1,x) + f(x) \big) > - R^2/2 \Big) 
  \\
 & \leq & 6  \rsC \sum_{j=0}^{k+1}  (   2^j R +1 )       \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{2j - 1/2} - 2^{-1} \big)^{3/2}  \big\}
\, + \, 
6C \exp \big\{ -  2^{-15/4} 3^{-3}  \rsc^4 n^{1/3} \big\} \\
 & \leq & 12 R \rsC       \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2}  \big\}
\, + \, 
6C \exp \big\{ -  2^{-15/4} 3^{-3}  \rsc^4 n^{1/3} \big\} \\
 & \leq & 18 R \rsC       \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{ - 1/2} -  2^{-1} \big)^{3/2}  \big\} \, ,
 \end{eqnarray*}  
 where the second inequality used $R \geq (\log 4)^{1/3} 2^2 c^{-3} \big( (2^{3/2} - 2^{-1})^{3/2} - (2^{-1/2} - 2^{-1})^{3/2} \big)^{-1/3}$ in order to ensure that each ratio of consecutive summands in the sum is at most one-half; the third makes use of $1 \leq R \leq  (2^{-1/2} - 2^{-1})^{-1/2} 2^{3/4} 3^{-1} \rsc n^{1/9}$.
 

 Thus,
\begin{eqnarray*}
 \PP \big( A_1 \big) & \leq & 
   \rsC  \exp \big\{ - 2^{-3} \rsc R^3 \big\} 
 \, + \, 18 R \rsC       \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2}  \big\} \\
  & \leq &  19 R \rsC       \exp \big\{ -  2^{-6} \rsc   R^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2}  \big\} \, ,
\end{eqnarray*}
the latter inequality due to $R \geq 1$.
The same argument yields that $\PP \big( A_2 \big)$ satisfies the same upper bound. Combining the estimates completes the proof of Lemma~\ref{l.regfluc}. \qed



Theorem~\ref{t.nmodcon}'s proof will also harness estimates showing that a {\em local weight regularity} event is typical. 
For $x,y \in \R$ and $\e,r > 0$, this event is defined by
$$
\lwr_{n;([x,x+\e],0)}^{([y,y+\e],1)}\big( \e , r  \big) \, = \,
 \left\{ \sup_{\begin{subarray}{c} x_1,x_2 \in [x,x+\e] \\
    y_1, y_2 \in [y,y+\e]  \end{subarray}} \Big\vert \weight_{n;(x_2,0)}^{(y_2,1)}  - \weight_{n;(x_1,0)}^{(y_1,1)}  \Big\vert \, \leq \, r \e^{1/2} \right\} \, . 
$$

The relevant control is offered by Theorem~\ref{t.differenceweight}, except that this theorem addresses parabolically adjusted weight.
The next result is the one we will apply in proving 
Theorem~\ref{t.wlp.one}: the main new hypothesis, $\vert x - y \vert \leq \e^{-1/2}$, limits parabolic curvature.  
%The complement of an event $A$ is denoted~$\neg \, A$.
\begin{corollary}\label{c.ordweight}
Let 
$n \in 2\N$ and  $x,y \in \R$ satisfy 
$n \geq 10^{29} c^{-18}$ and   $\big\vert x - y  \big\vert \leq \e^{-1/2} \wedge 2^{-5/3} 3^{-1} \rsc  n^{1/18}$.
Let  $\e \in (0,2^{-4}]$ and
 $R \in \big[2 \cdot 10^4 \, , \,   10^3 n^{1/18} \big]$.
Then
\begin{equation}\label{e.ordweight}
 \PP \Big( \neg \, \lwr_{n;([x,x+\e],0)}^{([y,y+\e],1)}\big( \e , R  \big)    \Big) \leq 
 10032 \, C  \exp \big\{ - c_1 2^{-21 - 1/2} R^{3/2}     \big\}
 \, .
\end{equation}
\end{corollary}
\noindent{\bf Proof.} Recall that we denote $Q:\R \to \R$, $Q(u) = 2^{-1/2} u^2$. For $u_1,u_2 \in [x,x+\e]$
and $v_1,v_2 \in [y,y+\e]$, note that, since $\vert x - y \vert \leq \e^{-1/2}$ and $\e \leq 1$, 
$$
\big\vert Q(v_2 - u_2) - Q(v_1 - u_1) \big\vert \leq 
2\e Q' \big( \vert x - y \vert + \e \big) = 2\e \cdot 2^{1/2}  \big( \vert x - y \vert + \e \big) \leq 2^{5/2} \e^{1/2} \, .
$$
Thus, when $R \geq 2 \cdot 2^{5/2}$, the left-hand side of~(\ref{e.ordweight}) is at most~(\ref{e.differenceweight}) with ${\bf R} = R/2$. The corollary thus follows from Theorem~\ref{t.differenceweight}. \qed





\subsection{Deriving Theorem~\ref{t.nmodcon}}


 
% \noindent{\bf Proof of Theorem~\ref{t.wlp.one}.} 

For  $f \in  \initcond_{\ovbar\coninit}$, $\e  \in (0,2)$ and $\rho > 0$, define   the equicontinuity event  
 $$
 \mathsf{EquiCty}_{n;(*:f,0)}^{[-1,1]}\big( \rho , \e \big)
 = \Big\{ \, \omega_{[-1,1],\e}\big( y \to  \weight_{n;(*:f,0)}^{(y,1)} \big) <  \rho \, \Big\} \, ,
$$ 
where the modulus of continuity of a function $h: [-1,1] \to \R$ is denoted by
$$
    \omega_{[-1,1],\e}(h) \,  = \, \sup \Big\{ \, \big\vert h(x) - h(y) \big\vert : x,y \in [-1,1] \, , \,  \vert x - y \vert \leq \e \, \Big\} \, .
$$
Here is an equicontinuity claim.
\begin{lemma}\label{l.equicty}
Let $\ovbar\coninit \in (0,\infty)^3$. Set
$$
\Ctbs = 2^{16} c_1^{-2/3} \, \, \, \, \textrm{and} \, \, \, \,  \Ctbd = \max \Big\{ \,    39 \coninit_1  \,  , \,  12 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\} \, ,
$$
and define the function  $g(\e) = 2 \Ctbs \, \e^{1/2} \big( \log \e^{-1} \big)^{2/3}$. Let $\e > 0$ satisfy 
$\e \leq \Ctbd^{-6} \exp \big\{ - 2^{3/2} 10^6 \big\} C^{-2}$.
When  $n \in 2\N$ verifies
$n \geq 10^{29} c^{-18} \Ctbd^{18} \Ctbs^{18} \big( \log \e^{-1} \big)^{12}$, we have that, for   $f \in \initcond_{\ovbar\coninit}$, 
\begin{equation}\label{e.ece}
 \PP \Big( \neg \,   \mathsf{EquiCty}_{n;(*:f,0)}^{[-1,1]}\big( g(\e) , \e \big)  \Big) \leq  \e \, .
\end{equation}
\end{lemma}
\noindent{\bf Proof.} We first argue that, whenever $R \geq 1$,  
\begin{eqnarray}
 & & \regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R-1) \cap \bigcap_{u \in \e \Z \cap [-R,R], 
 v \in \e \Z \cap [-1,1]} \lwr_{n;([u,u+\e],0)}^{([v,v+\e],1)} \Big( \e , \Ctbs \big( \log \e^{-1} \big)^{2/3}  \Big)  \nonumber \\
 & \subseteq & \mathsf{EquiCty}_{n;(*:f,0)}^{[-1,1]}\big( g(\e) , \e \big)  \, .   \label{e.equictyinc}
\end{eqnarray}
 To verify this inclusion, suppose that $\regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R-1)$ occurs,
and consider $y \in [-1,1]$. By the remark made 
after Definition~\ref{d.regfluc}, all $f$-rewarded line-to-point polymers that abut at time one on $[-1,1]$
must begin at time zero somewhere on $[-R,R]$, (where here of course the present parameter value $R-1$ is involved). Thus, 
the quantity
$\weight_{n;(*:f,0)}^{(y,1)}$ is seen to equal $\weight_{n;(x,0)}^{(y,1)} + f(x)$ for some $x \in [-R,R]$.
Note that the event $\lwr_{n;(x,0)}^{([y,y+\e],1)} \Big( \e , 2\Ctbs \big( \log \e^{-1} \big)^{2/3}  \Big)$ occurs when the intersection of the $\lwr$ events displayed above occurs;
in this circumstance, we thus see that, for any $\eta \in (0,\e)$, 
$\weight_{n;(x,0)}^{(y + \eta,1)} \geq  \weight_{n;(x,0)}^{(y,1)}  + f(x) \, - \,  \e^{1/2} \cdot 2\Ctbs \big( \log \e^{-1} \big)^{2/3}$
and thus 
$\weight_{n;(*:f,0)}^{(y + \eta,1)} \geq  \weight_{n;(*:f,0)}^{(y,1)} \, - \,  \e^{1/2} \cdot 2\Ctbs \big( \log \e^{-1} \big)^{2/3}$.  Provided that we further suppose that $y + \eta \leq 1 $, the inequality with the roles of $y$ and $y+\eta$ reversed is similarly obtained, so that
$$
 \Big\vert \weight_{n;(*:f,0)}^{(y + \eta,1)} -  \weight_{n;(*:f,0)}^{(y,1)}   \Big\vert \, \leq \,  \e^{1/2} \cdot 2\Ctbs \big( \log \e^{-1} \big)^{2/3} \, .
$$
Thus,~(\ref{e.equictyinc}) is obtained. Verifying the equicontinuity claim is now a matter of arguing that the $\regfluc$ and the intersection of the $\lwr$
events on the left-hand side of~(\ref{e.equictyinc}) both have probability at least $1 - \e/2$. 

Treating the intersection $\lwr$ event first, we now set the value of $R$ equal to $1 + \Ctbd \big( \log \e^{-1} \big)^{1/3}$ where $\Ctbd$ is a further positive parameter on which we will impose certain lower bounds.

Let $u,v \in \R$ satisfying $\vert u \vert \leq R$ and $\vert v \vert \leq 1$ be given.  We apply Corollary~\ref{c.ordweight} with ${\bf x} = u$, ${\bf y} = v$, ${\bm \e} = \e$ and  ${\bf R} = \Ctbs \big( \log \e^{-1} \big)^{2/3}$ to find that
$$
 \PP \Big( \neg \,  \lwr_{n;([u,u+\e],0)}^{([v,v+\e],1)} \Big( \e , \Ctbs \big( \log \e^{-1} \big)^{2/3}  \Big) \leq
    10032 \, C  \e^{c_1 2^{-21 - 1/2} \Ctbs^{3/2}    } \, .
 $$
 Since $\vert u \vert \leq R = 1 + \Ctbd \big( \log \e^{-1} \big)^{1/3}$ and $\vert v \vert \leq 1$, this application may be made provided that $\e \in (0,2^{-4}]$,  
$n \geq 10^{29} c^{-18}$,  $\Ctbd \big( \log \e^{-1} \big)^{1/3} + 2  \leq \e^{-1/2} \wedge 2^{-5/3} 3^{-1} \rsc  n^{1/18}$, and 
$\Ctbs \big( \log \e^{-1} \big)^{2/3} \in \big[ 2 \cdot 10^4 \, , \,   10^3 n^{1/18} \big]$. Thus, it may be made for $\e > 0$ sufficiently small, and with $n$ exceeding an $\e$-determined level whose order is $\big( \log \e^{-1} \big)^{12}$. Note also  that this application uses $n \in 2\N$.
 
 Allowing $u$ and $v$ to vary over $\e \Z \cap [-R,R]$ and $\e \Z \cap [-1,1]$, the probability that any of the $\lwr$ events so indexed fails is seen to be at most
 \begin{equation}\label{e.atmostebytwo}
    \big( 2 R \e^{-1} + 1 \big)    \big( 2 \e^{-1} + 1  \big)  \cdot  10032 \, C  \e^{c_1 2^{-21 - 1/2} \Ctbs^{3/2}    }
 \end{equation}
 and thus at most $\e/2$ since $\Ctbs$ satisfies $c_1 2^{-21 - 1/2} \Ctbs^{3/2} - 2 > 1$, and $\e > 0$ is small enough.  
 
Lemma~\ref{l.regfluc} shows that the failure probability of the $\regfluc$ event is governed by a similar bound. Indeed, setting ${\bf R} = R - 1$ in the lemma, we see that
\begin{equation}\label{e.rhsub}
 \PP \Big( \neg \, 
\regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R-1)  \Big) \leq 38 (R-1) \rsC       \exp \big\{ -  2^{-6} \rsc   (R - 1)^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2}  \big\}  \, ,
\end{equation}
provided that 
$n \geq  c^{-18} \max \big\{  (\coninit_2 + 1)^9 \, , \,   10^{23} \coninit_1^9     \, , \, 3^{9}  \big\}$,
 $$
    R  \geq 1 + \max \Big\{ \,    39 \coninit_1  \,  , \, 5  \, , \,   3 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\} \, , 
  $$
  and
 $R - 1 \leq 6^{-1}c n^{1/9}$.
 
 Recalling that $R = 1 + \Ctbd \big( \log \e^{-1} \big)^{1/3}$, we see that, in essence since $2^{-6} \rsc   \Ctbd^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2}$ exceeds one, and 
 for $\e > 0$ small enough, 
\begin{equation}\label{e.regflucbound} 
 \PP \Big( \neg \, 
\regfluc_{n;(*:f,0)}^{( \{-1,1 \}, 1 )}(R)  \Big) \,  \leq  \, \e/2 \, .
\end{equation}
 We infer then from~(\ref{e.equictyinc}) that Lemma~\ref{l.equicty} holds. \qed

\noindent{\bf Proof of Theorem~\ref{t.nmodcon}.}
Set $X_n:[-1,1] \to \R$, $X_n(y) = \weight_{n;(*:f,0)}^{(y,1)}$, and let $g:(0,1) \to (0,\infty)$ be specified via Lemma~\ref{l.equicty}. Setting $c' = 10^{-29/12} c^{-3/2} \Ctbd^{3/2} \Ctbs^{3/2}$,
this lemma may be used to show that 
\begin{equation}\label{e.omegarho}
 \PP \Big(  \omega_{[-1,1],\rho}\big( y \to  X_n(y) \big) \leq g(2\rho)    \, \, \,  \forall \, \rho \in \big( e^{-c' n^{1/12}} ,  2^{-j}  \big)  \Big) \geq 1 - 2^{1-j} 
\end{equation}
whenever $j \in \N$ satisfies $2^{-j} \leq \e_0$ where $\e_0 = \Ctbd^{-6} \exp \big\{ - 2^{3/2} 10^6 \big\} C^{-2}$ (which is the upper bound on $\e$ in Lemma~\ref{l.equicty}). Indeed, this bound is obtained by noting that  $g$ is increasing on the interval $\big( 0 , e^{-4/3} \big)$ and $\e_0 \leq e^{-4/3}$, and applying 
Lemma~\ref{l.equicty} on decreasing dyadic scales ${\bm \e} = 2^{-j}, 2^{-j- 1}, \cdots$ for as long as the lemma's hypothesis $\e \geq \exp \big\{ - c' n^{1/12} \big\}$ permits.

Define the random variable $\zeta = \zeta_n \in \big[  e^{-c' n^{1/12}} , \e_0 \big]$ to be the
maximal value on this interval such that,  for all $\rho \in \big(   e^{-c' n^{1/12}} , \zeta)$, 
$\omega_{[-1,1],\rho} \big( y \to  X_n(y) \big) \leq g(2\rho)$; if no such value exists, set $\zeta = 0$. 
We see from~(\ref{e.omegarho}) that
%$\zeta$ is almost surely positive, and indeed that 
$\PP \big( \zeta \leq s \big) \leq 4s$ for $s \in (  e^{-c' n^{1/12}} ,\e_0]$. 

We now fix $y,z \in [-1,1]$ with $y +  2 e^{-c' n^{1/12}} < z \leq y + e^{-1}$. 
%and suppose in the first instance that 
Define $K \in \N$ to be the random integer $\lceil (z-y) \zeta^{-1} \rceil$.
Setting $h = (z-y)K^{-1}$, it is readily verified that $h \in (e^{-c' n^{1/12}},\zeta]$, and so we find 
\begin{eqnarray}
 \big\vert X_n(z) - X_n(y) \big\vert & \leq & \sum_{k=0}^{K-1} \big\vert X_n\big( y + (k+1)h \big) - X_n\big(y + k h \big) \big\vert \leq K g(2h) \nonumber
  \\
  & \leq & 2^{3/2} K \Ctbs h^{1/2} \big( \log h^{-1} \big)^{2/3} \, . \label{e.khbound}
\end{eqnarray} 
In the case that $K=1$, we may now apply  $h \leq \zeta \leq e^{-4/3}$ in order to learn that
$\big\vert X_n(z) - X_n(y) \big\vert$ is at most  $2^{3/2} K \Ctbs \zeta^{1/2} \big( \log \zeta^{-1} \big)^{2/3}$.

Now suppose that $K \geq 2$. Distinctive to this case is the bound  $h \geq \zeta/2$, which follows from $(z-y) \zeta^{-1} > 1$.
Before we use this bound, note that,
since $K h = (z-y)$, the quantity~(\ref{e.khbound})  equals 
$$
 2^{3/2} \Ctbs (z-y)^{1/2} h^{-1/2} \bigg( \frac{\log h^{-1}}{\log (z-y)^{-1}} \bigg)^{2/3} (z-y)^{1/2} \big( \log (z-y)^{-1} \big)^{2/3}
$$
and thus, in view of $z-y \leq e^{-1}$ and $\zeta/2 \leq h  \leq e^{-4/3}$, may be bounded above by
\begin{eqnarray*}
 & & 2^{3/2} \Ctbs h^{-1/2} \big( \log h^{-1} \big)^{2/3} (z-y)^{1/2} \big( \log (z-y)^{-1} \big)^{2/3} \\
 & \leq & 
 2^{3/2} \Ctbs (\zeta/2)^{-1/2} \big( \log (\zeta/2)^{-1} \big)^{2/3} (z-y)^{1/2} \big( \log (z-y)^{-1} \big)^{2/3} \, .
\end{eqnarray*}
Further using $\zeta \leq 1/2$, we find that 
 $2^{3/2 + 1/2 + 2/3} \Ctbs \zeta^{-1/2} \big( \log   \zeta^{-1} \big)^{2/3} (z-y)^{1/2} \big( \log (z-y)^{-1} \big)^{2/3}$
serves as an upper bound on  
 $\big\vert X_n(z) - X_n(y) \big\vert$ in the case that $K \geq 2$.
 Whether this case applies, or rather $K=1$, we see that  
 the random variable
$$
 S_n : = \sup \bigg\{ \big\vert X_n(z) - X_n(y) \big\vert (z-y)^{-1/2} \big( \log (z-y)^{-1} \big)^{-2/3} : -1 \leq y,z \leq 1  \, , \,  2 e^{-c' n^{1/12}} < z - y \leq e^{-1} \bigg\}
$$
is bounded above by  $2^{8/3} \Ctbs \zeta^{-1/2} \big( \log \zeta^{-1} \big)^{2/3}$. 
Recalling that  $\PP \big( \zeta \leq s \big) \leq 4s$ for $s \in ( e^{-c' n^{1/12}} , \e_0]$,
we see that, for such~$s$, 
$$
\PP \Big(  S_n \geq 2^{3/2} \Ctbs  s^{-1/2} \big( \log s^{-1} \big)^{2/3} \Big) \leq 4s \, .
$$
Set $r = 2^{8/3} \Ctbs  s^{-1/2} \big( \log s^{-1} \big)^{2/3}$.
%we use $\Ctbs \geq 1$ in finding that
%$s \leq 2^{20/3} \Ctbs^2 r^{-2} \big( \log r \big)^{4/3}$.
We {\em claim} that  $r \geq 2^{10/3} \Ctbs e$ implies that $s \leq d^{-2} r^{-2} \big( \log r \big)^{4/3}$. Indeed, setting
 $h = s^{-1/2}$ and $K = d r$, with $d = 2^{-10/3} \Ctbs^{-1}$, we have $K =  h ( \log h )^{2/3}$. We also have $K \geq e$, and this implies $h \leq K$, whence $h \geq K (\log K)^{-2/3}$ and also $s \leq d^{-2} r^{-2} \big( \log (dr) \big)^{4/3}$. Since $d \leq 1$, we have our claim. Furthermore, the condition that $s \leq \e_0$ is ensured when $d^{-2} r^2 (\log r)^{4/3} \leq \e_0$, and two omitted lines of working imply that $r \geq 2^{1/2} d^{-3/2} \e_0^{-3/4}$ is enough to ensure the latter.
 
 
 That is, setting $r_0 = r_0(\ovbar\coninit) = 2^{10/3} \Ctbs e \vee 2^{11/2} \Ctbs^{3/2} \Ctbd^{9/2} C^{3/2} \exp \big\{ 3 \cdot 2^{-1/2} \cdot 10^6 \big\}$, we have found that $r \geq r_0$ implies that
$$
\PP \big(  S_n \geq r  \big) \leq 2^{26/3} \Ctbs^2 r^{-2} \big( \log r \big)^{4/3} \vee 4  e^{-c' n^{1/12}}  \, .
$$
Noting that $2^{26/3} \Ctbs^2 \leq 2^{41} c_1^{-4/3}$, and $c_1 = 2^{-5/2} c \wedge 8^{-1} \geq 2^{-3}c$ in view of $c \geq 1$,
completes the proof of Theorem~\ref{t.nmodcon}. \qed



% To prove Theorem~\ref{t.wlp.one}(1) and~(2), note that,  by Arzela-Ascoli and Prokhorov, it is enough to argue that,
 %for any $\e > 0$, there exists $K > 0$, $n_0 \in \N$ and a function $g: [0,2) \to (0,1)$ with $g(\delta) \to 0$ as $\delta \searrow 0$ such that, for all $n \geq n_0$ and $f \in \initcond_{\ovbar\coninit}$,
%$$
%\PP \Big( \mathsf{UnifBd}_{n;(*:f,0)}^{[-1,1]}(K) \cap \mathsf{EquiCty}_{n;(*:f,0)}^{[-1,1]}(g) \Big)  \geq 1 - \e
%$$

\subsection{Deriving Theorem~\ref{t.wlp.one}}

$\empty$

\noindent{\bf Proof of Theorem~\ref{t.wlp.one}(1).} The result is Lemma~\ref{l.basic}(3).


\noindent{\bf Proof of Theorem~\ref{t.wlp.one}(2).} 
Let $f \in \initcond_{\ovbar\coninit}$ be given. From~\cite[Theorem~$8.2$]{Billingsley}, the sequence of probability measures $\big\{ \nu_{n;(*:f,0)}^{([-1,1],1)} : n \in \N \big\}$  is tight if, first, the one-point distribution is tight, in the sense that for all $\eta > 0$, there exists $K > 0$ such that, 
 for all $n \in \N$, 
\begin{equation}\label{e.onepoint}
%$$
\PP \Big( \, \big\vert \weight_{n;(*:f,0)}^{(0,1)} \big\vert \leq K \, \Big) \geq 1 - \eta \, ;
%$$
\end{equation}
and, second, if, for each $\e > 0$
and
$\eta > 0$,
there exist 
$\rho > 0$ and $n_0 \in \N$
such that, for $n \geq n_0$,
\begin{equation}\label{e.equictyclaim}
%$$
\PP \Big( \mathsf{EquiCty}_{n;(*:f,0)}^{[-1,1]}\big( \rho , \e \big) \Big) \geq 1 - \eta \, .
%$$
\end{equation}
Moreover, 
%by a minor variation on the proof of~\cite[Theorem~$8.2$]{Billingsley}, 
if a choice of $n_0 = n_0(\e,\eta)$ such that~(\ref{e.onepoint}) and~(\ref{e.equictyclaim}) hold whenever $n \geq n_0$ may be made independently of  $f \in \initcond_{\ovbar\coninit}$, then the collection of measures
$\big\{ \nu_{n;(*:f,0)}^{([-1,1],1)}: n \in \N \big\}$ is $\initcond_{\ovbar\coninit}$-uniformly tight, where  the indexing variable is $f \in  \initcond_{\ovbar\coninit}$.
A little work is needed to use the proof of~\cite[Theorem~$8.2$]{Billingsley} to establish this last assertion.
We need to understand that, if the two bounds~(\ref{e.onepoint}) and~(\ref{e.equictyclaim}) hold whenever $n \geq n_0(\e,\eta)$, we are able to assert that the same bounds also hold whenever $n \geq n_0$ where the new selection of $n_0$ is made merely as a function of $\ovbar\coninit$. For this, what is needed is that, for a {\em given} value of $n$ that exceeds an $\ovbar\coninit$-determined level, these two bounds may be asserted with the parameters $K$ and $\eta$ being selected independently of $f \in \initcond_{\ovbar\coninit}$. We omit this fact's proof, but mention that the essence of the derivation lies in the argument for Lemma~\ref{l.basic}(1) and~(3).
  
  
  


%Even 
Theorem~\ref{t.wlp.one}(2)
thus follows from equicontinuity Lemma~\ref{l.equicty} and the next {\em uniform boundedness}~lemma. \qed
%(The above claim clearly implies even Theorem~\ref{t.wlp.one}(1).)



\vspace{-2mm}
 Let  $f \in  \initcond_{\ovbar\coninit}$. For $K > 0$, define the 
 %uniform boundedness 
 event  
 $$
  \mathsf{UnifBd}_{n;(*:f,0)}^{[-1,1]}(K) \, = \, \Big\{ \sup_{y \in [-1,1]} \big\vert  \weight_{n;(*:f,0)}^{(y,1)} \big\vert \leq K \Big\} \, .
 $$ 
\begin{lemma}\label{l.unifbd}
For any $\e > 0$ small enough, there exists $K = K(\e,\ovbar\coninit) > 0$ such that, for all $f \in \initcond_{\ovbar\coninit}$,
$$
 \PP \Big( \neg \,    \mathsf{UnifBd}_{n;(*:f,0)}^{[-1,1]}(K) \Big) \leq \e 
$$
whenever $n$ exceeds a certain constant multiple of $\big( \log \e^{-1} \big)^{12}$.
\end{lemma}
\vspace{-2mm}
\noindent{\bf Proof.}
We begin by arguing that, 
for $R \geq \coninit_2$,
\begin{eqnarray}
 & & \regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R-1) \cap  \maxmin_{n;([-R,R],0)}^{([-1,1],1)}( R^2 ) \label{e.unifbdinc} \\
 & \subseteq &  \mathsf{UnifBd}_{n;(*:f,0)}^{[-1,1]}\Big( R^2 + 2^{-1/2} (R+1)^2 + \max \{ \coninit_3 , \coninit_1(1 + R) \} \Big) \, . \nonumber
\end{eqnarray}
Indeed, it was noted after~(\ref{e.equictyinc})  that $\weight_{n;(*:f,0)}^{(y,1)} = \sup \big\{ \weight_{n;(x,0)}^{(y,1)} + f(x) : x \in [-R,R] \big\}$
when the event $\regfluc_{n;(*:f,0)}^{\big( \{-1,1 \}, 1 \big)}(R-1)$ occurs;  since $R \geq \coninit_2$, $- \coninit_3 \leq \sup_{\vert x \vert \leq R} f(x)  \leq  \coninit_1(1 + R)$.
On the event $\maxmin_{n;([-R,R],0)}^{([-1,1],1)}( R^2 )$,  $\big\vert \weight_{n;(x,0)}^{(y,1)} \big\vert \leq R^2 + 2^{-1/2} (R+1)^2$ whenever $\vert x \vert \leq R$ and $\vert y \vert \leq 1$; this proves~(\ref{e.unifbdinc}).

Set $R = 1 + \Ctbd \big( \log \e^{-1} \big)^{1/3}$ as in the proof of Lemma~\ref{l.equicty}.
%We will shortly exercise the right to increase the value of the positive constant~$\Ctbd$. 
 We now apply 
Corollary~\ref{c.maxminweight}   with parameter settings ${\bf t_1} = 0$, ${\bf t_2} = 1$, ${\bf x} = -R$, ${\bf y} = -1$, ${\bf a} = \lceil 2R \rceil$, ${\bf b} = 2$ and ${\bf r} = R^2$ to find that 
$$
\PP \Big( \neg \, \maxmin_{n;([-R,R],0)}^{([-1,1],1)}( R^2 ) \Big) \leq  (2R+1) \cdot 400 C \exp \big\{ - \rsc_1 2^{-9} R^3 \big\}
$$
provided that $n$ exceeds an $\e$-determined level (which is of the order $\big( \log \e^{-1} \big)^{12}$, in order that the hypothesis ${\bf r} \leq 4 n^{1/{18}}$ be satisfied).   This upper bound is at most $\e/2$ for small enough $\e > 0$,
since $\rsc_1 2^{-9} \Ctbd^3 > 1$ holds in view of $\Ctbd \geq 12c^{-3}$, $c_1 \geq 2^{-5/2}c$ and $c \leq 1/2$.

  
Set $K = R^2 + 2^{-1/2} (R+1)^2 + \max \{ \coninit_3 , \coninit_1(1 + R) \}$. From~(\ref{e.unifbdinc}), we combine the last inference with~(\ref{e.regflucbound}) to obtain Lemma~\ref{l.unifbd}. \qed
%the uniform boundedness claim holds, and so complete the proof of even Theorem~\ref{t.wlp.one}(2).


\noindent{\bf Proof of Theorem~\ref{t.wlp.one}(3).}
 Let $\nu \in \wlp_{\ovbar{\coninit}}$. For a sequence $\big\{ f_n : n\in \N \big\}$ of elements of  $\initcond_{\ovbar\coninit}$, set $\nu_n = \nu_{n;(*:f_n,0)}^{([-1,1],1)}$. Then, for some such sequence of functions, and along a certain even subsequence of~$n$, the sequence $\nu_n$ converges to $\nu$ weakly.
 
 


%For $\ovbar\coninit \in (0,\infty)^3$, some  $c',r_0 = c'(\ovbar\coninit),r_0(\ovbar\coninit) > 0$ and all 
%$f \in \initcond_{\ovbar\coninit}$,~$n~\in~2\N$~and~$r~\geq~r_0$,

Recall that $r$ is a positive parameter that is at least $r_0$. For $\e > 0$ and $m \in \N$, the set 
$$
 \left\{ \, h \in \mc{C}: \sup_{\begin{subarray}{c} y,z \in [-1,1], \\
    2\exp \{-c' m^{1/12} \} < z - y < e^{-1}  \end{subarray}} \frac{\big\vert \, h(z) - h(y) \, \big\vert}{(z-y)^{1/2} \big( \log (z-y)^{-1} \big)^{2/3}} \, > \, r - \e \, \right\}  
$$
is open in $\mc{C}$. Recall the notation that $X$  is $\nu$-distributed. Applying the Portmanteau theorem along the convergent subsequence of $\nu_n$, we learn that 
$$
 \nu 
 \left( \,  \sup_{\begin{subarray}{c} y,z \in [-1,1], \\
    2\exp \{-c' m^{1/12} \} < z - y < e^{-1}  \end{subarray}} \frac{\big\vert \, X(z) - X(y) \, \big\vert}{(z-y)^{1/2} \big( \log (z-y)^{-1} \big)^{2/3}} \, > \, r - \e \, \right)  
$$
is at most the limit infimum along the concerned subsequence of $n \in \N$  of the left-hand side of~(\ref{e.nmodcon}) when $m$ replaces $n$ in the subscripted lower bound on $z - y$; $f_n$ replaces $f$; and $> r - \e$ replaces $\geq r$. 
We then apply Theorem~\ref{t.nmodcon}, consider $m \to \infty$ and then $\e \searrow 0$ to obtain Theorem~\ref{t.wlp.one}(3). \qed  
  

 

\bibliographystyle{plain}

\bibliography{airy}


%\end{document}    
 
\appendix

\section{Calculational derivations}

We mentioned in Subsection~\ref{s.calcderexplain} that, during the proofs of our results, we have taken care to record the hypotheses needed in order to invoke results needed along the way.
Clearly, in each proof, it is necessary that the hypotheses of the result being proved apply all the conditions so invoked. 
What we have not done during the course of the proofs is to justify that this is the case. 
In this appendix, we provide these justifications, which we call {\em calculational derivations}.



There are five results where this work needs to be done. We present our working for the results in the order in which the proofs have appeared. Thus, we treat in the consecutive sections of this appendix 
Proposition~\ref{p.maxminweight}, Proposition~\ref{p.dyadic}, Theorem~\ref{t.differenceweight}, Lemma~\ref{l.regfluc} and Lemma~\ref{l.equicty}.

In the typical calculational derivation, we begin by recording all of the conditions invoked during the proof of the result in question. Some analysis then follows, sometimes involving introducing further conditions, whose role is to imply several of the needed hyptoheses, with a view to producing a simplified list of conditions that imply the complete list of needed hypotheses. Sometimes after a little further simplification, we produce a final list of conditions, which coincide with the hypotheses set of the result in question. 

There are a few notational devices that we will use in the derivations. Conditions are given square bracketed names such as $[1]$ or $[n4]$, shown on the left. 
These names may be recycled from one calculational derivation to the next.
The notation $[1,n4]$ means `conditions $[1]$ and $[n4]$'. Implication is denoted by a right arrow, so that $[1,n4] \to [r3]$ means `conditions $[1]$ and $[n4]$ imply condition $[r3]$'.  

The notation $[n2,4,5]$ is used as a shorthand for $[n2,n4,n5]$. This meaning would be ambiguous, were there named conditions $[4]$ or $[5]$, but we employ this condition only when the meaning is unambiguous.

\subsection{Proposition~\ref{p.maxminweight}: derivation}

The proof of this result consists of the derivation of~(\ref{e.weightuvinfimum}) and that of~(\ref{e.weightuvsupremum}).
The calculational derivation of the proposition treats the two pieces separately.
In the first case, we follow the plan described above: recording of all needed hypotheses  is followed by an analysis that reveals that all of these conditions are implied by the hypotheses of 
Proposition~\ref{p.maxminweight}. In the second, we split the derivation again into two pieces, and analyse them separately.
 

\noindent{\bf In the derivation of~(\ref{e.weightuvinfimum})}, the following assertions are used:
$$
[1] \, \, n/2 \geq  (c/3)^{-1/18} \vee 6^{36}
$$
$$
[2] \, \, 2^{-1/3} \leq (n/2)^{1/18}
$$
$$
[3] \, \, 2^{-5/3} t = s \in [ 2^{3/2},  2 (n/2)^{1/18} ]
$$
and 
$$
[4] \, \, 2^{-1/3} ( \vert x - y \vert + 1  ) \leq 2^{-1} c (n/2)^{1/18}
$$

Thus, $[1,2,3,4]$ is our list of needed conditions. Turning to analyse them, we first note
  that $[1] \to [2]$.
Introducing a further condition
$$
[5] \, \, n \geq 10^{29} \vee 2 (c/3)^{-18} \, ,
$$
we have $[5] \to [1]$. 

[3] is equivalent to 
$$
  t \in [ 2^{19/6} , 2^{47/18} n^{1/18} ]
$$
and thus is implied by
$$
[6] \, \, t \in [33,  2^{47/18}  n^{1/18} ]
$$
since $33 \geq 2^{19/6}$.

[4] is equivalent to
$$
 \vert x - y \vert + 1 \leq 2^{-13/18} c n^{1/18}
$$
Since [5] entails that $1 \leq 3^{-1} 2^{-1/18} c n^{1/18}$, [4] is implied by [5] and
$$
 \vert x - y \vert \leq (  2^{-13/18} - 3^{-1} 2^{-1/18} ) c n^{1/18}
$$
Since $2^{-13/18} - 3^{-1} 2^{-1/18} = 0.28542 \cdots \geq 0.20998 \cdots = 3^{-1} 2^{-2/3}$, we see that, if we write
$$
[7] \, \,  
 \vert x - y \vert \leq  3^{-1} 2^{-2/3} c n^{1/18}
$$
then $[5,7] \to [4]$.

In summary, $[5,6,7] \to [1,2,3,4]$. Since $[5,6,7]$ are hypothesised in Proposition~\ref{p.maxminweight}, we see that the hypotheses are adequate for deriving~(\ref{e.weightuvinfimum}).



\noindent{\bf Derivation of~(\ref{e.weightuvsupremum}).}

This derivation involves a use of  Proposition~\ref{p.mega}(1) and a use of  Proposition~\ref{p.mega}(2). 
We structure the calculational derivational of~(\ref{e.weightuvsupremum}) by analysing each of these applications in turn.

In the application of Proposition~\ref{p.mega}(1),
% Proposition~\ref{p.strongothercurves} 
the bounds needed are
 $$ 
 n  \geq 1 
  \vee  (c/3)^{-18} \vee  6^{36}
  $$ 
  $$
  1/2 \leq n^{1/18}
  $$
   $$
   t/2 \in \big[ 2^{3/2} \, , \, 2n^{1/18} \big]
   $$
   $$
   \big\vert x - z + 1/2 \big\vert =  \big\vert y - x + 1/2 \big\vert
 \leq \rsc/2 \cdot   n^{1/18}
 $$
 The first two follow directly from the hypotheses.
 The third follows from the hypothesised $t \in [33,4n^{1/18}]$. For the fourth, 
 $$
 [a] \, \,  \vert x - y \vert + 1/2 \leq 2^{-1} c n^{1/18}
 $$
 suffices. By hypothesis, we know $n/2 \geq (c/3)^{-18}$
 or equivalently $c/6 \cdot 2^{-1/18} n^{1/18} \geq 1/2$.
To show $[a]$, it thus suffices to show that
$$
 \vert x - y \vert \leq c \big( 2^{-1} - 6^{-1} 2^{-1/18} \big) n^{1/18}
$$ 
Since we suppose that the left-hand side is at most $c \cdot 3^{-1} 2^{-2/3} n^{1/18}$, this inequality holds in view of $3^{-1} 2^{-2/3} \leq 2^{-1} - 6^{-1} 2^{-1/18}$.


In the application of Proposition~\ref{p.mega}(2), 
%Proposition~\ref{p.nobigmax.gen}
we need
$$
[b] \, \, \big\vert 2^{-2/3} (y - z) + 2^{-5/3} \big\vert =  
\big\vert 2^{1/3} (y - x) + 2^{-5/3} \big\vert  \leq c/2 \cdot (2n)^{1/9}
$$
$$
[c] \, \,  2^{-5/3} \leq \rsc/4 \cdot (2n)^{1/9} 
$$
$$
[d] \, \, 2^{-4/3}t - 5 \cdot 2^{-11/6} \in \big[ 2^{7/2} , 2 (2n)^{1/3} \big]
$$
$$
[e] \, \, 2 n \geq c^{-18}
$$

Note that $[b]$ is equivalent to
$$
[f] \, \, \vert x - y \vert + 4^{-1} \leq 2^{-11/9} c n^{1/9}
$$
When $\vert y - x \vert \geq 1$, $[f]$ is implied by squaring $[a]$ and using $c \leq 1$. When  $\vert y - x \vert \leq 1$, $[f]$ is implied by $5^9 2^{-7} c^{-9} \leq n$, a condition which follows from the hypothesised $n \geq 2 (c/3)^{-18}$ and $c \leq 1$.

$[c]$ is equivalent to $n \geq 4 c^{-9}$ which follows by the hypothesised lower bound on $n$ as well as $c \leq 1$. 

$[d]$ follows from the hypothesised $t \in [33,4n^{1/18}]$ via
$$
  2^{-4/3} \cdot 33  - 5 \cdot 2^{-11/6} =  11.69 \cdots \geq 11.31 \cdots = 2^{7/2}
$$

$[e]$ follows from  the hypothesised lower bound on $n$.




\subsection{Proposition \ref{p.dyadic}: derivation}


% Present hypotheses
%[1]
%$$
%n \geq 2 \, , \, \vert  y - x  \vert \leq \rsc/2 \cdot n^{1/9} - 1 \, \,  \textrm{and} \, \, 
%$$
%$$ 
% K_0 \geq  3 \cdot 2^{19/2} \, ;
%$$
%

In this proof, Proposition~\ref{p.locreg} is applied twice, and here we make use of  
$\vert  y + u_1 - x - z \vert \leq 2^{-1} \rsc n^{1/9}$
and
 $\vert x + u_1  - y - z \vert \leq 2^{-1} \rsc  n^{1/9}$.
 Since $u_1,z \in [0,1]$, both of these are implied by
  $$
 [1] \, \,  \vert  y - x  \vert + 1 \leq 2^{-1} \rsc n^{1/9} \, .
  $$
Note that $[1]$ is implied by the hypothesised inequalities that $\vert  y - x  \vert \leq 4^{-1} \rsc  n^{1/9}$ and $1 \leq 4^{-1} \rsc n^{1/9}$.

We also use 
$n+1 \geq 6^3 c^{-3}$, which follows from  $n \geq (4/c)^9$ and $c \leq 1$.




\subsection{Theorem~\ref{t.differenceweight}: derivation}

For this calculational derivation, in defiance of the guideline offered in the paragraphs that begin this appendix, we begin by labelling the actual hypotheses of Theorem~\ref{t.differenceweight}.

These hypotheses concern parameters $n \in \N$, $\e > 0$, $x,y \in \R$ and $R \geq 0$. The conditions in question are:
$$
[h1] \, \, \e \in (0,2^{-4}]
$$  
$$
[h2] \, \, n \geq 10^{29} c^{-18}
$$
Let $x,y \in \R$ satisfy  
$$
 [h3] \, \, \big\vert x - y  \big\vert \leq 2^{-5/3} 3^{-1} \rsc  n^{1/18}
$$
$$
 [h4] \, \, R \geq 10^4
$$ 
$$
 [h5] \, \,  R \leq  10^3 n^{1/18} 
$$   

Naturally we must now argue that these conditions imply all conditions invoked during the proof of Theorem~\ref{t.differenceweight}.
With a few exceptions, discussed at the end of the derivation, these needed conditions are invoked in two contexts: an application of 
Corollary~\ref{c.maxminweight} and an application of Proposition~\ref{p.dyadic}. We discuss the two contexts in turn.

The first context is the use of 
Corollary~\ref{c.maxminweight} via~(\ref{e.maxminbound}). Here, the following conditions are needed:
$$
[c1] \, \, n \geq 10^{29} \vee 2(c/3)^{-18} \, , \,
$$
$$
[c2] \, \,  \big\vert x - y  \big\vert + 4 \leq   3^{-1} 2^{-2/3} \rsc  n^{1/18}
$$
$$
 [c3] \, \, r_0 \geq  33 
 $$
 $$
 [c4] \, \, r_0 \leq 4 n^{1/18}  
$$
where 
$$
 r_0 = 2^{-9/4}S
$$
and
$$
 R = 2^2 (1 - 2^{-1/4})^{-1} S
$$

Note that $[h2,h3] \to [c1]$.


$[c2]$ is implied by
$$\big\vert x - y  \big\vert \leq  2^{-1} 3^{-1} 2^{-2/3} \rsc  n^{1/18} \,  \textrm{and} \,
n \geq \big( 2^{11/3} 3 c^{-1} \big)^{18} = 2^{66} 3^{18} c^{-18}
$$
the first of which is $[h3]$ and the second of which is implied by $[h2]$
since $2^{66} 3^{18} \in [10^{28},10^{29}]$. 

$[c3]$ expressed in terms of $R$ is 
$$
 [c3] \, \,  R \geq  33  \cdot  2^{9/4}  \cdot  2^2 (1 - 2^{-1/4})^{-1}
$$
$[c4]$ expressed in terms of $R$ is 
$$
 [c4] \, \,  R \leq  4 n^{1/18} \cdot  2^{9/4}  \cdot  2^2 (1 - 2^{-1/4})^{-1}
$$

The second of the two contexts is the application of Proposition~\ref{p.dyadic}. For this purpose, we must have:
$$
[p1] \, \,n \geq (4/c)^9
$$
$$
[p2] \, \, \big\vert x - y  \big\vert \leq \rsc/4 \cdot n^{1/9}
$$
$$
[p3] \, \, \Kzero  \geq  4
$$

Note that $[h2] \to [p1]$ since $c \leq 1$.
Also $[h3] \to [p2]$.

In $[p3]$, the value of $\Kzero$ ranges over infinitely many values as Proposition~\ref{p.dyadic} is repeatedly applied, but in each case, this value satisfies
$$
 K_0 \geq 2^{k/4 - 1/2} S
$$ 
where $k \in \N$. Thus, it is enough to ensure that $[p3]$ is satisfied to impose that
$$
 S \geq  2^{2 + 1/2}
$$ 
or equivalently 
$$
[*] \, \, R \geq 2^{5/2} \cdot 2^2 (1 - 2^{-1/4})^{-1}
$$
which is implied by $[c3]$.

Returning to $[c3,c4]$, note that $(1 - 2^{-1/4})^{-1} = 6.285 \cdots$ and $(1 - 2^{-1/4})^{-1} \cdot 33 \cdot 2^{9/4 + 2} = 3946.\cdots$,
so that $[c3]$ is implied by
$$
   R \geq 10^4 
$$
which is $[h4]$,
while $[c4]$ is implied by 
$$
 R \leq 10^3 n^{1/18}
$$
which is $[h5]$.

During the proof of the theorem, we also use that $S$ is bounded below by $2^{7/2}$, $2^{5/2 + 2} = 2^{9/2}$ and $1$. Thus, we set $S = 2^{9/2}$. All of these bounds follow from 
the variant of $[*]$ where the right-hand side is multiplied by four, and this bound follows from $[c3]$.



\subsection{Lemma \ref{l.regfluc}: derivation}

We begin this longer derivation by gathering together the collection of conditions that were used during the proof of this lemma.

First recall that the parameters on which conditions are imposed are $n \in \N$, $R > 0$, and the three positive components of $\ovbar{\coninit}$.

The penultimate inequality of the first displayed set of the equations in the proof makes use of
$$
R^2/4 \geq  2^{-1/2} (\coninit_2 + 1 )^2 +  \coninit_3 \, .
$$
When $\rmreg(2)$ with parameter choices ${\bf z} = x_0$
and ${\bf s} = R^2/4$ is applied to the  ensemble  $\scaledle_{n;0}^{\downarrow;(-1,1)}$, 
the hypotheses 
 $$
 n \geq c^{-9} (\coninit_2 + 1)^9
 $$ 
 and 
 $$
 R^2/4 \in [1,n^{1/3}] 
 $$
 are used.
 
Next, it is supposed that
 $$
 2 R \leq 3^{-1}c n^{1/9} \, .
 $$

When Proposition~\ref{p.mega}(3)
%$\rmreg(4)$ 
is applied to  $\scaledle_{n;0}^{\downarrow;(-1,1)}$, use is made of the conditions:
$$
1 \leq 3^{-1} \rsc  n^{1/9}
$$ 
$$
\coninit_1 \leq \big( 2^{-1/2} - 2^{-5/2} - 2^{-1} \big) (\rsc/9)n^{1/9}
$$ 
$$
\coninit_1 \leq 5 \cdot 2^{3/2} c/3 \cdot n^{1/9}
$$
$$
n + 1  \geq 2^{45/4} \rsc^{-9}
$$

Next,  the condition 
$$R \geq 1 \vee 39 \coninit_1
$$ 
is used to assert that 
$$
2^{-1} R^2 \big( 2^{2j - 1/2} - 1/2 \big) \geq \coninit_1 \big( 2 + 2^{j+1}R  \big)
$$ 
for each $j \geq 0$.



When Proposition~\ref{p.mega}(2) 
%Proposition~\ref{p.nobigmax.gen} 
is applied to the ensemble
$\scaledle_{n;0}^{\downarrow;(-1,1)}$, the conditions  
$$
3 \cdot 2^j R  \leq c n^{1/9} \, , 
$$
$$ 
 2^{j+1} R  \leq \rsc n^{1/9} \, , 
 $$
 $$
  2^{-1} R^2 \big( 2^{2j - 1/2} - 1/2 \big) \leq 2 n^{1/3}  
  $$
  $$
  2^{-1} R^2 \big( 2^{2j - 1/2} - 1/2 \big)    \geq   2^{7/2}
  $$
   and 
   $$
    n \geq c^{-18} 
$$
are used. The first three of these conditions are valid when $j \in \llbracket 0,k \rrbracket$ in light of the condition $2^{k+1} R \leq 3^{-1} c n^{1/9}$ that defines $k$ (and $c \leq 1$ is used as well); indeed, they are also valid when $j = k+1$, a fact which is used immediately after in this proof. For this reason, none of these three conditions impose any additional requirements, and they will be omitted henceforth in our analysis.

Finally, the following bounds are needed:
$$
R \geq (\log 4)^{1/3} 2^2 c^{-3} \big( (2^{3/2} - 2^{-1})^{3/2} - (2^{-1/2} - 2^{-1})^{3/2} \big)^{-1/3}
$$ 
$$
R \leq  (2^{-1/2} - 2^{-1})^{-1/2} 2^{3/4} 3^{-1} \rsc n^{1/9}
$$
and
$$
R \geq 1 \, .
$$


Our analysis begins by confirming that the condition 
$R \geq 1 \vee 39 \coninit_1$ indeed suffices for its role above.

\noindent{\bf Claim.}  The condition
$$
R \geq 1 \vee 39 \coninit_1
$$ 
implies  that 
$$
2^{-1} R^2 \big( 2^{2j - 1/2} - 1/2 \big) \geq \coninit_1 \big( 2 + 2^{j+1}R  \big)
$$ 
for each $j \geq 0$.  

\noindent{\bf Proof.} We claim that  $R \geq 1 \vee 39 \coninit_1$ implies that 
\begin{equation}\label{e.jpositive}
2^{-1} R^2 \big( 2^{2j - 1/2} - 1/2 \big) \geq \coninit_1 \big( 2 + 2^{j+1}R  \big) \qquad \textrm{for each $j \geq 0$} \, .
\end{equation}

The displayed inequality is equivalent to
$$
 R^2 \big( 2^{2j + 1/2} - 1 \big) \geq  2^3 \coninit_1 \big( 1 + 2^j R  \big)
$$ 
for $j \geq 0$. Since $2^{2j + 1/2} - 1 \geq   2^{2j} \big( 2^{1/2}   - 1 \big)$
for $j \geq 0$ and $1 + 2^j R \leq 2^{j+1}R$ (this due to $R \geq 1$), the last displayed bound is implied by
$$
 R^2   2^j \big( 2^{1/2}   - 1 \big) \geq 2^4 \coninit_1  R  \, .
$$
This holds for all $j \geq 0$ provided that 
 $R   \geq 2^4  \big( 2^{1/2}   - 1 \big)^{-1} \coninit_1$.
 Since $2^4  \big( 2^{1/2}   - 1 \big)^{-1} = 38.62 \cdots$, it is also implied by  $R   \geq 39 \coninit_1$.
 
 Thus, $R   \geq 1 \vee 39 \coninit_1$ implies~(\ref{e.jpositive}), as we claimed. \qed
  
Next we write the set of needed conditions in a list:

$$
R^2/4 \geq  2^{-1/2} (\coninit_2 + 1 )^2 +  \coninit_3 \, .
$$
 $$
 n \geq c^{-9} (\coninit_2 + 1)^9
 $$ 
 $$
 R^2  \geq 4 
 $$
 $$
 R^2 \leq 4 n^{1/3} 
 $$
 $$
 2 R \leq 3^{-1}c n^{1/9} \, .
 $$
$$
1 \leq 3^{-1} \rsc  n^{1/9}
$$ 
$$
\coninit_1 \leq \big( 2^{-1/2} - 2^{-5/2} - 2^{-1} \big) (\rsc/9)n^{1/9}
$$ 
$$
\coninit_1 \leq 5 \cdot 2^{3/2} c/3 \cdot n^{1/9}
$$
$$
n + 1  \geq 2^{45/4} \rsc^{-9}
$$
$$
R \geq 1 \vee 39 \coninit_1
$$ 
 $$
  2^{-1} R^2 \big( 2^{1/2} -  2^{-1} \big) \geq 2^{7/2}    
  $$
   $$
    n \geq c^{-18} \, .
$$
$$
R \geq (\log 4)^{1/3} 2^2 c^{-3} \big( (2^{3/2} - 2^{-1})^{3/2} - (2^{-1/2} - 2^{-1})^{3/2} \big)^{-1/3}
$$ 
$$
R \leq  (2^{-1/2} - 2^{-1})^{-1/2} 2^{3/4} 3^{-1} \rsc n^{1/9}
$$
$$
R \geq 1 \, .
$$

We now split this list into categories:
\begin{itemize}
\item Lower bounds on $R$.
\item Upper bounds on $R$.
\item Lower bounds on $n$ without dependence on $R$.
\end{itemize}

\noindent{\em Lower bounds on $R$.}
$$
  [L1] \, \,  R^2/4 \geq  2^{-1/2} (\coninit_2 + 1 )^2 +  \coninit_3 \, .
$$
 $$
 [L2] \, \,  R^2  \geq 4 
 $$
$$
  [L3] \, \,  R \geq 39 \coninit_1
$$ 
 $$
   [L4] \, \,  2^{-1} R^2 \big( 2^{1/2} -  2^{-1} \big) \geq 2^{7/2}    
  $$
$$
   [L5] \, \,  R \geq (\log 4)^{1/3} 2^2 c^{-3} \big( (2^{3/2} - 2^{-1})^{3/2} - (2^{-1/2} - 2^{-1})^{3/2} \big)^{-1/3}
$$
 $$
   [L6] \, \,  R \geq 1 \, .
$$



\noindent{\em Upper bounds on $R$.}

 $$
  [U1] \, \,  R^2 \leq 4 n^{1/3} 
 $$
 $$
  [U2] \, \,  2 R \leq 3^{-1}c n^{1/9} \, .
 $$
$$ 
  [U3] \, \,   R \leq  (2^{-1/2} - 2^{-1})^{-1/2} 2^{3/4} 3^{-1} \rsc n^{1/9}
$$



\noindent{\em Lower bounds on $n$.}
 $$
  [n1] \, \,  n \geq c^{-9} (\coninit_2 + 1)^9
 $$ 
$$
  [n2] \, \,   1 \leq 3^{-1} \rsc  n^{1/9}
$$ 
$$
 [n3] \, \,  \coninit_1 \leq \big( 2^{-1/2} - 2^{-5/2} - 2^{-1} \big) 9^{-1} \cdot c n^{1/9}
$$ 
$$
 [n4] \, \,   \coninit_1 \leq 5 \cdot 2^{3/2} 3^{-1} \cdot c  n^{1/9}
$$
$$
 [n5] \, \,   n + 1  \geq 2^{45/4} \rsc^{-9}
$$
   $$
  [n6] \, \,     n \geq c^{-18} \, .
$$

\noindent{\bf Simplifying the lists.}

For each of the three lists, we now find a simpler set of conditions that imply the conditions listed.


\noindent{\em Simplifying the list of lower bounds on $R$.}
We consider three further conditions:
 $$
   [L7] \, \,  R  \geq 5  
  $$
$$
   [L8] \, \,  R \geq 3 c^{-3} 
$$
and
$$
 [L9] \, \, R \geq  2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, .
$$

$[L4]$ takes the form
 $R \geq \big( 2^{1/2} -  2^{-1} \big)^{-1/2}  2^{9/4}$. Since $\big( 2^{1/2} -  2^{-1} \big)^{-1/2}  2^{9/4} = 4.975 \cdots $, $[L7] \to [L4]$. 

Note also that $[L7] \to [L2,6]$.

Since  
\begin{eqnarray*}
 & & (\log 4)^{1/3} 2^2  \big( (2^{3/2} - 2^{-1})^{3/2} - (2^{-1/2} - 2^{-1})^{3/2} \big)^{-1/3} \\
 & = &         3.37758 \cdots       \times            \big(    3.55298 \cdots - 0.09425 \cdots \big)^{-1/3} =       3.37758 \cdots       \times 0.66124 \cdots =  2.23 \cdots \, ,
\end{eqnarray*}
we see that $[L8] \to [L5]$.

Note that $[L9] \to [L1]$.

Thus $[L7,8,9] \to [L1,2,4,5,6]$.

We see then that $[L3,7,8,9]$ is a simplified list, implying the entire set of conditions $[L1,2,3,4,5,6]$.



\noindent{\em Simplifying the list of upper bounds on $R$.}


Note that the conditions $[U1]$ and $[U2]$ may be rewritten:
 $$
  [U1] \, \,  R \leq 2 n^{1/9} 
 $$
 and
 $$
  [U2] \, \,  R \leq 6^{-1}c n^{1/9} \, .
 $$



Since  $(2^{-1/2} - 2^{-1})^{-1/2} 2^{3/4} 3^{-1} = 1.231 \cdots$, $[U2] \to [U3]$. 
That $[U2] \to [U1]$ follows from $c \leq 1$.
We see that the simplified list for the upper bounds on $R$ may be chosen to consist of the condition~$[U2]$. 


\noindent{\em Simplifying the list of lower bounds on $n$.}
Note that $[n2,3,4]$ may be rewritten:
$$
  [n2] \, \,   n \geq  3^{9} \rsc^{-9} 
$$ 
$$
 [n3] \, \,  n \geq \coninit_1^9 \big( 2^{-1/2} - 2^{-5/2} - 2^{-1} \big)^{-9} 9^{9}  c^{-9} 
$$ 
and
$$
 [n4] \, \,  n \geq  \coninit_1^9 \, 5^{-9}  2^{-27/2} 3^{9}  c^{-9}  
$$

Noting that
$$
 \big( 2^{-1/2} - 2^{-5/2} - 2^{-1} \big)^{-9} 9^{9} = ( 0.03033 \cdots )^{-9} 9^9 = 1.783 \cdots \times 10^{22} \, ,
$$
we see that, if we write 
$$
 [n7] \, \,  n \geq \coninit_1^9 10^{23}  c^{-9} \, , 
$$ 
then $[n7] \to [n3,4]$.

We also introduce 
$$
  [n8] \, \,   n \geq  3^{9} \rsc^{-18} 
$$ 
Since $c \leq 1$, $[n8] \to [n2,5]$. Also $[n8] \to [n6]$.

Thus, $[n7,8] \to [n2,3,4,5,6]$. We see that  $[n1,7,8] \to [n1,2,3,4,5,6]$.
The list $[n1,7,8]$ may be written:
 $$
    n \geq \max \Big\{  c^{-9} (\coninit_2 + 1)^9 \, , \,   \coninit_1^9 10^{23}  c^{-9}   \, , \, 3^{9} \rsc^{-18}  \Big\}
 $$ 
 which since $c \leq 1$ is implied by
 $$
 [n9] \, \,    n \geq  c^{-18} \max \Big\{  (\coninit_2 + 1)^9 \, , \,   10^{23} \coninit_1^9     \, , \, 3^{9}  \Big\} \, . 
 $$ 
 The condition $[n9]$ may thus be chosen as the simplified list of lower bounds on $n$.
 
 \noindent{\bf Summary.} Drawing together the three simplified lists, we see that the set of conditions 
 $$
 [L3,L7,L8,L9,U2,n9]
 $$ 
 are sufficient for all the conditions that are applied during the proof of Lemma~\ref{l.regfluc}. These conditions are:
 $$
    R  \geq \max \Big\{ \,    39 \coninit_1  \,  , \, 5  \, , \,   3 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\} \, , 
  $$
 $$
    R \leq 6^{-1}c n^{1/9} \, ,
 $$
and
$$
  n \geq  c^{-18} \max \Big\{  (\coninit_2 + 1)^9 \, , \,   10^{23} \coninit_1^9     \, , \, 3^{9}  \Big\} \, . 
$$
Since these are the set of hypotheses of Lemma~\ref{l.regfluc}, the calculational derivation of this result is complete. \qed

\subsection{Lemma~\ref{l.equicty} derivation}

The calculational derivation of this result is also long, and we first mention that conditions invoked during its proof fall under four categories. They are hypotheses needed in order to 
\begin{itemize}
\item apply Corollary~\ref{c.ordweight};
\item find that the quantity (\ref{e.atmostebytwo}) is at most $\e/2$;
\item apply Lemma~\ref{l.regfluc};
\item and find that the right-hand side of (\ref{e.rhsub}) is also at most $\e/2$.
\end{itemize}
We begin with four subsections, labelled $A$, $B$, $C$ and $D$, whose respective roles are to gather these hypotheses and analyse them, so that a simplified collection of conditions is provided at the end of each subsection. When this is done, we will record all the resulting conditions, split them according to type, and further simplify them. 

We mention also that the values of the two positive constants $\Ctbs$ and $\Ctbd$ have been set in the statement of Lemma~\ref{l.equicty}. We will however treat them for now as free parameters, and will later set them, in accordance with their stated values, while showing that these choices are compatible with all conditions that concern them.

\noindent{\bf A: Hypotheses and analysis for application of Corollary~\ref{c.ordweight}.} 
Here are the hypotheses:
 $$
[a1] \, \, \e \in (0,2^{-4}] 
 $$  
$$ 
[a2] \, \,  n \geq 10^{29} c^{-18}
$$  
$$
[a3] \, \, 
\Ctbd \big( \log \e^{-1} \big)^{1/3} + 2  \leq \e^{-1/2} 
$$
$$ 
[a4] \, \, 
\Ctbd \big( \log \e^{-1} \big)^{1/3} + 2  \leq 2^{-5/3} 3^{-1} \rsc  n^{1/18}
$$ 
$$
[a5] \, \, 
\Ctbs \big( \log \e^{-1} \big)^{2/3} \geq 2 \cdot 10^4
$$
$$
[a6] \, \, 
\Ctbs \big( \log \e^{-1} \big)^{2/3} \leq   10^3 n^{1/18} 
$$
$$
[a7] \, \, 
n \in 2\N
$$

We introduce the conditions
$$
 [a8] \, \,  2 \leq \Ctbd \big( \log \e^{-1} \big)^{1/3}
$$
$$
 [a9] \, \,  2  \Ctbd \big( \log \e^{-1} \big)^{1/3} \leq \e^{-1/2}
$$
$$
 [a10] \, \,  2  \Ctbd \big( \log \e^{-1} \big)^{1/3}
  \leq 2^{-5/3} 3^{-1} c n^{1/18}
$$
Note that $[a8,9] \to [a3]$ and $[a8,10] \to [a4]$.

Since $[a9]$ is equivalent to
$$
 \e^{-1} \leq \exp \big\{ (2\Ctbd)^{-3} \e^{-3/2} \big\} \, ,
$$
it is implied by
$$
  \e^{-1} \leq (2\Ctbd)^{-3} \e^{-3/2}
$$
or equivalently by 
$$
 [a11] \, \, \e \leq (2\Ctbd)^{-6}
$$
$[a10]$ is equivalent to
$$
[a12] \, \, n \geq 3^{18} 2^{48} c^{-18} \Ctbd^{18} \big( \log \e^{-1} \big)^6
$$
$[a5]$ is equivalent to
$$
[a13] \, \, \e \leq \exp \big\{ - \Ctbs^{-3/2} 2^{3/2} 10^6 \big\}
$$
$[a6]$ is equivalent to
$$
[a14] \, \, n \geq 10^{-54} \Ctbs^{18} \big( \log \e^{-1} \big)^{12}
$$
$[a8]$ is equivalent to
$$
[a15] \, \, \e \leq \exp \big\{ - 8 \Ctbd^{-3} \big\}
$$
With
$$
[a16] \, \, \Ctbd \geq 2 
$$
then $[a11,16] \to [a15]$.

In summary, $[a1,2,7,11,12,13,14,16] \to [a1-10]$.

 

\noindent{\bf B: Hypotheses and analysis to obtain the bound}
 \begin{equation}\label{e.eovertwo}
    \big( 2 R \e^{-1} + 1 \big)    \big( 2 \e^{-1} + 1  \big)  \cdot  10032 \, C  \e^{c_1 2^{-21 - 1/2} \Ctbs^{3/2}    } \leq \e/2 \, .
 \end{equation}
Recall that $R = 1 + \Ctbd \big( \log \e^{-1} \big)^{1/3}$. The left-hand side here is at most
$16 \cdot 10032 C  \e^{c_1 2^{-21 - 1/2} \Ctbs^{3/2}    }$
provided that
$$
 [b1] \, \, 2R \e^{-1} \geq 1 
$$
and
$$
 [b2] \, \, 2 \e^{-1} \geq 1
$$
Imposing 
$$
[b3] \, \, c_1 2^{-21 - 1/2} \Ctbs^{3/2} \geq 4 \, ,
$$
the left-hand side is bounded above by $16 \cdot 10032 C R \e^2$. $[a3]$ implies that $R \leq \e^{-1/2}$, so that the bound may become $16 \cdot 10032 C \e^{3/2}$. This latter quantity is seen to be at most $\e/2$ precisely when
$\e \leq C^{-2} 2^{-2} (16 \cdot 10032)^{-2}$. Since $2^2 (16 \cdot 10032)^2 = 103056408576$, this upper bound on $\e$ is implied by
$$
[b4] \, \, \e \leq 10^{-12} C^{-2}
$$ 
Note that $[b2] \to [b1]$ since $R \geq 1$, and that $[a1] \to [b2]$. 

Note that $[b3]$ is equivalent to
$$
[b5] \, \, \Ctbs \geq 2^{47/3} c_1^{-2/3}
$$
In summary, (\ref{e.eovertwo}) is implied by $[a1,a3,b4,b5]$.

\noindent{\bf C:
Hypotheses and analysis for the application of Lemma~\ref{l.regfluc}.} In this case, our hypotheses are:
$$
[d1] \, \, n \geq  c^{-18} \max \big\{  (\coninit_2 + 1)^9 \, , \,   10^{23} \coninit_1^9     \, , \, 3^{9}  \big\} ,
$$
 $$
[d2] \, \,    R  \geq 1 + \max \Big\{ \,    39 \coninit_1  \,  , \, 5  \, , \,   3 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\} \, , 
  $$
  and
 $$
 [d3] \, \, R - 1 \leq 6^{-1}c n^{1/9}
 $$
  Recalling that $R = 1 + \Ctbd \big( \log \e^{-1} \big)^{1/3}$, we see that $[d3]$ is equivalent to 
 $$
 \Ctbd \big( \log \e^{-1} \big)^{1/3} \leq 6^{-1}c n^{1/9}
 $$
 or 
 $$
[d4] \, \, n \geq \Ctbd^9 \big( \log \e^{-1} \big)^3  6^9 c^{-9} 
 $$
 Since $[a1]$ implies that $\e \leq e^{-1}$, we see that $[a1,d5] \to [d2]$, where
$$
 [d5] \, \, \Ctbd \geq \max \Big\{ \,    39 \coninit_1  \,  , \, 5  \, , \,   3 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\}
$$ 
In summary, $[a1,d1,d4,d5] \to [d1,2,3]$.  
  
  
\noindent{\bf D: Hypotheses and analysis for the bound} 
 \begin{equation}\label{e.secondebound}
 38 (R-1) \rsC       \exp \big\{ -  2^{-6} \rsc   (R - 1)^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2}  \big\}  \leq \e/2 \, .
\end{equation}
 Since $R = 1 + \Ctbd \big( \log \e^{-1} \big)^{1/3}$, this bound is implied by 
 $$
 [e1] \, \, 2^{-6} c \Ctbd^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2} \geq 2
 $$
and
$$
[e2] \, \, 38 \cdot 2 \Ctbd \big( \log \e^{-1} \big)^{1/3} C \leq \e^{-1}
$$ 
 $[e2]$ is equivalent to 
 $$
  \e^{-1} \leq \exp \big\{ (76)^{-3} \Ctbd^{-3} C^{-3} \e^{-3} \big\}
 $$
and is thus implied by
$$
 \e^{-1} \leq (76)^{-3} \Ctbd^{-3} C^{-3} \e^{-3}  
$$ 
or
$$
 [e3] \, \, \e \leq (76)^{-3/2} \Ctbd^{-3/2} C^{-3/2}
$$
In summary, the bound~(\ref{e.secondebound})
is implied by $[e1,3]$.


We continue by collecting all the new conditions, and splitting them according to the form of the inequality on parameters.

\noindent{\bf E: Gathering and splitting the obtained conditions.}
For the calculational derivation of Lemma~\ref{l.equicty}, a sufficient list of hypotheses has been found to be:
$$
[a1,2,7,11,12,13,14,16]; [a1,a3(\textrm{implied by other $a$-conditions}),b4,b5]; 
[a1,d1,d4,d5]; \, \, \textrm{and} \, \, [e1,3] \, .
$$
 We now recall these conditions:
 $$
[a1] \, \, \e \in (0,2^{-4}] 
 $$  
$$ 
[a2] \, \,  n \geq 10^{29} c^{-18}
$$
$$
[a7] \, \, 
n \in 2\N
$$
$$
 [a11] \, \, \e \leq (2\Ctbd)^{-6}
$$
$$
[a12] \, \, n \geq 3^{18} 2^{48} c^{-18} \Ctbd^{18} \big( \log \e^{-1} \big)^6
$$
$$
[a13] \, \, \e \leq \exp \big\{ - \Ctbs^{-3/2} 2^{3/2} 10^6 \big\}
$$
$$
[a14] \, \, n \geq 10^{-54} \Ctbs^{18} \big( \log \e^{-1} \big)^{12}
$$
$$
[a16] \, \, \Ctbd \geq 2 
$$ 
$$
[b4] \, \, \e \leq 10^{-12} C^{-2}
$$ 
$$
[b5] \, \, \Ctbs \geq 2^{47/3} c_1^{-2/3}
$$
$$
[d1] \, \, n \geq  c^{-18} \max \big\{  (\coninit_2 + 1)^9 \, , \,   10^{23} \coninit_1^9     \, , \, 3^{9}  \big\} ,
$$
 $$
[d4] \, \, n \geq \Ctbd^9 \big( \log \e^{-1} \big)^3  6^9 c^{-9} 
 $$
$$
 [d5] \, \, \Ctbd \geq \max \Big\{ \,    39 \coninit_1  \,  , \, 5  \, , \,   3 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\}
$$ 
 $$
 [e1] \, \, 2^{-6} c \Ctbd^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2} \geq 2
 $$
$$
 [e3] \, \, \e \leq (76)^{-3/2} \Ctbd^{-3/2} C^{-3/2}
$$


We reexpress this list in four categories:

 Upper bounds on $\e$:
 $$
[a1] \, \, \e \in (0,2^{-4}] 
 $$  
$$
 [a11] \, \, \e \leq (2\Ctbd)^{-6}
$$
$$
[a13] \, \, \e \leq \exp \big\{ - \Ctbs^{-3/2} 2^{3/2} 10^6 \big\}
$$
$$
[b4] \, \, \e \leq 10^{-12} C^{-2}
$$
$$
 [e3] \, \, \e \leq (76)^{-3/2} \Ctbd^{-3/2} C^{-3/2}
$$



Lower bounds on $\Ctbd$: 
$$
[a16] \, \, \Ctbd \geq 2 
$$ 
$$
 [d5] \, \, \Ctbd \geq \max \Big\{ \,    39 \coninit_1  \,  , \, 5  \, , \,   3 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\}
$$ 
 $$
 [e1] \, \, 2^{-6} c \Ctbd^3 \big( 2^{ - 1/2} - 2^{-1} \big)^{3/2} \geq 2
 $$

Lower bound on $\Ctbs$:  
$$
[b5] \, \, \Ctbs \geq 2^{47/3} c_1^{-2/3}
$$ 

Conditions on $n$: 
$$ 
[a2] \, \,  n \geq 10^{29} c^{-18}
$$
$$
[a7] \, \, 
n \in 2\N
$$
$$
[a12] \, \, n \geq 3^{18} 2^{48} c^{-18} \Ctbd^{18} \big( \log \e^{-1} \big)^6
$$
$$
[a14] \, \, n \geq 10^{-54} \Ctbs^{18} \big( \log \e^{-1} \big)^{12}
$$
$$
[d1] \, \, n \geq  c^{-18} \max \big\{  (\coninit_2 + 1)^9 \, , \,   10^{23} \coninit_1^9     \, , \, 3^{9}  \big\} ,
$$
 $$
[d4] \, \, n \geq \Ctbd^9 \big( \log \e^{-1} \big)^3  6^9 c^{-9} 
 $$
In the next three subsections, we simplify three of these four lists.


\noindent{\bf F: Simplifying lower bounds on $\Ctbd$:} $[e1]$ is equivalent to 
$$
  \Ctbd^3 \geq 2^7  \big( 2^{ - 1/2} - 2^{-1} \big)^{-3/2} c^{-1}
$$
which, since $\big( 2^{ - 1/2} - 2^{-1} \big)^{-3/2} = 10.6098 \cdots$, is implied by $\Ctbd^3 \geq 1359 c^{-1}$ or 
$$
 [f1] \, \, \Ctbd \geq 12 c^{-1/3} 
$$
Since $c \leq 1$, the condition
$$
 [f2] \, \, \Ctbd \geq \max \Big\{ \,    39 \coninit_1  \,  , \,  12 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\}
$$ 
is seen to imply all lowers bound $[a16,d5,e1]$ on $\Ctbd$.
 
In order to simplify other bounds, we now set the values of $\Ctbd$ and $\Ctbs$. We set
$$
 \Ctbd = \max \Big\{ \,    39 \coninit_1  \,  , \,  12 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\}
$$ 
and 
$$
 \Ctbs = 2^{16} c_1^{-2/3} \, .
$$
These choices verify the bounds demanded on these two constants.



\noindent{\bf G: Simplifying conditions on $n$.}

Since $\e \leq e^{-1}$, $c \leq 1$, $\Ctbd \geq 1$, $\Ctbs \geq 1$ and $3^{18} 2^{48} \in [10^{23},10^{24}]$, we have $[g1] \to [a2,a12,a14,d4]$, where
$$
[g1] \, \, n \geq 10^{29} c^{-18} \Ctbd^{18} \Ctbs^{18} \big( \log \e^{-1} \big)^{12}
$$
In fact, we also have $[g1,d5] \to [d1]$, because $10^{29} (39)^{18}\coninit_1^{18} \geq 10^{23} \coninit_1^9$ when $\coninit_1 \geq 1$; and, if $\coninit_1 \in (0,1)$, then we have $10^{29} \geq 10^{23}$. 

That is, all conditions $[a2,a7,a12,a14,d1,d4]$ on $n$ are implied by $[a7,g1]$.



\noindent{\bf H: Simplifying upper bounds on $\e$.}

Since $\Ctbs \geq 1$, $\Ctbd \geq 1$ and $C \geq 1$, the condition
$$
[h1] \, \, \e \leq \Ctbd^{-6} \exp \big\{ - 2^{3/2} 10^6 \big\} C^{-2} 
$$
satisfies $[h1] \to [a1,a11,a13,b4,e3]$, so that it implies all needed upper bounds on $\e$.
 
We are ready to conclude this calculational derivation. 
 
 
\noindent{\bf I: Conclusion.}
In summary of these simplifications, all hypotheses needed for the proof of Lemma~\ref{l.equicty} are implied by 
$[a7,g1,h1]$ provided that the constants $\Ctbd$ and $\Ctbs$ are set as we have specified.

That is, with the choices 
$$
 \Ctbd = \max \Big\{ \,    39 \coninit_1  \,  , \,  12 c^{-3}  \, , \, 2 \big( (\coninit_2 + 1 )^2 +  \coninit_3 \big)^{1/2} \, \Big\}
$$ 
and 
$\Ctbs = 2^{16} c_1^{-2/3}$, a set of conditions sufficient to permit the derivation of Lemma~\ref{l.equicty} is:  
$[a7] \, n \in 2\N$,
$[g1] \, n \geq 10^{29} c^{-18} \Ctbd^{18} \Ctbs^{18} \big( \log \e^{-1} \big)^{12}$ and
$[h1] \,  \e \leq \Ctbd^{-6} \exp \big\{ - 2^{3/2} 10^6 \big\} C^{-2}$. Since these conditions are exactly the hypotheses of Lemma~\ref{l.equicty}, we have completed the calculational derivation of this lemma.


\bibliographystyle{plain}

\bibliography{airy}


\end{document}    